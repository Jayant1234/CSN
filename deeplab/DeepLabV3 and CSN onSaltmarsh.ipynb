{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLabV3 and CSN onSaltmarsh.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIrYCEjjCZYfTbhsVVapR+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"69SP7G-VqfOl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1594552219621,"user_tz":240,"elapsed":861,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"79e45cd4-1bd9-40ed-ea2d-330676ea5517"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dzoHeNtzcC2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"ok","timestamp":1594552221628,"user_tz":240,"elapsed":2842,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"1b1c41b7-8c4a-4857-c943-fb888826da3b"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Jul 12 11:10:19 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0U4RIt-pcG5P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1594552246304,"user_tz":240,"elapsed":27502,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"c5f2fc1e-00f0-497d-b7b2-d1306633bdbd"},"source":["!pip install pytorch\n","!pip install torchvision\n","!pip install opencv-python\n","!pip install --upgrade Pillow\n","!pip install scipy\n","!pip install tqdm\n","!pip install tensorboardx\n","!pip install Biopython\n","# conda install -c menpo opencv : opencv 3.4\n","# pillow : conda install pillow =6\n","# conda install scipy\n","# conda install -c conda-forge tqdm\n","# conda install -c conda-forge tensorboardx"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pytorch\n","  Using cached https://files.pythonhosted.org/packages/ee/67/f403d4ae6e9cd74b546ee88cccdb29b8415a9c1b3d80aebeb20c9ea91d96/pytorch-1.0.2.tar.gz\n","Building wheels for collected packages: pytorch\n","  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n","\u001b[?25h  Running setup.py clean for pytorch\n","Failed to build pytorch\n","Installing collected packages: pytorch\n","    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nnpl2lcb/pytorch/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nnpl2lcb/pytorch/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-oume9wzs/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n","Requirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.5.1+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchvision) (0.16.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n","Requirement already up-to-date: Pillow in /usr/local/lib/python3.6/dist-packages (7.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n","Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.18.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx) (47.3.1)\n","Requirement already satisfied: Biopython in /usr/local/lib/python3.6/dist-packages (1.77)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Biopython) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9n6LHYrnnUz1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1594552246578,"user_tz":240,"elapsed":27755,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"d9192a94-f401-44b6-d09e-bca7dbd908e7"},"source":["import torch\n","print(torch.cuda.get_device_name(0))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gq3nIOp3ngFy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552246855,"user_tz":240,"elapsed":28011,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["import torch as torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","#from torchviz import make_dot\n","from torch.autograd import Variable\n","#from torchsummary import summary #make this work\n","import os\n","#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n","#from graphviz import Digraph\n","import torch.nn.utils.prune as prune\n","import math"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejfRnLgsn6Wy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552247311,"user_tz":240,"elapsed":28427,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["class BaseNetCNN(nn.Module):\n","    \"\"\"\n","    A base Network, 81+81+81 parameters in each BaseNet. \n","    \"\"\"\n","    def __init__(self,channels=32):\n","        inp=3\n","        super(BaseNetCNN, self).__init__()\n","        self.channels=channels\n","        kernel_size=3\n","        BatchNorm=nn.BatchNorm2d\n","        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size,padding=1, bias=False)\n","        self.bn1 = BatchNorm(channels)\n","        self.conv2 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size,padding=1, bias=False)\n","        self.bn2 = BatchNorm(channels)\n","        self.conv3 = nn.Conv2d(in_channels=channels, out_channels=channels,kernel_size=kernel_size, padding=1, bias=False)\n","        self.bn3 = BatchNorm(channels)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = self.relu(out)\n","        \n","        out += x\n","\n","        return out\n","\n","# class BaseNetCNN(nn.Module):\n","\n","#     def __init__(self, channels):\n","#         super(BaseNetCNN, self).__init__()\n","#         self.channels=channels\n","#         stride=1\n","#         dilation=1 \n","#         downsample=None\n","#         BatchNorm=nn.BatchNorm2d\n","#         out_channels=channels*2\n","#         self.conv1 = nn.Conv2d(channels, out_channels, kernel_size=1, bias=False)\n","#         self.bn1 = BatchNorm(out_channels)\n","#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride,\n","#                                dilation=dilation, padding=dilation, bias=False)\n","#         self.bn2 = BatchNorm(out_channels)\n","#         self.conv3 = nn.Conv2d(out_channels, channels, kernel_size=1, bias=False)\n","#         self.bn3 = BatchNorm(channels)\n","#         self.relu = nn.ReLU(inplace=True)\n","#         self.downsample = downsample\n","#         self.stride = stride\n","#         self.dilation = dilation\n","\n","#     def forward(self, x):\n","#         residual = x\n","\n","#         out = self.conv1(x)\n","#         out = self.bn1(out)\n","#         out = self.relu(out)\n","\n","#         out = self.conv2(out)\n","#         out = self.bn2(out)\n","#         out = self.relu(out)\n","\n","#         out = self.conv3(out)\n","#         out = self.bn3(out)\n","\n","#         if self.downsample is not None:\n","#             residual = self.downsample(x)\n","\n","#         out += residual\n","#         out = self.relu(out)\n","\n","#         return out\n","    \n","class InterconnectionCNN(nn.Module):\n","    \"\"\"\n","    A base Network, hope is to give it parameters less than 100. It might not be possible for ANNs.\n","    \"\"\"\n","    def __init__(self,cnnsize):\n","        super(InterconnectionCNN, self).__init__()\n","        #newsize\n","        #run one layer or two// just doing it for 2x2 module size. DAMN.   \n","        #one idea here was to divide the input here and make it go through a layer, seems unneccesary\n","        BatchNorm=nn.BatchNorm2d\n","        self.conv1 = nn.Conv2d(in_channels=cnnsize, out_channels=512, kernel_size=1,padding=0, bias=False)\n","        self.bn1 = BatchNorm(512)\n","        self.conv2 = nn.Conv2d(in_channels=512, out_channels=cnnsize, kernel_size=1,padding=0, bias=False)\n","        self.bn2 = BatchNorm(cnnsize)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        #concatenate modules output in each column in Modularity and give out x. \n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ModularityCNN(nn.Module):\n","    #modular_hierarchy=0 :level of hierarchy one is at. \n","    def __init__(self,args,depth,width,level,basenet_size):\n","        super(ModularityCNN, self).__init__()\n","        \"\"\"\n","        args(list) : list containing all modules to be sewed\n","        depth(int) : The expansion depth\n","        width(int) : The total width = expansion  width**expo_level + linear_width_multiplier*(level-expo_level)\n","        level(int) : Levels-1 above basenet, i.e. it contains info about interconnection no.\n","        //especially needed for weight initlization.   \n","        \"\"\"\n","\n","        self.depth=depth\n","        self.width=width\n","        self.level=level\n","        self.basenet_size= basenet_size#32 #check basenet, needs to be same// I have to find way to get this input here from CSN \n","        self.cnn_channels=self.basenet_size*(self.width**self.level) #formula just works till there is no width increase in linear exp.\n","#         print(\"CNN Channel Count: \",self.cnn_channels)\n","#         print(\"Level\",level)\n","        if len(args) != width*depth:\n","            assert \"Error : Module size not right!\"\n","        if type(args) is list:\n","            i=0\n","            j=0\n","            for module in args:  \n","                self.add_module(\"module\"+str(i), module)\n","                i+=1\n","                #add interconnections based on size of depth and width and level? \n","                if(i%self.width==0 and self.width>1 and i<((self.width*self.depth)-1)):\n","                    self.add_module(\"interconnection\"+str(j),InterconnectionCNN(self.cnn_channels))\n","                    j+=1\n","        else:#ordered Dict case\n","            for idx, module in enumerate(args):\n","                self.add_module(str(idx), module)\n","      \n","    def init_weights(self,m):\n","        \"\"\"\n","        To be applied to a same level but when clipping it into the bigger one!\n","        \"\"\"\n","        if type(m) == Modularity:\n","            #load saved weights of level-1 onto the Modularity!\n","            #maybe its better to load save weights while forming the lower modularity? i.e -1. \n","            #That way I won't have to worry about interconnections at all, its just one apply on all sub-modules\n","            #god damn I am good. \n","            pass\n","    def forward(self, x): \n","        #OOOPS, forgot to do batch norm here...\n","        #define interconnections name as different. \n","        foro=[]\n","        fori=[]\n","#         print(\"Level\", self.level, \"First X split Sections and x.size():\",int(list(x.size())[1]/self.width),x.size())\n","#         print(\"Split 2's size\",fori[1].size())\n","        fori=torch.split(x,int(list(x.size())[1]/self.width), dim=1)\n","        module_iterator= self.children()# this would return interconnections by the end. A bit troublesome. Figured out, \n","        #need to test this ofc\n","        for i in range(self.depth): \n","            if(i==0):\n","                for j in range(self.width): \n","                    #first layer in given width\n","                    depthbuff=0\n","                    if(j==0):\n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    elif(j==self.width-1): \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    else:   \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                \n","            elif(i==self.depth-1): \n","                module=next(module_iterator)# this is interconnection hopefully\n","                #print(module)\n","                #print(\"LEVEL:\",self.level,\"Above module's concatenated input size: \", torch.cat(foro,1).size())\n","                inp=torch.cat(foro,1)\n","                output=module(inp)\n","                del inp\n","                del fori\n","                fori=torch.split(output,int(list(output.size())[1]/self.width),1)\n","                del output\n","                depthbuff=0\n","                del foro\n","                foro=[]\n","                for j in range(self.width): \n","                    if(j==0):\n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    elif(j==self.width-1): \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    else:   \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","            else:\n","                module=next(module_iterator)# this is interconnection hopefully\n","                #check if this module is interconnection type?\n","#                 print(module)\n","#                 print(\"LEVEL:\",self.level,\"Above module's concatenated input size: \", torch.cat(foro,1).size())\n","                inp=torch.cat(foro,1)\n","                output=module(inp)\n","                del inp\n","                del fori\n","                fori=torch.split(output,int(list(output.size())[1]/self.width),1)\n","                del output\n","                depthbuff=0\n","                del foro\n","                foro=[]\n","                for j in range(self.width): \n","                    \n","                    if(j==0):\n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    elif(j==self.width-1): \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","                    else:   \n","                        module=next(module_iterator)\n","                        out1=module(fori[depthbuff])\n","                        foro.append(out1)\n","                        depthbuff+=1\n","\n","        out= torch.cat(foro,1)\n","        del foro\n","        out += x\n","        return out"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFbW-wsEoBDM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552247596,"user_tz":240,"elapsed":28680,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["class CompositionalSparseNetCNN(nn.Module):\n","    def __init__(self,inp=3,stage=\"Base_model\",exp_level=4,channels_width=256, exponential_cutoff=4,\\\n","                 dir_saved_weights=r'Weights/',expo_depth=2,expo_width=2,nettype=\"CNN\",prev_path=\"CSN\"):\n","        \"\"\"\n","        inp[int]: baseNet size\n","        pruning_type (string) : 'unstructured' or 'structured', structured refers to layers or modules\n","        stage (string) : 'base_model' or exp_expansion' or 'linear_expansion' or 'reload'\n","        exp_level (int) : 0-100 : represents total expansion  level including both exponen. and linear.\n","        exponential_cutoff(int) : 1 to 20, tells expansion level at which exponential expansion halts\n","        dir_saved_weights (string): filepath to save prev. modular hierarchy level weights for uploading\n","        expo_depth (int) : exponential expansion depth size\n","        expo_width (int) : exponential expansion width size\n","        channels_width(int) : Based on exponential expansion size, this width will change!\n","        nettype (string) : \"CNN\" or \"FCN\" \n","        \"\"\"\n","#         List of changes to make : \n","#             1. Give width of the whole network in MODULARITY. \n","#             2. Manage the input filter size with width of current module. \n","#            3. Check the fucking variable width and depth. \n","\n","        super(CompositionalSparseNetCNN, self).__init__()\n","        self.inp=inp\n","        self.exp_level=exp_level\n","        self.stage=stage\n","        self.dir_saved_weights=dir_saved_weights\n","        self.exponential_cutoff=exponential_cutoff\n","        self.prev_path=prev_path\n","        self.nettype=nettype\n","        \n","        \n","        if(self.stage=='exp_expansion' and (self.exp_level!=self.exponential_cutoff)):\n","            assert \"Inconsistent Model configuration, At exponentially expansion stage, expansion level should be the same number as exponential exp level\"\n","    \n","        #merge both exponential and linear expansion methods after weight manipulation.\n","        #exponential expansion\n","        self.expo_depth=expo_depth # y=(ed)^level y= x^a\n","        self.expo_width=expo_width\n","        #linear expansion\n","        self.linear_depth=4 # y= multiplier* ld #y=mx \n","        self.linear_width=0 #lets keep this constant for a while. BECOZ OF FREAKIN GPUs.  \n","        self.multiplier=exp_level-self.exponential_cutoff\n","        self.basenet_size= int(channels_width/(self.expo_width**self.exponential_cutoff + self.linear_width*self.multiplier))\n","        print(self.basenet_size)\n","        #first two layers\n","        self.relu = nn.ReLU()\n","        self.channels_width=channels_width\n","        self.downsamp1= nn.Sequential(\n","            nn.Conv2d(3, 256, kernel_size=7, stride=2, padding=3,\n","                                bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","            )\n","        self.conv1= nn.Sequential(\n","            nn.Conv2d(256, channels_width, kernel_size=1, stride=1, padding=0,\n","                                bias=False),\n","            nn.BatchNorm2d(channels_width),\n","            nn.ReLU(inplace=True)\n","            )\n","\n","        #transfer contents to a method. \n","        total_width = self.expo_width**exponential_cutoff + (exp_level-exponential_cutoff)*self.linear_width\n","        all_modules=self.expansion()\n","        #modularityCNN definition\n","        if(self.multiplier>0): \n","            #perform addition of modules similar to above!. \n","            td= self.expo_depth+self.linear_depth*self.multiplier\n","            tw=self.expo_width+self.linear_width*self.multiplier\n","            self.modularity=ModularityCNN(all_modules,td,tw,self.exponential_cutoff,self.basenet_size)\n","        else :\n","            self.modularity=ModularityCNN(all_modules,self.expo_depth,self.expo_width,self.exponential_cutoff,self.basenet_size)\n","        if(self.stage=='linear_expansion'): \n","            #loading dicts from previous expansion levels. \n","            #PUT IN A CHECK IF LEVEL 1 IS NOT THERE, JUST PUT EXPODICT AS rand weight init\n","            path=self.prev_path+'/'+'level'+str(self.exponential_cutoff-1)+'.pth'\n","            statedict=torch.load(path)     \n","            expodict={}\n","            for k in list(statedict.keys()):\n","                lst=k.split('.')\n","                if(lst[0]==\"modularity\"):\n","                    lst=lst[1:]\n","                    new_k='.'.join(lst)\n","                    expodict[new_k]=statedict[k]\n","            \n","            old_depth=self.expo_depth + self.linear_depth*(self.multiplier-1)\n","            old_width=self.expo_width + self.linear_width*(self.multiplier-1)\n","            new_depth=self.expo_depth + self.linear_depth*self.multiplier\n","            new_width=self.expo_width + self.linear_width*self.multiplier\n","            \n","            path=self.prev_path+'/'+'level'+str(self.exp_level-1)+'.pth'\n","            statedict=torch.load(path)     \n","            lineardict= [{}] * (old_depth*old_width)\n","            linearinter=[{}] * (old_depth-1)\n","            for k in list(statedict.keys()):\n","                lst=k.split('.')\n","                if(lst[0]==\"modularity\"):\n","                    lst=lst[1:]\n","                    no=0\n","                    if lst[0][0]==\"m\": \n","                        no=int(lst[0][6:])#getting no. from module..no\n","                        new_k='.'.join(lst[1:]) #removes modularity right? but it contains module0 identity of itself?\n","                        lineardict[no][new_k]=statedict[k] \n","                    elif lst[0][0]==\"i\": \n","                        no=int(lst[0][15:])#getting no. from interconnection..no\n","                        new_k='.'.join(lst[1:]) #removes modularity right? but it contains module0 identity of itself?\n","                        linearinter[no][new_k]=statedict[k]\n","                    else : \n","                        assert \"The loaded linear dict is not right!\"\n","                    \n","        \n","            #print('lineardict', [dit.keys() for dit in lineardict])\n","            #print('linearinter',linearinter)\n","\n","            width_pos=math.ceil(float(new_width - old_width)/2)\n","            depth_pos=math.ceil(float(new_depth - old_depth)/2)\n","            first_num=depth_pos*new_width + width_pos\n","            total_lst=[i for i in range(0,new_depth*new_width)]\n","            lst_linear=[]\n","            lst_exp=[]\n","            #can find interconnection no. based on depth_pos simply. Its depth_pos-1? \n","            \n","            for j in range(0,old_depth):\n","                lst_linear.extend([i+first_num+j*new_width for i in range(0,old_width)])\n","            print(lst_linear)\n","            lst_exp=[item for item in total_lst if item not in lst_linear]\n","            print(lst_exp)\n","            lin_buffer=0\n","            for n,module in enumerate(self.modularity.named_children()):\n","                name=module[0]\n","                mtype= \"x\"\n","                no=0\n","                if name[0]==\"m\": \n","                    no=int(name[6:])#getting no. from module..no\n","                    mtype=\"m\"\n","                elif name[0]==\"i\": \n","                    no=int(name[15:])#getting no. from interconnection..no\n","                    mtype=\"i\"\n","                else : \n","                    no=None\n","                    print(no,name)\n","                    print(mtype)\n","                    continue\n","                print(no,name)\n","                print(mtype)  \n","                \n","                if(mtype==\"m\"):\n","                    if (no in lst_linear):\n","                        module[1].load_state_dict(lineardict[lin_buffer])\n","                        lin_buffer+=1\n","                        print(\"Checking linBuffer and module no./decrease intercon count\",lin_buffer,n)\n","                    elif no in lst_exp: \n","                        module[1].load_state_dict(expodict)\n","                elif(mtype==\"i\") and (old_width==new_width):\n","                    #there is no way interconnections are gonna work through transfer learning if width is increased.\n","                    inter_num=int(((lin_buffer)/old_width)-1)\n","                    if(0 < lin_buffer < max(lst_linear)) and inter_num < len(linearinter):\n","                        print(\"Checking internum and module no./decrease intercon count\",inter_num,n)\n","                        module[1].load_state_dict(linearinter[inter_num]) \n","\n","                else : \n","                    assert \"What kind of module is this? it should not be here.\"\n","        \"\"\"BIGGEST MISTAKE Here could be that, the loading of state dict does not happen?\"\"\"\n","        #print(\"self.modularity.state_dict: \",self.modularity.state_dict().keys())\n","\n","        self.downsamp2 = nn.Sequential(\n","            nn.Conv2d(channels_width,1024, kernel_size=7, stride=2, padding=3,\n","                                bias=False),\n","            nn.BatchNorm2d(1024),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(1024, 2048, kernel_size=7, stride=2, padding=3,\n","                                bias=False),\n","            nn.BatchNorm2d(2048),\n","            nn.ReLU(inplace=True),\n","            )\n","    \n","    def expansion(self): \n","        \"\"\"\n","        creates a basenet list and stiches them into Modularity Classes design. \n","        \"\"\"\n","        \n","        exp_basenet_list = [BaseNetCNN(self.basenet_size) for count in range(0,(self.expo_depth*self.expo_width)**self.exponential_cutoff)]\n","        #was not thinking, need to load weights on those Modularity modules which are one_level below! see if thats possible.\n","        module_size=self.expo_depth*self.expo_width\n","        for i in range(0,self.exponential_cutoff-1):\n","            new_basenet=[]\n","            for j in range(0,(module_size)**(self.exponential_cutoff-i),module_size):\n","                new_basenet.append(ModularityCNN(exp_basenet_list[j:j+module_size],self.expo_depth,self.expo_width,i+1,self.basenet_size))\n","            exp_basenet_list=new_basenet\n","\n","        if(self.stage =='exp_expansion'): \n","            for i in range(len(exp_basenet_list)):\n","                path=self.prev_path+'/'+'level'+str(self.exponential_cutoff-1)+'.pth'\n","                statedict=torch.load(path)              \n","                #In order to load this\n","                \"\"\"I just realized I have to write this script in weight init method or it will be just overwritten right\n","                ??\"\"\"\n","                modulardict={}\n","                for k in list(statedict.keys()):\n","                    lst=k.split('.')\n","                    if(lst[0]==\"modularity\"):\n","                        lst=lst[1:]\n","                        new_k='.'.join(lst)\n","                        modulardict[new_k]=statedict[k]\n","                exp_basenet_list[i].load_state_dict(modulardict)\n","                #print(exp_basenet_list[i].state_dict())\n","\n","        lin_basenet_list=[]\n","        #linear expansion\n","        if(self.multiplier>0): \n","            #td = total depth of last level of dynamic hierarchy \n","            #tw =  total width of last level of dynamic hierarchy\n","            td= self.expo_depth+self.linear_depth*self.multiplier\n","            tw=self.expo_width+self.linear_width*self.multiplier\n","            d=self.expo_depth\n","            w=self.expo_width\n","            lin_basenet_list = [BaseNetCNN(self.basenet_size) for count in range(0,((d*w)**(self.exponential_cutoff-1))*(td*tw-d*w))]\n","        \n","            module_size=d*w\n","            final_module_size=td*tw\n","            for i in range(0,self.exponential_cutoff-1):\n","                new_basenet=[]\n","                j=0\n","                while(j<len(lin_basenet_list)):\n","                    new_basenet.append(ModularityCNN(lin_basenet_list[j:j+module_size],self.expo_depth,self.expo_width,i+1,self.basenet_size))\n","                    j+=module_size                        \n","                lin_basenet_list=new_basenet\n","\n","        basenet_list= exp_basenet_list+lin_basenet_list\n","        return basenet_list\n","    \n","    def forward(self, x):\n","        \"\"\"based on hierarchy levels, depths for linear and exponential expansion, \n","        base net is repeated in init with various self.basenet in list and then used to be trained.\"\"\"\n","        x=self.downsamp1(x)\n","        low_level_feat=x\n","        x=self.conv1(x)\n","        x=self.modularity(x)\n","        x=self.downsamp2(x)\n","        return x, low_level_feat\n","    "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Z5qHlKvoM18","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552247866,"user_tz":240,"elapsed":28933,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["def global_pruning(model,pruning_rate=0.3):\n","        \"\"\"\n","        Global unstructured magnitude L1 norm pruning\n","        design or experiment choices : to create pruning on top of pruning or remove old ones to produce new higher rates? \n","        Current : Keeps pruning by keeping weights zero! but next pruning will just prune these zeroes too right, need to increase\n","        the rate still, so the other choice is actually better. To just restore everything back to normal. shall do that then\n","        \"\"\"\n","        parameters_to_prune={}\n","        for name, param in model.named_parameters():\n","            #parameters_to_prune[name]= param.data\n","            lst=name.split('.')            \n","            s=\".\"\n","            LOC=s.join([\"model\"]+lst[0:-1])\n","            if(lst[0]=='modularity'):\n","                exec(\"parameters_to_prune[\"+LOC+\"]= 'weight'\")#just pruning weights, not biases/thats how its done.\n","                \n","        parameter_tuple=tuple(list(parameters_to_prune.items()))\n","        prune.global_unstructured(\n","             parameter_tuple,\n","             pruning_method=prune.L1Unstructured,\n","             amount=pruning_rate,)\n","\n","def remove_global_pruning(model): \n","        parameters_to_prune={}\n","        for name, param in model.named_parameters():\n","            #parameters_to_prune[name]= param.data\n","            lst=name.split('.')            \n","            s=\".\"\n","            LOC=s.join([\"model\"]+lst[0:-1])\n","            if(lst[0]=='modularity'):\n","                exec(\"parameters_to_prune[\"+LOC+\"]= 'weight'\")#just pruning weights, not biases/thats how its done.\n","        \n","        parameter_tuple=tuple(list(parameters_to_prune.items())) \n","        for m in parameter_tuple: \n","            #does the job really, removed all pruning reparametrization but keeps zeroes in weights. \n","            #print(m)\n","            prune.remove(m[0], 'weight')\n","            \n","def structured_pruning(model, pruning_rate=0.3): \n","    \"\"\"Acts on all BaseNets differently!\"\"\"\n","    basenets_to_prune=[]\n","    for name, param in model.named_parameters():\n","        #parameters_to_prune[name]= param.data\n","        lst=name.split('.')            \n","        s=\".\"\n","        LOC=s.join([\"model\"]+lst[0:-1])\n","        #print(lst[-2])\n","        if(lst[0]=='modularity') and lst[-2][0:4]=='conv':\n","            basenets_to_prune.append(LOC)\n","            #print(LOC)\n","    basenets_to_prune=list(set(basenets_to_prune))\n","    for basenets in basenets_to_prune:\n","        exec(\"prune.ln_structured(\"+basenets+\", name='weight', amount=\"+str(pruning_rate)+\", n=2, dim=0)\")\n","\n","def remove_structured_pruning(model): \n","    \"\"\"Acts on all BaseNets differently!\"\"\"\n","    basenets_to_prune=[]\n","    for name, param in model.named_parameters():\n","        #parameters_to_prune[name]= param.data\n","        lst=name.split('.')            \n","        s=\".\"\n","        LOC=s.join([\"model\"]+lst[0:-1])\n","        #print(lst[-2])\n","        if(lst[0]=='modularity') and lst[-2][0:4]=='conv':\n","            basenets_to_prune.append(LOC)\n","            print(LOC)\n","    basenets_to_prune=list(set(basenets_to_prune))\n","    for basenets in basenets_to_prune: \n","        exec(\"prune.remove(\"+basenets+\",'weight')\")\n","\n","\n","def randomize_pruning(model,ranmodel):\n","    \"\"\"WORKS do it only for modularity though. Although 0.8*random1 + 0.2*random2 is still random..!\"\"\"\n","    beta = 0.2 #The interpolation parameter    \n","    dict1=model.modularity.state_dict()\n","    dict2=ranmodel.modularity.state_dict()\n","    dict3={}\n","    #print(dict1)\n","    #print(dict1.keys())\n","    for key in dict1.keys(): \n","        dict3[key]=beta*(dict2[key])+(1-beta)*dict1[key]\n","    #print(dict3)\n","    model.modularity.load_state_dict(dict3)\n","    return model\n","            \n","    #parameter_tuple=tuple(list(parameters_to_prune.items()))\n","    #print(parameter_tuple)\n","    #for item in parameter_tuple: \n","        \n","def create_graph(model,inp):\n","    nput = torch.randn(1, *inp)\n","    #transforms = [\n","        # Fold Conv, BN, RELU layers into one\n","        #hl.transforms.Fold(\"Transpose > MatMul > Add > Relu\", \"FCLayer\",name=\"FCLayer\"),\n","        # Fold repeated blocks\n","       #  hl.transforms.FoldDuplicates(),]\n","#     hl.build_graph(model, nput,transforms=transforms).save(\"newone\",format=\"pdf\")\n","    hl.build_graph(model, nput).save(\"newone\",format=\"pdf\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHuKZT6lMwXF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1594552249547,"user_tz":240,"elapsed":30604,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"88714e06-7340-438c-a847-7a7111c1fd7a"},"source":["%cd gdrive/My\\ Drive/CSNModels/DeepLab/\n","!ls"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/CSNModels/DeepLab\n","Data\t     DeepLabCSN  mypath.py    run\tutils\n","dataloaders  modeling\t __pycache__  train.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kNzM89lQJ10W","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552250163,"user_tz":240,"elapsed":31193,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["import argparse\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","from dataloaders import make_data_loader\n","from modeling.sync_batchnorm.replicate import patch_replication_callback\n","from modeling.deeplab import *\n","from utils.loss import SegmentationLosses\n","from utils.calculate_weights import calculate_weigths_labels\n","from utils.lr_scheduler import LR_Scheduler\n","from utils.saver import Saver\n","from utils.summaries import TensorboardSummary\n","from utils.metrics import Evaluator\n","import sys\n","class Trainer(object):\n","    def __init__(self, args):#,model):\n","        self.args = args\n","\n","        # Define Saver\n","        self.saver = Saver(args)\n","        self.saver.save_experiment_config()\n","        # Define Tensorboard Summary\n","        self.summary = TensorboardSummary(self.saver.experiment_dir)\n","        self.writer = self.summary.create_summary()\n","        \n","        # Define Dataloader\n","        kwargs = {'num_workers': args.workers, 'pin_memory': True}\n","        self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n","        #backbone = model\n","        # Define network\n","        model = DeepLab(num_classes=self.nclass,\n","                        backbone=args.backbone,\n","                        output_stride=args.out_stride,\n","                        sync_bn=args.sync_bn,\n","                        freeze_bn=args.freeze_bn)\n","\n","        train_params = [{'params': model.get_1x_lr_params(), 'lr': args.lr},\n","                        {'params': model.get_10x_lr_params(), 'lr': args.lr * 10}]\n","\n","        # Define Optimizer\n","        optimizer = torch.optim.SGD(train_params, momentum=args.momentum,\n","                                    weight_decay=args.weight_decay, nesterov=args.nesterov)\n","\n","        # Define Criterion\n","        # whether to use class balanced weights\n","        if args.use_balanced_weights:\n","            classes_weights_path = os.path.join(Path.db_root_dir(args.dataset), args.dataset+'_classes_weights.npy')\n","            if os.path.isfile(classes_weights_path):\n","                weight = np.load(classes_weights_path)\n","            else:\n","                weight = calculate_weigths_labels(args.dataset, self.train_loader, self.nclass)\n","            weight = torch.from_numpy(weight.astype(np.float32))\n","        else:\n","            weight = None\n","        self.criterion = SegmentationLosses(weight=weight, cuda=args.cuda).build_loss(mode=args.loss_type)\n","        self.model, self.optimizer = model, optimizer\n","        \n","        # Define Evaluator\n","        self.evaluator = Evaluator(self.nclass)\n","        # Define lr scheduler\n","        self.scheduler = LR_Scheduler(args.lr_scheduler, args.lr,\n","                                            args.epochs, len(self.train_loader))\n","\n","        # Using cuda\n","        if args.cuda:\n","            self.model = torch.nn.DataParallel(self.model, device_ids=self.args.gpu_ids)\n","            patch_replication_callback(self.model)\n","            self.model = self.model.cuda()\n","\n","        # Resuming checkpoint\n","        self.best_pred = 0.0\n","        if args.resume is not None:\n","            if not os.path.isfile(args.resume):\n","                raise RuntimeError(\"=> no checkpoint found at '{}'\" .format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint['epoch']\n","            if args.cuda:\n","                self.model.module.load_state_dict(checkpoint['state_dict'])\n","            else:\n","                self.model.load_state_dict(checkpoint['state_dict'])\n","            if not args.ft:\n","                self.optimizer.load_state_dict(checkpoint['optimizer'])\n","            self.best_pred = checkpoint['best_pred']\n","            print(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(args.resume, checkpoint['epoch']))\n","\n","        # Clear start epoch if fine-tuning\n","        if args.ft:\n","            args.start_epoch = 0\n","\n","    def training(self, epoch):\n","        train_loss = 0.0\n","        self.model.train()\n","        tbar = tqdm(self.train_loader)\n","        num_img_tr = len(self.train_loader)\n","        for i, sample in enumerate(tbar):\n","            image, target = sample['image'], sample['label']\n","            if self.args.cuda:\n","                image, target = image.cuda(), target.cuda()\n","            self.scheduler(self.optimizer, i, epoch, self.best_pred)\n","            self.optimizer.zero_grad()\n","            output = self.model(image)\n","            loss = self.criterion(output, target)\n","            loss.backward()\n","            self.optimizer.step()\n","            train_loss += loss.item()\n","            tbar.set_description('Train loss: %.3f' % (train_loss / (i + 1)))\n","            self.writer.add_scalar('train/total_loss_iter', loss.item(), i + num_img_tr * epoch)\n","\n","            # Show 10 * 3 inference results each epoch\n","            if i % (num_img_tr // 10) == 0:\n","                global_step = i + num_img_tr * epoch\n","                #print(\"I was here!!\")\n","                self.summary.visualize_image(self.writer, self.args.dataset, image, target, output, global_step)\n","\n","        self.writer.add_scalar('train/total_loss_epoch', train_loss, epoch)\n","        print('[Epoch: %d, numImages: %5d]' % (epoch, i * self.args.batch_size + image.data.shape[0]))\n","        print('Loss: %.3f' % train_loss)\n","\n","        if self.args.no_val:\n","            # save checkpoint every epoch\n","            is_best = False\n","            self.saver.save_checkpoint({\n","                'epoch': epoch + 1,\n","                'state_dict': self.model.module.state_dict(),\n","                'optimizer': self.optimizer.state_dict(),\n","                'best_pred': self.best_pred,\n","            }, is_best)\n","\n","\n","    def validation(self,epoch,loader='val'):\n","        self.model.eval()\n","        self.evaluator.reset()\n","        if(loader==\"val\"):\n","            tbar = tqdm(self.val_loader, desc='\\r')\n","        elif(loader==\"test\"):\n","            print('TEST RESULTS ARE BELOW::::::::::::::::::::::::::::')\n","            tbar = tqdm(self.test_loader, desc='\\r')\n","        test_loss = 0.0\n","        for i, sample in enumerate(tbar):\n","            image, target = sample['image'], sample['label']\n","            if self.args.cuda:\n","                image, target = image.cuda(), target.cuda()\n","            with torch.no_grad():\n","                output = self.model(image)\n","            loss = self.criterion(output, target)\n","            test_loss += loss.item()\n","            tbar.set_description('Test loss: %.3f' % (test_loss / (i + 1)))\n","            pred = output.data.cpu().numpy()\n","            target = target.cpu().numpy()\n","            pred = np.argmax(pred, axis=1)\n","            # Add batch sample into evaluator\n","            self.evaluator.add_batch(target, pred)\n","\n","        # Fast test during the training\n","        Acc = self.evaluator.Pixel_Accuracy()\n","        Acc_class = self.evaluator.Pixel_Accuracy_Class()\n","        mIoU,IoU = self.evaluator.Mean_Intersection_over_Union()\n","        FWIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()\n","        self.writer.add_scalar('val/total_loss_epoch', test_loss, epoch)\n","        self.writer.add_scalar('val/mIoU', mIoU, epoch)\n","        self.writer.add_scalar('val/Acc', Acc, epoch)\n","        self.writer.add_scalar('val/Acc_class', Acc_class, epoch)\n","        self.writer.add_scalar('val/fwIoU', FWIoU, epoch)\n","        print('Validation:')\n","        print('[Epoch: %d, numImages: %5d]' % (epoch, i * self.args.batch_size + image.data.shape[0]))\n","        print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n","        print(\"Classwise_IoU:\")\n","        print(IoU)\n","        print('Loss: %.3f' % test_loss)\n","        print(self.evaluator.confusion_matrix)\n","        if(loader=='val'):\n","            new_pred = mIoU\n","            if new_pred > self.best_pred:\n","                is_best = True\n","                self.best_pred = new_pred\n","                self.saver.save_checkpoint({\n","                    'epoch': epoch + 1,\n","                    'state_dict': self.model.module.state_dict(),\n","                    'optimizer': self.optimizer.state_dict(),\n","                    'best_pred': self.best_pred,\n","                }, is_best)\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnrZAiTOL_al","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594552250473,"user_tz":240,"elapsed":31480,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["def main(model):    \n","    parser = argparse.ArgumentParser(description=\"PyTorch DeeplabV3Plus Training\")\n","    parser.add_argument('--backbone', type=str, default='resnet',\n","                        choices=['resnet', 'xception', 'drn', 'mobilenet', 'csn'],\n","                        help='backbone name (default: resnet)')\n","    parser.add_argument('--out-stride', type=int, default=16,\n","                        help='network output stride (default: 8)')\n","    parser.add_argument('--dataset', type=str, default='marsh',\n","                        choices=['pascal', 'coco', 'cityscapes','marsh'],\n","                        help='dataset name (default: pascal)')\n","    parser.add_argument('--use-sbd', action='store_true', default=True,\n","                        help='whether to use SBD dataset (default: True)')\n","    parser.add_argument('--workers', type=int, default=4,\n","                        metavar='N', help='dataloader threads')\n","    parser.add_argument('--base-size', type=int, default=513,\n","                        help='base image size')\n","    parser.add_argument('--crop-size', type=int, default=513,\n","                        help='crop image size')\n","    parser.add_argument('--sync-bn', type=bool, default=None,\n","                        help='whether to use sync bn (default: auto)')\n","    parser.add_argument('--freeze-bn', type=bool, default=False,\n","                        help='whether to freeze bn parameters (default: False)')\n","    parser.add_argument('--loss-type', type=str, default='ce',\n","                        choices=['ce', 'focal'],\n","                        help='loss func type (default: ce)')\n","    # training hyper params\n","    parser.add_argument('--epochs', type=int, default=None, metavar='N',\n","                        help='number of epochs to train (default: auto)')\n","    parser.add_argument('--start_epoch', type=int, default=0,\n","                        metavar='N', help='start epochs (default:0)')\n","    parser.add_argument('--batch-size', type=int, default=2,\n","                        metavar='N', help='input batch size for \\\n","                                training (default: auto)')\n","    parser.add_argument('--test-batch-size', type=int, default=None,\n","                        metavar='N', help='input batch size for \\\n","                                testing (default: auto)')\n","    parser.add_argument('--use-balanced-weights', action='store_true', default=False,\n","                        help='whether to use balanced weights (default: False)')\n","    # optimizer params\n","    parser.add_argument('--lr', type=float, default=None, metavar='LR',\n","                        help='learning rate (default: auto)')\n","    parser.add_argument('--lr-scheduler', type=str, default='poly',\n","                        choices=['poly', 'step', 'cos'],\n","                        help='lr scheduler mode: (default: poly)')\n","    parser.add_argument('--momentum', type=float, default=0.9,\n","                        metavar='M', help='momentum (default: 0.9)')\n","    parser.add_argument('--weight-decay', type=float, default=5e-4,\n","                        metavar='M', help='w-decay (default: 5e-4)')\n","    parser.add_argument('--nesterov', action='store_true', default=False,\n","                        help='whether use nesterov (default: False)')\n","    # cuda, seed and logging\n","    parser.add_argument('--no-cuda', action='store_true', default=\n","                        False, help='disables CUDA training')\n","    parser.add_argument('--gpu-ids', type=str, default='0',\n","                        help='use which gpu to train, must be a \\\n","                        comma-separated list of integers only (default=0)')\n","    parser.add_argument('--seed', type=int, default=1, metavar='S',\n","                        help='random seed (default: 1)')\n","    # checking point\n","    parser.add_argument('--resume', type=str, default=None,\n","                        help='put the path to resuming file if needed')\n","    parser.add_argument('--checkname', type=str, default=None,\n","                        help='set the checkpoint name')\n","    # finetuning pre-trained models\n","    parser.add_argument('--ft', action='store_true', default=False,\n","                        help='finetuning on a different dataset')\n","    # evaluation option\n","    parser.add_argument('--eval-interval', type=int, default=1,\n","                        help='evaluuation interval (default: 1)')\n","    parser.add_argument('--no-val', action='store_true', default=False,\n","                        help='skip validation during training')\n","\n","    args = parser.parse_args()\n","    args.cuda = not args.no_cuda and torch.cuda.is_available()\n","    if args.cuda:\n","        try:\n","            args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n","        except ValueError:\n","            raise ValueError('Argument --gpu_ids must be a comma-separated list of integers only')\n","\n","    if args.sync_bn is None:\n","        if args.cuda and len(args.gpu_ids) > 1:\n","            args.sync_bn = True\n","        else:\n","            args.sync_bn = False\n","\n","    # default settings for epochs, batch_size and lr\n","    if args.epochs is None:\n","        epoches = {\n","            'coco': 30,\n","            'cityscapes': 200,\n","            'pascal': 50,\n","\t\t\t'marsh' : 100,\n","        }\n","        args.epochs = epoches[args.dataset.lower()]\n","\n","    if args.batch_size is None:\n","        args.batch_size = 4 * len(args.gpu_ids)\n","\n","    if args.test_batch_size is None:\n","        args.test_batch_size = args.batch_size\n","\n","    if args.lr is None:\n","        lrs = {\n","            'coco': 0.1,\n","            'cityscapes': 0.01,\n","            'pascal': 0.007,\n","\t\t\t'marsh' : 0.01,\n","        }\n","        args.lr = lrs[args.dataset.lower()] / (4 * len(args.gpu_ids)) * args.batch_size\n","\n","\n","    if args.checkname is None:\n","        args.checkname = 'deeplab-'+str(args.backbone)\n","    args.backbone=model\n","    print(args)\n","    print('This will also print testing data results.. hopefully...')\n","    torch.manual_seed(args.seed)\n","    trainer = Trainer(args)\n","    print('Starting Epoch:', trainer.args.start_epoch)\n","    print('Total Epoches:', trainer.args.epochs)\n","    for epoch in range(trainer.args.start_epoch, trainer.args.epochs):\n","        trainer.training(epoch)\n","        if not trainer.args.no_val and epoch % args.eval_interval == (args.eval_interval - 1):\n","            trainer.validation(epoch)\n","    trainer.validation(0,loader='test')\n","    \n","    trainer.writer.close()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nQdxSmlMgtL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594573788934,"user_tz":240,"elapsed":21569928,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}},"outputId":"3c0e3fa5-8aab-4d55-f788-56f0da53594a"},"source":["if __name__ == \"__main__\":\n","    from Bio import SeqIO\n","    path = '/path/to/sequences.txt'\n","    sequences = ['']\n","    sys.argv = sequences\n","    stages=['base_model', 'exp_expansion', 'linear_expansion', 'reload']\n","    path=F\"/content/gdrive/My Drive/CSNModels/DeepLab/DeepLabCSN\"\n","    torch.cuda.empty_cache()\n","    #first was without pruning. This one is without randomized pruning/ but with structured pruning. Lets see/ We have test results of this here too. \n","    \n","    # model=CompositionalSparseNetCNN(exp_level=1, exponential_cutoff=1,expo_depth=2,expo_width=2,stage=stages[0],\n","    #                         prev_path=path, channels_width=128)\n","    \n","    # main(model)\n","    # structured_pruning(model, pruning_rate=0.5)\n","    # remove_structured_pruning(model)\n","    # torch.save(model.state_dict(),path+\"/level1.pth\")\n","\n","    # del model\n","    # model=CompositionalSparseNetCNN(exp_level=2, exponential_cutoff=2,expo_depth=2,expo_width=2,stage=stages[0],\n","    #                         prev_path=path, channels_width=256)\n","    \n","    # main(model)\n","    # structured_pruning(model, pruning_rate=0.5)\n","    # remove_structured_pruning(model)\n","    # torch.save(model.state_dict(),path+\"/level2.pth\")\n","    # del model\n","    torch.cuda.empty_cache()\n","    model=CompositionalSparseNetCNN(exp_level=3, exponential_cutoff=2,expo_depth=2,expo_width=2,stage=stages[0],\n","                            prev_path=path, channels_width=256)\n","    main(model)\n","    structured_pruning(model, pruning_rate=0.5)\n","    remove_structured_pruning(model)\n","    torch.save(model.state_dict(),path+\"/level3base.pth\")\n","    # del model\n","    # torch.cuda.empty_cache()\n","    # model=CompositionalSparseNetCNN(exp_level=4, exponential_cutoff=2,expo_depth=2,expo_width=2,stage=stages[2],\n","    #                         prev_path=path, channels_width=256)\n","    # main(model)\n","    # structured_pruning(model, pruning_rate=0.5)\n","    # remove_structured_pruning(model)\n","    # torch.save(model.state_dict(),path+\"/level4.pth\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["64\n","Namespace(backbone=CompositionalSparseNetCNN(\n","  (relu): ReLU()\n","  (downsamp1): Sequential(\n","    (0): Conv2d(3, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (conv1): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (modularity): ModularityCNN(\n","    (module0): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module1): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (interconnection0): InterconnectionCNN(\n","      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (module2): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module3): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (interconnection1): InterconnectionCNN(\n","      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (module4): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module5): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (interconnection2): InterconnectionCNN(\n","      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (module6): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module7): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (interconnection3): InterconnectionCNN(\n","      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (module8): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module9): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (interconnection4): InterconnectionCNN(\n","      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (module10): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (module11): ModularityCNN(\n","      (module0): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module1): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (interconnection0): InterconnectionCNN(\n","        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module2): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (module3): BaseNetCNN(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","  )\n","  (downsamp2): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(1024, 2048, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","  )\n","), base_size=513, batch_size=2, checkname='deeplab-resnet', crop_size=513, cuda=True, dataset='marsh', epochs=100, eval_interval=1, freeze_bn=False, ft=False, gpu_ids=[0], loss_type='ce', lr=0.005, lr_scheduler='poly', momentum=0.9, nesterov=False, no_cuda=False, no_val=False, out_stride=16, resume=None, seed=1, start_epoch=0, sync_bn=False, test_batch_size=2, use_balanced_weights=False, use_sbd=True, weight_decay=0.0005, workers=4)\n","This will also print testing data results.. hopefully...\n","this ran....\n","Using poly LR Scheduler!\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting Epoch: 0\n","Total Epoches: 100\n","\n","=>Epoches 0, learning rate = 0.0050,                 previous best = 0.0000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n","Train loss: 0.506: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 0, numImages:   362]\n","Loss: 91.584\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.446: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 0, numImages:    52]\n","Acc:0.7259133279960202, Acc_class:0.1621725788013839, mIoU:0.11565220169128836, fwIoU: 0.5701071122294972\n","Classwise_IoU:\n","[7.78144875e-01 0.00000000e+00 2.61762173e-01 3.54829641e-05\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.27284151e-04\n"," 0.00000000e+00]\n","Loss: 11.590\n","[[9.100437e+06 0.000000e+00 3.597090e+05 1.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.170000e+02 5.100000e+02]\n"," [1.063700e+04 0.000000e+00 3.321700e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.000000e+00 0.000000e+00]\n"," [8.414760e+05 0.000000e+00 8.327440e+05 6.490000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.400000e+01 1.613000e+03]\n"," [1.852430e+05 0.000000e+00 5.463130e+05 2.600000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.070000e+02 0.000000e+00]\n"," [9.719000e+04 0.000000e+00 2.769700e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.060000e+02 5.400000e+02]\n"," [5.293000e+05 0.000000e+00 1.168030e+05 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.900000e+01 7.416000e+03]\n"," [1.754800e+04 0.000000e+00 6.203000e+03 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [5.417630e+05 0.000000e+00 2.788900e+05 7.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.630000e+02 0.000000e+00]\n"," [1.071100e+04 0.000000e+00 1.359720e+05 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.300000e+01 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 1, learning rate = 0.0050,                 previous best = 0.1157\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.416: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 1, numImages:   362]\n","Loss: 75.353\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.436: 100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 1, numImages:    52]\n","Acc:0.7351437230887318, Acc_class:0.17052917751927513, mIoU:0.13224110006962592, fwIoU: 0.5725661875344495\n","Classwise_IoU:\n","[7.62617693e-01 0.00000000e+00 3.21804657e-01 0.00000000e+00\n"," 8.84693616e-03 1.47516381e-04 0.00000000e+00 9.67530979e-02\n"," 0.00000000e+00]\n","Loss: 11.346\n","[[9.285646e+06 0.000000e+00 7.577000e+04 0.000000e+00 6.346300e+04\n","  1.986000e+03 0.000000e+00 3.430900e+04 0.000000e+00]\n"," [1.587900e+04 0.000000e+00 2.020800e+04 0.000000e+00 0.000000e+00\n","  5.200000e+01 0.000000e+00 7.719000e+03 0.000000e+00]\n"," [9.140430e+05 0.000000e+00 6.520200e+05 0.000000e+00 3.120700e+04\n","  8.000000e+01 0.000000e+00 7.914600e+04 0.000000e+00]\n"," [4.152750e+05 0.000000e+00 7.468500e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.421290e+05 0.000000e+00]\n"," [1.055830e+05 0.000000e+00 1.322400e+04 0.000000e+00 2.240000e+03\n","  4.199000e+03 0.000000e+00 4.870000e+02 0.000000e+00]\n"," [5.607760e+05 0.000000e+00 5.900400e+04 0.000000e+00 3.279200e+04\n","  9.800000e+01 0.000000e+00 8.680000e+02 0.000000e+00]\n"," [1.749600e+04 0.000000e+00 2.634000e+03 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.621000e+03 0.000000e+00]\n"," [6.429660e+05 0.000000e+00 5.369700e+04 0.000000e+00 0.000000e+00\n","  4.478000e+03 0.000000e+00 1.202820e+05 0.000000e+00]\n"," [4.282500e+04 0.000000e+00 5.041800e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.348300e+04 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 2, learning rate = 0.0049,                 previous best = 0.1322\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.390: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 2, numImages:   362]\n","Loss: 70.676\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.404: 100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 2, numImages:    52]\n","Acc:0.7492330900559073, Acc_class:0.21037599537293827, mIoU:0.15088076014707064, fwIoU: 0.5884556234838477\n","Classwise_IoU:\n","[7.79339405e-01 0.00000000e+00 2.70872896e-01 3.07345295e-01\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.69245963e-04\n"," 0.00000000e+00]\n","Loss: 10.507\n","[[9.318043e+06 0.000000e+00 2.058600e+04 1.155380e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.007000e+03 0.000000e+00]\n"," [7.110000e+03 0.000000e+00 1.080700e+04 2.540200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.390000e+02 0.000000e+00]\n"," [8.953430e+05 0.000000e+00 4.791300e+05 2.680840e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.393900e+04 0.000000e+00]\n"," [2.163480e+05 0.000000e+00 4.338800e+04 4.555850e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.676800e+04 0.000000e+00]\n"," [1.213180e+05 0.000000e+00 2.017000e+03 2.022000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.760000e+02 0.000000e+00]\n"," [6.267850e+05 0.000000e+00 4.101000e+03 4.377000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.827500e+04 0.000000e+00]\n"," [1.754900e+04 0.000000e+00 1.650000e+02 6.037000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [5.902180e+05 0.000000e+00 9.461000e+03 2.214060e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.380000e+02 0.000000e+00]\n"," [2.049000e+04 0.000000e+00 1.816000e+03 1.073680e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.705200e+04 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 3, learning rate = 0.0049,                 previous best = 0.1509\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.365: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 3, numImages:   362]\n","Loss: 66.055\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.392: 100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 3, numImages:    52]\n","Acc:0.7571341258629655, Acc_class:0.24320707483618575, mIoU:0.17039232793268622, fwIoU: 0.60881693348435\n","Classwise_IoU:\n","[0.78624543 0.         0.36237758 0.34668677 0.         0.\n"," 0.         0.03822118 0.        ]\n","Loss: 10.191\n","[[9.013012e+06 0.000000e+00 2.832870e+05 1.463680e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.850700e+04 0.000000e+00]\n"," [6.579000e+03 0.000000e+00 5.763000e+03 3.129100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.250000e+02 0.000000e+00]\n"," [6.672870e+05 0.000000e+00 7.804160e+05 2.287200e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.300000e+01 0.000000e+00]\n"," [1.843690e+05 0.000000e+00 1.169500e+04 5.351450e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.800000e+02 0.000000e+00]\n"," [9.509600e+04 0.000000e+00 1.726400e+04 2.642000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.073100e+04 0.000000e+00]\n"," [5.107980e+05 0.000000e+00 1.345840e+05 5.876000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.280000e+03 0.000000e+00]\n"," [1.659700e+04 0.000000e+00 2.290000e+02 6.925000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [5.022140e+05 0.000000e+00 2.293500e+04 2.635910e+05 0.000000e+00\n","  3.600000e+01 0.000000e+00 3.264700e+04 0.000000e+00]\n"," [1.924300e+04 0.000000e+00 1.346000e+03 1.260960e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.100000e+01 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 4, learning rate = 0.0048,                 previous best = 0.1704\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.373: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 4, numImages:   362]\n","Loss: 67.496\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.422: 100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 4, numImages:    52]\n","Acc:0.7425946971191661, Acc_class:0.21130516893760365, mIoU:0.14318671357413504, fwIoU: 0.5811508412478475\n","Classwise_IoU:\n","[0.78181855 0.         0.1942328  0.29581706 0.         0.\n"," 0.         0.01681201 0.        ]\n","Loss: 10.969\n","[[9.294291e+06 0.000000e+00 3.811900e+04 1.240960e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.668000e+03 0.000000e+00]\n"," [9.851000e+03 0.000000e+00 0.000000e+00 3.380900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.980000e+02 0.000000e+00]\n"," [8.953970e+05 0.000000e+00 3.432620e+05 4.377420e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.500000e+01 0.000000e+00]\n"," [2.213780e+05 0.000000e+00 0.000000e+00 5.107110e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [1.114940e+05 0.000000e+00 7.005000e+03 1.685000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.549000e+03 0.000000e+00]\n"," [6.041950e+05 0.000000e+00 4.270600e+04 6.605000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.200000e+01 0.000000e+00]\n"," [1.723000e+04 0.000000e+00 2.990000e+02 6.222000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [5.465750e+05 0.000000e+00 2.646000e+03 2.582150e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.398700e+04 0.000000e+00]\n"," [2.074700e+04 0.000000e+00 0.000000e+00 1.259790e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]]\n","\n","=>Epoches 5, learning rate = 0.0048,                 previous best = 0.1704\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.361: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 5, numImages:   362]\n","Loss: 65.426\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.402: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 5, numImages:    52]\n","Acc:0.7351906364936015, Acc_class:0.20420283831644342, mIoU:0.14480472473310008, fwIoU: 0.5727537565155059\n","Classwise_IoU:\n","[7.64834691e-01 0.00000000e+00 2.16885551e-01 2.89484271e-01\n"," 0.00000000e+00 4.35566695e-04 0.00000000e+00 3.16024428e-02\n"," 0.00000000e+00]\n","Loss: 10.448\n","[[9.176287e+06 0.000000e+00 1.773080e+05 9.699700e+04 0.000000e+00\n","  1.910000e+02 0.000000e+00 1.039100e+04 0.000000e+00]\n"," [7.278000e+03 0.000000e+00 4.967000e+03 3.139000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.230000e+02 0.000000e+00]\n"," [9.695770e+05 0.000000e+00 4.373200e+05 2.693100e+05 0.000000e+00\n","  8.900000e+01 0.000000e+00 2.000000e+02 0.000000e+00]\n"," [2.809860e+05 0.000000e+00 2.956100e+04 4.202200e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.322000e+03 0.000000e+00]\n"," [1.033640e+05 0.000000e+00 9.097000e+03 1.354000e+03 0.000000e+00\n","  5.020000e+02 0.000000e+00 1.141600e+04 0.000000e+00]\n"," [5.506500e+05 0.000000e+00 9.780600e+04 3.595000e+03 0.000000e+00\n","  2.850000e+02 0.000000e+00 1.202000e+03 0.000000e+00]\n"," [1.704700e+04 0.000000e+00 1.850000e+02 6.519000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]\n"," [5.793550e+05 0.000000e+00 1.193500e+04 2.033170e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.681600e+04 0.000000e+00]\n"," [2.830800e+04 0.000000e+00 9.008000e+03 1.070450e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.365000e+03 0.000000e+00]]\n","\n","=>Epoches 6, learning rate = 0.0047,                 previous best = 0.1704\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.363: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 6, numImages:   362]\n","Loss: 65.619\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.399: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 6, numImages:    52]\n","Acc:0.753995458314736, Acc_class:0.23800519953897503, mIoU:0.17760629345355358, fwIoU: 0.5934450761536962\n","Classwise_IoU:\n","[7.69327043e-01 0.00000000e+00 3.17864112e-01 3.73624399e-01\n"," 0.00000000e+00 5.16037137e-04 0.00000000e+00 2.30499867e-02\n"," 1.14075064e-01]\n","Loss: 10.386\n","[[9.174335e+06 0.000000e+00 1.992890e+05 7.971600e+04 0.000000e+00\n","  1.058000e+03 0.000000e+00 6.341000e+03 4.350000e+02]\n"," [1.091800e+04 0.000000e+00 1.084000e+04 1.642200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.080000e+02 5.470000e+03]\n"," [8.843620e+05 0.000000e+00 6.449110e+05 1.278910e+05 0.000000e+00\n","  8.840000e+02 0.000000e+00 8.420000e+02 1.760600e+04]\n"," [2.566770e+05 0.000000e+00 1.110300e+04 4.594250e+05 0.000000e+00\n","  4.000000e+00 0.000000e+00 2.610000e+02 4.619000e+03]\n"," [1.052780e+05 0.000000e+00 8.256000e+03 1.360000e+03 0.000000e+00\n","  5.388000e+03 0.000000e+00 5.451000e+03 0.000000e+00]\n"," [5.515540e+05 0.000000e+00 9.810300e+04 3.369000e+03 0.000000e+00\n","  3.420000e+02 0.000000e+00 1.700000e+02 0.000000e+00]\n"," [1.892800e+04 0.000000e+00 1.511000e+03 3.217000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.500000e+01 0.000000e+00]\n"," [6.142820e+05 0.000000e+00 1.973100e+04 1.660110e+05 0.000000e+00\n","  1.871000e+03 0.000000e+00 1.928000e+04 2.480000e+02]\n"," [2.197000e+04 0.000000e+00 3.560000e+03 9.956900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.652000e+03 1.997500e+04]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 7, learning rate = 0.0047,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.352: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 7, numImages:   362]\n","Loss: 63.659\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.426: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 7, numImages:    52]\n","Acc:0.7466550450032547, Acc_class:0.24578913041442055, mIoU:0.17109158448447306, fwIoU: 0.5990022168976896\n","Classwise_IoU:\n","[0.77023394 0.         0.36306876 0.36613666 0.         0.\n"," 0.         0.0403849  0.        ]\n","Loss: 11.078\n","[[8.744298e+06 0.000000e+00 5.518030e+05 1.480570e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.701600e+04 0.000000e+00]\n"," [5.812000e+03 0.000000e+00 2.025400e+04 1.753600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.560000e+02 0.000000e+00]\n"," [5.986760e+05 0.000000e+00 9.354020e+05 1.419350e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.830000e+02 0.000000e+00]\n"," [1.715340e+05 0.000000e+00 5.613900e+04 5.036510e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.650000e+02 0.000000e+00]\n"," [9.532400e+04 0.000000e+00 1.746400e+04 2.743000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.020200e+04 0.000000e+00]\n"," [5.053630e+05 0.000000e+00 1.398300e+05 7.268000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.077000e+03 0.000000e+00]\n"," [1.598900e+04 0.000000e+00 3.054000e+03 4.703000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.000000e+00 0.000000e+00]\n"," [4.826370e+05 0.000000e+00 6.721900e+04 2.371020e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.446500e+04 0.000000e+00]\n"," [1.627300e+04 0.000000e+00 4.411800e+04 8.414900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.186000e+03 0.000000e+00]]\n","\n","=>Epoches 8, learning rate = 0.0046,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.343: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 8, numImages:   362]\n","Loss: 62.172\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.435: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 8, numImages:    52]\n","Acc:0.7320696528144974, Acc_class:0.2218367796417637, mIoU:0.14773877585917292, fwIoU: 0.5825911559815379\n","Classwise_IoU:\n","[7.76194175e-01 0.00000000e+00 2.33578152e-01 2.84361582e-01\n"," 0.00000000e+00 9.18023556e-05 0.00000000e+00 3.54232703e-02\n"," 0.00000000e+00]\n","Loss: 11.323\n","[[8.972859e+06 0.000000e+00 2.300590e+05 2.441660e+05 0.000000e+00\n","  4.000000e+01 0.000000e+00 1.405000e+04 0.000000e+00]\n"," [7.053000e+03 0.000000e+00 3.050000e+03 3.340000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.750000e+02 8.000000e+01]\n"," [8.348480e+05 0.000000e+00 4.877280e+05 3.474920e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.023000e+03 2.405000e+03]\n"," [1.626160e+05 0.000000e+00 4.146300e+04 5.273750e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.180000e+02 1.700000e+01]\n"," [1.023840e+05 0.000000e+00 9.331000e+03 4.978000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.040000e+03 0.000000e+00]\n"," [5.394740e+05 0.000000e+00 1.008630e+05 1.291200e+04 0.000000e+00\n","  6.000000e+01 0.000000e+00 2.290000e+02 0.000000e+00]\n"," [1.523400e+04 0.000000e+00 1.490000e+02 8.281000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.700000e+01 0.000000e+00]\n"," [4.226940e+05 0.000000e+00 6.024000e+03 3.624680e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.019600e+04 4.100000e+01]\n"," [1.459300e+04 0.000000e+00 2.063700e+04 1.088070e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.689000e+03 0.000000e+00]]\n","\n","=>Epoches 9, learning rate = 0.0046,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.347: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 9, numImages:   362]\n","Loss: 62.751\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.400: 100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 9, numImages:    52]\n","Acc:0.7496531915583932, Acc_class:0.2319492420088596, mIoU:0.17150871839670048, fwIoU: 0.595151572400385\n","Classwise_IoU:\n","[0.76865965 0.         0.31260835 0.3552809  0.         0.\n"," 0.         0.10702956 0.        ]\n","Loss: 10.409\n","[[9.037226e+06 0.000000e+00 3.303800e+05 7.467600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.889200e+04 0.000000e+00]\n"," [1.183300e+04 0.000000e+00 5.697000e+03 2.384500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.483000e+03 0.000000e+00]\n"," [7.821310e+05 0.000000e+00 6.774470e+05 1.521070e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.481100e+04 0.000000e+00]\n"," [2.549320e+05 0.000000e+00 4.642000e+03 4.428850e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.963000e+04 0.000000e+00]\n"," [1.100930e+05 0.000000e+00 1.237100e+04 1.288000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.981000e+03 0.000000e+00]\n"," [5.279040e+05 0.000000e+00 1.220000e+05 3.266000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.680000e+02 0.000000e+00]\n"," [1.744000e+04 0.000000e+00 2.810000e+02 2.586000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.444000e+03 0.000000e+00]\n"," [5.718740e+05 0.000000e+00 1.368800e+04 1.345740e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.012870e+05 0.000000e+00]\n"," [1.974200e+04 0.000000e+00 1.524000e+03 1.221460e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.314000e+03 0.000000e+00]]\n","\n","=>Epoches 10, learning rate = 0.0045,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.334: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 10, numImages:   362]\n","Loss: 60.469\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.369: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 10, numImages:    52]\n","Acc:0.7676702043173778, Acc_class:0.2288836042872028, mIoU:0.17709240475195356, fwIoU: 0.6087611688243459\n","Classwise_IoU:\n","[0.77962829 0.         0.37163747 0.35836197 0.         0.\n"," 0.         0.08420391 0.        ]\n","Loss: 9.590\n","[[9.328272e+06 0.000000e+00 5.601500e+04 5.115700e+04 2.468000e+03\n","  0.000000e+00 0.000000e+00 2.326200e+04 0.000000e+00]\n"," [8.682000e+03 0.000000e+00 1.133100e+04 2.354800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.970000e+02 0.000000e+00]\n"," [8.612390e+05 0.000000e+00 6.793440e+05 1.140420e+05 7.210000e+02\n","  0.000000e+00 0.000000e+00 2.115000e+04 0.000000e+00]\n"," [2.831810e+05 0.000000e+00 2.097300e+04 4.225790e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.356000e+03 0.000000e+00]\n"," [1.056820e+05 0.000000e+00 5.441000e+03 9.640000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.364600e+04 0.000000e+00]\n"," [6.203240e+05 0.000000e+00 2.615900e+04 2.037000e+03 2.004000e+03\n","  0.000000e+00 0.000000e+00 3.014000e+03 0.000000e+00]\n"," [1.783400e+04 0.000000e+00 7.530000e+02 3.399000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.765000e+03 0.000000e+00]\n"," [5.832700e+05 0.000000e+00 2.949000e+04 1.334540e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.520900e+04 0.000000e+00]\n"," [2.363900e+04 0.000000e+00 1.317000e+03 1.185060e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.264000e+03 0.000000e+00]]\n","\n","=>Epoches 11, learning rate = 0.0045,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.325: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 11, numImages:   362]\n","Loss: 58.740\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.381: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 11, numImages:    52]\n","Acc:0.7428326986139646, Acc_class:0.1731500956871586, mIoU:0.13381192216014454, fwIoU: 0.5760855487868489\n","Classwise_IoU:\n","[0.7707939  0.         0.28796079 0.02087572 0.         0.05639023\n"," 0.         0.06828666 0.        ]\n","Loss: 9.910\n","[[9.352713e+06 0.000000e+00 7.378700e+04 3.328000e+03 1.170000e+02\n","  1.330300e+04 0.000000e+00 1.792600e+04 0.000000e+00]\n"," [1.324600e+04 0.000000e+00 3.002300e+04 7.000000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.190000e+02 0.000000e+00]\n"," [9.540430e+05 0.000000e+00 6.989580e+05 1.654000e+03 0.000000e+00\n","  8.383000e+03 0.000000e+00 1.345800e+04 0.000000e+00]\n"," [3.318590e+05 0.000000e+00 3.777440e+05 1.554500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.941000e+03 0.000000e+00]\n"," [1.054130e+05 0.000000e+00 2.316000e+03 3.000000e+00 0.000000e+00\n","  5.479000e+03 0.000000e+00 1.252200e+04 0.000000e+00]\n"," [5.795150e+05 0.000000e+00 3.257200e+04 4.800000e+01 1.100000e+02\n","  3.838500e+04 0.000000e+00 2.908000e+03 0.000000e+00]\n"," [1.985800e+04 0.000000e+00 2.442000e+03 4.960000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.550000e+02 0.000000e+00]\n"," [6.422080e+05 0.000000e+00 1.141960e+05 5.112000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.990700e+04 0.000000e+00]\n"," [2.655400e+04 0.000000e+00 1.176920e+05 1.845000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.350000e+02 0.000000e+00]]\n","\n","=>Epoches 12, learning rate = 0.0045,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.332: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 12, numImages:   362]\n","Loss: 60.014\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.455: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 12, numImages:    52]\n","Acc:0.7488636287240986, Acc_class:0.1965256805517456, mIoU:0.15301356878714756, fwIoU: 0.5909123645281056\n","Classwise_IoU:\n","[7.76203904e-01 0.00000000e+00 3.17923840e-01 1.80850550e-01\n"," 9.44589332e-03 0.00000000e+00 0.00000000e+00 9.26706971e-02\n"," 2.72355260e-05]\n","Loss: 11.841\n","[[9.216337e+06 0.000000e+00 1.940080e+05 2.980800e+04 6.201000e+03\n","  0.000000e+00 0.000000e+00 1.481500e+04 5.000000e+00]\n"," [8.358000e+03 0.000000e+00 2.763300e+04 6.791000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.076000e+03 0.000000e+00]\n"," [8.468660e+05 0.000000e+00 7.941480e+05 1.313300e+04 4.992000e+03\n","  0.000000e+00 0.000000e+00 1.735700e+04 0.000000e+00]\n"," [2.693550e+05 0.000000e+00 2.783820e+05 1.533940e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.082200e+04 1.360000e+02]\n"," [1.081310e+05 0.000000e+00 1.493500e+04 5.250000e+02 1.322000e+03\n","  0.000000e+00 0.000000e+00 8.200000e+02 0.000000e+00]\n"," [5.833760e+05 0.000000e+00 6.438600e+04 3.040000e+02 2.938000e+03\n","  0.000000e+00 0.000000e+00 2.534000e+03 0.000000e+00]\n"," [1.689300e+04 0.000000e+00 2.715000e+03 3.481000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.620000e+02 0.000000e+00]\n"," [5.564590e+05 0.000000e+00 1.381320e+05 4.390600e+04 9.100000e+01\n","  0.000000e+00 0.000000e+00 8.283500e+04 0.000000e+00]\n"," [2.299100e+04 0.000000e+00 1.012320e+05 1.814400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.355000e+03 4.000000e+00]]\n","\n","=>Epoches 13, learning rate = 0.0044,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.337: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 13, numImages:   362]\n","Loss: 60.947\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.645: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 13, numImages:    52]\n","Acc:0.7414347960669906, Acc_class:0.17806516293907027, mIoU:0.14305011686426125, fwIoU: 0.5654958331169235\n","Classwise_IoU:\n","[0.74769433 0.         0.27434118 0.14916876 0.         0.\n"," 0.         0.11624679 0.        ]\n","Loss: 16.763\n","[[9.399302e+06 0.000000e+00 4.396200e+04 4.911000e+03 4.270000e+02\n","  0.000000e+00 0.000000e+00 1.257200e+04 0.000000e+00]\n"," [1.675700e+04 0.000000e+00 1.200200e+04 8.303000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.796000e+03 0.000000e+00]\n"," [1.116258e+06 0.000000e+00 5.125080e+05 3.826000e+03 2.210000e+02\n","  0.000000e+00 0.000000e+00 4.368300e+04 0.000000e+00]\n"," [4.767900e+05 0.000000e+00 6.066700e+04 1.202330e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.439900e+04 0.000000e+00]\n"," [1.074120e+05 0.000000e+00 1.075300e+04 1.100000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.557000e+03 0.000000e+00]\n"," [6.459740e+05 0.000000e+00 7.318000e+03 0.000000e+00 1.700000e+02\n","  0.000000e+00 0.000000e+00 7.600000e+01 0.000000e+00]\n"," [1.954800e+04 0.000000e+00 2.810000e+02 1.518000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.404000e+03 0.000000e+00]\n"," [6.799540e+05 0.000000e+00 2.261900e+04 4.505000e+03 0.000000e+00\n","  1.000000e+01 0.000000e+00 1.143350e+05 0.000000e+00]\n"," [4.718200e+04 0.000000e+00 3.404300e+04 5.085700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.464400e+04 0.000000e+00]]\n","\n","=>Epoches 14, learning rate = 0.0044,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.323: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 14, numImages:   362]\n","Loss: 58.407\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.384: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 14, numImages:    52]\n","Acc:0.7489230377554991, Acc_class:0.18741971721758327, mIoU:0.13723897275921854, fwIoU: 0.5905543550429219\n","Classwise_IoU:\n","[0.78118864 0.         0.37255046 0.00573655 0.         0.00173218\n"," 0.         0.07394293 0.        ]\n","Loss: 9.971\n","[[9.107537e+06 0.000000e+00 3.438440e+05 5.710000e+02 0.000000e+00\n","  5.450000e+02 0.000000e+00 8.677000e+03 0.000000e+00]\n"," [9.403000e+03 0.000000e+00 3.406500e+04 4.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.860000e+02 0.000000e+00]\n"," [5.969340e+05 0.000000e+00 1.073031e+06 1.230000e+02 0.000000e+00\n","  1.500000e+01 0.000000e+00 6.393000e+03 0.000000e+00]\n"," [3.041910e+05 0.000000e+00 4.145110e+05 4.209000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.178000e+03 0.000000e+00]\n"," [1.040300e+05 0.000000e+00 1.512000e+04 0.000000e+00 0.000000e+00\n","  2.878000e+03 0.000000e+00 3.705000e+03 0.000000e+00]\n"," [5.241610e+05 0.000000e+00 1.280790e+05 0.000000e+00 0.000000e+00\n","  1.138000e+03 0.000000e+00 1.600000e+02 0.000000e+00]\n"," [1.864700e+04 0.000000e+00 4.599000e+03 2.800000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.770000e+02 0.000000e+00]\n"," [6.155310e+05 0.000000e+00 1.426190e+05 3.350000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.293800e+04 0.000000e+00]\n"," [2.449200e+04 0.000000e+00 1.208970e+05 5.660000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.710000e+02 0.000000e+00]]\n","\n","=>Epoches 15, learning rate = 0.0043,                 previous best = 0.1776\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.322: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 15, numImages:   362]\n","Loss: 58.249\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.384: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 15, numImages:    52]\n","Acc:0.7645704120516883, Acc_class:0.22433766599762858, mIoU:0.18072944112199701, fwIoU: 0.6102874642398692\n","Classwise_IoU:\n","[7.83246388e-01 0.00000000e+00 3.46957680e-01 2.60061373e-01\n"," 4.87958726e-04 0.00000000e+00 0.00000000e+00 1.99351610e-01\n"," 3.64599605e-02]\n","Loss: 9.987\n","[[9.314153e+06 0.000000e+00 6.242500e+04 3.112900e+04 1.660400e+04\n","  0.000000e+00 0.000000e+00 3.686300e+04 0.000000e+00]\n"," [1.234700e+04 0.000000e+00 1.190800e+04 1.240900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.620000e+03 3.574000e+03]\n"," [8.221240e+05 0.000000e+00 6.936600e+05 5.380100e+04 5.855000e+03\n","  0.000000e+00 0.000000e+00 1.010560e+05 0.000000e+00]\n"," [2.934710e+05 0.000000e+00 1.143160e+05 2.385660e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.559700e+04 1.390000e+02]\n"," [1.171230e+05 0.000000e+00 3.763000e+03 1.389000e+03 8.200000e+01\n","  0.000000e+00 0.000000e+00 3.376000e+03 0.000000e+00]\n"," [6.001050e+05 0.000000e+00 3.145200e+04 1.072000e+03 1.985500e+04\n","  0.000000e+00 0.000000e+00 1.054000e+03 0.000000e+00]\n"," [1.698200e+04 0.000000e+00 1.304000e+03 3.401000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.064000e+03 0.000000e+00]\n"," [5.454580e+05 0.000000e+00 3.208500e+04 3.284200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.110380e+05 0.000000e+00]\n"," [2.294400e+04 0.000000e+00 6.551500e+04 4.921300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.569000e+03 5.485000e+03]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 16, learning rate = 0.0043,                 previous best = 0.1807\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.318: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 16, numImages:   362]\n","Loss: 57.642\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.360: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 16, numImages:    52]\n","Acc:0.7838100962908596, Acc_class:0.2653582313501162, mIoU:0.21432565447739074, fwIoU: 0.6341500646493853\n","Classwise_IoU:\n","[0.79198872 0.         0.44506576 0.39044003 0.00319826 0.\n"," 0.         0.16143077 0.13680735]\n","Loss: 9.367\n","[[9.283059e+06 0.000000e+00 9.283200e+04 4.658800e+04 2.730000e+02\n","  0.000000e+00 0.000000e+00 3.840100e+04 2.100000e+01]\n"," [1.122800e+04 0.000000e+00 6.212000e+03 2.175100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.065000e+03 3.602000e+03]\n"," [6.924330e+05 0.000000e+00 8.555290e+05 7.571100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.280700e+04 1.600000e+01]\n"," [2.845730e+05 0.000000e+00 1.671100e+04 4.151990e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.333300e+04 2.273000e+03]\n"," [1.044380e+05 0.000000e+00 1.387900e+04 1.321000e+03 4.030000e+02\n","  0.000000e+00 0.000000e+00 5.692000e+03 0.000000e+00]\n"," [5.928850e+05 0.000000e+00 5.796400e+04 1.415000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.274000e+03 0.000000e+00]\n"," [1.674300e+04 0.000000e+00 1.043000e+03 3.565000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.400000e+03 0.000000e+00]\n"," [5.349500e+05 0.000000e+00 5.674300e+04 7.852700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.512030e+05 0.000000e+00]\n"," [2.277700e+04 0.000000e+00 3.730000e+02 1.024460e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.480000e+02 2.088200e+04]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 17, learning rate = 0.0042,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.333: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 17, numImages:   362]\n","Loss: 60.217\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.357: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 17, numImages:    52]\n","Acc:0.7613097842655655, Acc_class:0.1980714433495789, mIoU:0.15174381290866396, fwIoU: 0.607897641810478\n","Classwise_IoU:\n","[7.98266909e-01 0.00000000e+00 3.52386392e-01 1.11869992e-02\n"," 0.00000000e+00 3.81491265e-05 0.00000000e+00 2.03815867e-01\n"," 0.00000000e+00]\n","Loss: 9.290\n","[[9.283362e+06 0.000000e+00 1.290770e+05 1.932000e+03 0.000000e+00\n","  2.440000e+02 0.000000e+00 4.655900e+04 0.000000e+00]\n"," [7.194000e+03 0.000000e+00 3.611700e+04 3.800000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.090000e+02 0.000000e+00]\n"," [7.143920e+05 0.000000e+00 9.365870e+05 6.400000e+01 0.000000e+00\n","  2.600000e+01 0.000000e+00 2.542700e+04 0.000000e+00]\n"," [2.239400e+05 0.000000e+00 4.772940e+05 8.229000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.262600e+04 0.000000e+00]\n"," [1.015730e+05 0.000000e+00 1.052500e+04 1.100000e+01 0.000000e+00\n","  1.515000e+03 0.000000e+00 1.210900e+04 0.000000e+00]\n"," [6.133770e+05 0.000000e+00 3.885800e+04 5.000000e+00 0.000000e+00\n","  2.500000e+01 0.000000e+00 1.273000e+03 0.000000e+00]\n"," [1.603700e+04 0.000000e+00 5.379000e+03 1.290000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.206000e+03 0.000000e+00]\n"," [4.718580e+05 0.000000e+00 1.591370e+05 2.680000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.901600e+05 0.000000e+00]\n"," [1.985100e+04 0.000000e+00 1.249580e+05 1.050000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.670000e+02 0.000000e+00]]\n","\n","=>Epoches 18, learning rate = 0.0042,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.319: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 18, numImages:   362]\n","Loss: 57.710\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.389: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 18, numImages:    52]\n","Acc:0.7559175195114458, Acc_class:0.2137035614207792, mIoU:0.16564353953079033, fwIoU: 0.6052795287013896\n","Classwise_IoU:\n","[0.78333156 0.         0.35587019 0.15149121 0.         0.\n"," 0.         0.2000989  0.        ]\n","Loss: 10.111\n","[[9.142688e+06 0.000000e+00 2.311560e+05 2.764400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.968600e+04 0.000000e+00]\n"," [1.191200e+04 0.000000e+00 2.236000e+04 4.264000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.322000e+03 0.000000e+00]\n"," [6.938810e+05 0.000000e+00 8.454860e+05 1.896400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.181650e+05 0.000000e+00]\n"," [2.843320e+05 0.000000e+00 1.972600e+05 1.265500e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.239470e+05 0.000000e+00]\n"," [9.360900e+04 0.000000e+00 2.296700e+04 7.170000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.440000e+03 0.000000e+00]\n"," [5.851490e+05 0.000000e+00 6.502700e+04 1.209000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.153000e+03 0.000000e+00]\n"," [1.684000e+04 0.000000e+00 2.829000e+03 3.093000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.890000e+02 0.000000e+00]\n"," [5.034400e+05 0.000000e+00 6.300700e+04 2.512900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.298470e+05 0.000000e+00]\n"," [2.120600e+04 0.000000e+00 9.472500e+04 2.225300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.542000e+03 0.000000e+00]]\n","\n","=>Epoches 19, learning rate = 0.0041,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.319: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 19, numImages:   362]\n","Loss: 57.769\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.374: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 19, numImages:    52]\n","Acc:0.7484575573987701, Acc_class:0.20606344519407707, mIoU:0.1520421736981587, fwIoU: 0.5980626652843993\n","Classwise_IoU:\n","[7.80521371e-01 0.00000000e+00 3.77655442e-01 2.73815835e-02\n"," 5.23804626e-03 4.56437596e-06 0.00000000e+00 1.77578556e-01\n"," 0.00000000e+00]\n","Loss: 9.721\n","[[8.934906e+06 0.000000e+00 4.659340e+05 3.275000e+03 6.020000e+02\n","  1.560000e+02 0.000000e+00 5.630100e+04 0.000000e+00]\n"," [9.114000e+03 0.000000e+00 3.272400e+04 6.470000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.373000e+03 0.000000e+00]\n"," [5.331950e+05 0.000000e+00 1.109898e+06 2.025000e+03 4.500000e+01\n","  2.200000e+01 0.000000e+00 3.131100e+04 0.000000e+00]\n"," [3.064050e+05 0.000000e+00 3.355570e+05 2.050500e+04 0.000000e+00\n","  2.400000e+01 0.000000e+00 6.959800e+04 0.000000e+00]\n"," [9.119400e+04 0.000000e+00 2.296800e+04 2.100000e+01 6.620000e+02\n","  3.459000e+03 0.000000e+00 7.429000e+03 0.000000e+00]\n"," [5.767450e+05 0.000000e+00 7.579100e+04 1.050000e+02 0.000000e+00\n","  3.000000e+00 0.000000e+00 8.940000e+02 0.000000e+00]\n"," [1.630300e+04 0.000000e+00 5.864000e+03 5.580000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.026000e+03 0.000000e+00]\n"," [4.267380e+05 0.000000e+00 2.142440e+05 3.864000e+03 3.000000e+00\n","  6.500000e+01 0.000000e+00 1.765090e+05 0.000000e+00]\n"," [2.648800e+04 0.000000e+00 1.093390e+05 6.277000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.622000e+03 0.000000e+00]]\n","\n","=>Epoches 20, learning rate = 0.0041,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.313: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 20, numImages:   362]\n","Loss: 56.607\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.360: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 20, numImages:    52]\n","Acc:0.7557867173389898, Acc_class:0.19646607543592662, mIoU:0.15070814538035382, fwIoU: 0.6005548196953557\n","Classwise_IoU:\n","[7.91490883e-01 0.00000000e+00 3.38719860e-01 3.40090991e-04\n"," 3.34958374e-02 1.62070848e-03 0.00000000e+00 1.90705929e-01\n"," 0.00000000e+00]\n","Loss: 9.360\n","[[9.323074e+06 0.000000e+00 8.629800e+04 2.300000e+01 2.391000e+03\n","  5.850000e+02 0.000000e+00 4.880300e+04 0.000000e+00]\n"," [1.110400e+04 0.000000e+00 2.693000e+04 0.000000e+00 1.640000e+02\n","  0.000000e+00 0.000000e+00 5.660000e+03 0.000000e+00]\n"," [7.351430e+05 0.000000e+00 7.876280e+05 0.000000e+00 1.690000e+02\n","  5.000000e+00 0.000000e+00 1.535510e+05 0.000000e+00]\n"," [2.876390e+05 0.000000e+00 3.019920e+05 2.490000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.422090e+05 0.000000e+00]\n"," [1.015520e+05 0.000000e+00 1.574000e+04 0.000000e+00 4.466000e+03\n","  1.716000e+03 0.000000e+00 2.259000e+03 0.000000e+00]\n"," [5.951600e+05 0.000000e+00 5.453800e+04 0.000000e+00 1.000000e+00\n","  1.063000e+03 0.000000e+00 2.776000e+03 0.000000e+00]\n"," [1.731400e+04 0.000000e+00 2.349000e+03 1.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.087000e+03 0.000000e+00]\n"," [5.461350e+05 0.000000e+00 4.405200e+04 2.100000e+01 4.872000e+03\n","  4.200000e+01 0.000000e+00 2.263010e+05 0.000000e+00]\n"," [2.390900e+04 0.000000e+00 1.169130e+05 2.300000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.881000e+03 0.000000e+00]]\n","\n","=>Epoches 21, learning rate = 0.0040,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.322: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 21, numImages:   362]\n","Loss: 58.280\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.356: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 21, numImages:    52]\n","Acc:0.770276309724345, Acc_class:0.22505391015672094, mIoU:0.17367548000436298, fwIoU: 0.624986185867888\n","Classwise_IoU:\n","[8.07720332e-01 0.00000000e+00 3.87321967e-01 3.18384315e-02\n"," 5.46111571e-02 1.52789555e-06 0.00000000e+00 2.81585905e-01\n"," 0.00000000e+00]\n","Loss: 9.248\n","[[9.196610e+06 0.000000e+00 1.770230e+05 1.612800e+04 3.033000e+03\n","  1.090000e+02 0.000000e+00 6.827100e+04 0.000000e+00]\n"," [8.272000e+03 0.000000e+00 3.332300e+04 5.800000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.683000e+03 0.000000e+00]\n"," [5.512800e+05 0.000000e+00 1.023984e+06 7.428000e+03 1.640000e+02\n","  0.000000e+00 0.000000e+00 9.364000e+04 0.000000e+00]\n"," [2.282400e+05 0.000000e+00 4.515260e+05 2.458500e+04 3.000000e+01\n","  0.000000e+00 0.000000e+00 2.770800e+04 0.000000e+00]\n"," [9.441400e+04 0.000000e+00 1.881800e+04 2.630000e+02 7.254000e+03\n","  8.480000e+02 0.000000e+00 4.136000e+03 0.000000e+00]\n"," [5.939410e+05 0.000000e+00 5.649100e+04 3.410000e+02 0.000000e+00\n","  1.000000e+00 0.000000e+00 2.764000e+03 0.000000e+00]\n"," [1.518200e+04 0.000000e+00 3.126000e+03 1.221000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.222000e+03 0.000000e+00]\n"," [4.134720e+05 0.000000e+00 1.031410e+05 1.230600e+04 3.870000e+03\n","  0.000000e+00 0.000000e+00 2.886340e+05 0.000000e+00]\n"," [1.990900e+04 0.000000e+00 1.238100e+05 1.824000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.183000e+03 0.000000e+00]]\n","\n","=>Epoches 22, learning rate = 0.0040,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.325: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 22, numImages:   362]\n","Loss: 58.810\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.355: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 22, numImages:    52]\n","Acc:0.7675909922755106, Acc_class:0.21725854295331912, mIoU:0.16759161022379782, fwIoU: 0.6164618266520644\n","Classwise_IoU:\n","[7.98829272e-01 0.00000000e+00 3.85233525e-01 6.35446038e-03\n"," 4.77492374e-02 7.47356853e-04 0.00000000e+00 2.69410641e-01\n"," 0.00000000e+00]\n","Loss: 9.237\n","[[9.268161e+06 0.000000e+00 1.149720e+05 1.044000e+03 1.629600e+04\n","  5.060000e+02 0.000000e+00 6.019500e+04 0.000000e+00]\n"," [7.990000e+03 0.000000e+00 3.386800e+04 2.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.998000e+03 0.000000e+00]\n"," [6.690650e+05 0.000000e+00 9.403820e+05 5.500000e+01 4.473000e+03\n","  3.600000e+01 0.000000e+00 6.248500e+04 0.000000e+00]\n"," [2.734520e+05 0.000000e+00 3.648810e+05 4.665000e+03 5.100000e+01\n","  1.860000e+02 0.000000e+00 8.885400e+04 0.000000e+00]\n"," [9.613200e+04 0.000000e+00 1.495300e+04 3.600000e+01 7.999000e+03\n","  2.711000e+03 0.000000e+00 3.902000e+03 0.000000e+00]\n"," [6.081880e+05 0.000000e+00 2.547500e+04 0.000000e+00 1.833600e+04\n","  4.910000e+02 0.000000e+00 1.048000e+03 0.000000e+00]\n"," [1.555900e+04 0.000000e+00 3.570000e+03 1.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.621000e+03 0.000000e+00]\n"," [4.472500e+05 0.000000e+00 8.858000e+04 3.340000e+02 2.632000e+03\n","  5.000000e+00 0.000000e+00 2.826220e+05 0.000000e+00]\n"," [2.337000e+04 0.000000e+00 1.182750e+05 5.690000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.512000e+03 0.000000e+00]]\n","\n","=>Epoches 23, learning rate = 0.0040,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.317: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 23, numImages:   362]\n","Loss: 57.353\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.323: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 23, numImages:    52]\n","Acc:0.7955850686177967, Acc_class:0.2616209464819853, mIoU:0.21265561437685795, fwIoU: 0.6511757038135744\n","Classwise_IoU:\n","[0.80354247 0.         0.50915779 0.3853886  0.00328807 0.01178569\n"," 0.         0.20073791 0.        ]\n","Loss: 8.411\n","[[9.309459e+06 0.000000e+00 8.632600e+04 3.698900e+04 4.330000e+02\n","  3.722000e+03 0.000000e+00 2.424500e+04 0.000000e+00]\n"," [8.740000e+03 0.000000e+00 1.980200e+04 1.501800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.980000e+02 0.000000e+00]\n"," [5.815100e+05 0.000000e+00 9.892890e+05 5.068300e+04 4.800000e+01\n","  6.890000e+02 0.000000e+00 5.427700e+04 0.000000e+00]\n"," [2.854850e+05 0.000000e+00 3.965700e+04 3.947890e+05 0.000000e+00\n","  3.050000e+02 0.000000e+00 1.185300e+04 0.000000e+00]\n"," [9.571500e+04 0.000000e+00 1.501900e+04 5.500000e+02 4.150000e+02\n","  5.569000e+03 0.000000e+00 8.465000e+03 0.000000e+00]\n"," [5.899250e+05 0.000000e+00 5.388800e+04 1.472000e+03 0.000000e+00\n","  7.825000e+03 0.000000e+00 4.280000e+02 0.000000e+00]\n"," [1.605500e+04 0.000000e+00 9.250000e+02 3.313000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.458000e+03 0.000000e+00]\n"," [5.233140e+05 0.000000e+00 4.167900e+04 7.067600e+04 0.000000e+00\n","  1.180000e+02 0.000000e+00 1.856360e+05 0.000000e+00]\n"," [2.360400e+04 0.000000e+00 9.199000e+03 1.136020e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.210000e+02 0.000000e+00]]\n","\n","=>Epoches 24, learning rate = 0.0039,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.315: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 24, numImages:   362]\n","Loss: 57.100\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.355: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 24, numImages:    52]\n","Acc:0.7811069488252211, Acc_class:0.2572860138497217, mIoU:0.2044765483342138, fwIoU: 0.6361443104469457\n","Classwise_IoU:\n","[0.79655241 0.         0.42480194 0.36774392 0.02272305 0.01635977\n"," 0.         0.21210784 0.        ]\n","Loss: 9.220\n","[[9.274752e+06 0.000000e+00 4.850700e+04 3.886400e+04 2.995900e+04\n","  3.276000e+03 0.000000e+00 6.581600e+04 0.000000e+00]\n"," [9.476000e+03 0.000000e+00 5.440000e+02 2.560000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.238000e+03 0.000000e+00]\n"," [6.760650e+05 0.000000e+00 7.654230e+05 9.185400e+04 2.740000e+03\n","  1.656000e+03 0.000000e+00 1.387580e+05 0.000000e+00]\n"," [2.782990e+05 0.000000e+00 3.257000e+03 4.008600e+05 0.000000e+00\n","  1.300000e+01 0.000000e+00 4.966000e+04 0.000000e+00]\n"," [9.268300e+04 0.000000e+00 1.277700e+04 1.592000e+03 3.794000e+03\n","  3.568000e+03 0.000000e+00 1.131900e+04 0.000000e+00]\n"," [5.936350e+05 0.000000e+00 3.623200e+04 2.168000e+03 8.324000e+03\n","  1.083100e+04 0.000000e+00 2.348000e+03 0.000000e+00]\n"," [1.675400e+04 0.000000e+00 1.850000e+02 3.421000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.391000e+03 0.000000e+00]\n"," [4.935990e+05 0.000000e+00 2.383700e+04 7.015300e+04 2.110000e+02\n","  0.000000e+00 0.000000e+00 2.336230e+05 0.000000e+00]\n"," [2.193300e+04 0.000000e+00 0.000000e+00 1.243110e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.820000e+02 0.000000e+00]]\n","\n","=>Epoches 25, learning rate = 0.0039,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.309: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 25, numImages:   362]\n","Loss: 55.869\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.346: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 25, numImages:    52]\n","Acc:0.7712178661445103, Acc_class:0.23685005533252979, mIoU:0.18541864318415827, fwIoU: 0.6241444552690646\n","Classwise_IoU:\n","[7.96471614e-01 0.00000000e+00 3.65838881e-01 2.50861379e-01\n"," 5.19533679e-04 5.02236391e-03 0.00000000e+00 2.50054017e-01\n"," 0.00000000e+00]\n","Loss: 9.008\n","[[9.315125e+06 0.000000e+00 3.569400e+04 1.589600e+04 2.500000e+01\n","  5.690000e+02 0.000000e+00 9.386500e+04 0.000000e+00]\n"," [8.319000e+03 0.000000e+00 7.440000e+02 2.222200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.257300e+04 0.000000e+00]\n"," [7.203590e+05 0.000000e+00 6.448770e+05 1.205920e+05 5.800000e+01\n","  1.620000e+02 0.000000e+00 1.898350e+05 6.130000e+02]\n"," [2.923280e+05 0.000000e+00 0.000000e+00 2.549740e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.847870e+05 0.000000e+00]\n"," [9.735100e+04 0.000000e+00 9.467000e+03 3.820000e+02 6.600000e+01\n","  2.593000e+03 0.000000e+00 1.587400e+04 0.000000e+00]\n"," [6.180730e+05 0.000000e+00 2.588300e+04 5.970000e+02 1.221000e+03\n","  3.299000e+03 0.000000e+00 4.465000e+03 0.000000e+00]\n"," [1.602200e+04 0.000000e+00 4.100000e+01 2.246000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.442000e+03 0.000000e+00]\n"," [4.574700e+05 0.000000e+00 1.441000e+04 1.393100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.356120e+05 0.000000e+00]\n"," [2.439300e+04 0.000000e+00 0.000000e+00 1.084390e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.389400e+04 0.000000e+00]]\n","\n","=>Epoches 26, learning rate = 0.0038,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.316: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 26, numImages:   362]\n","Loss: 57.244\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.387: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 26, numImages:    52]\n","Acc:0.7448501211710404, Acc_class:0.1936210570211433, mIoU:0.14537704054037326, fwIoU: 0.5886448276923808\n","Classwise_IoU:\n","[7.81847266e-01 0.00000000e+00 2.72066365e-01 5.12035679e-02\n"," 3.29536273e-03 1.53013291e-06 0.00000000e+00 1.99979273e-01\n"," 0.00000000e+00]\n","Loss: 10.051\n","[[9.314546e+06 0.000000e+00 2.703200e+04 3.694000e+03 1.000000e+01\n","  0.000000e+00 0.000000e+00 1.158920e+05 0.000000e+00]\n"," [6.761000e+03 0.000000e+00 1.662700e+04 3.510000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.696000e+04 0.000000e+00]\n"," [9.159720e+05 0.000000e+00 5.153930e+05 2.632000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.424990e+05 0.000000e+00]\n"," [2.598310e+05 0.000000e+00 1.047400e+05 3.857600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.289420e+05 0.000000e+00]\n"," [1.074130e+05 0.000000e+00 1.825000e+03 1.120000e+02 4.160000e+02\n","  0.000000e+00 0.000000e+00 1.596700e+04 0.000000e+00]\n"," [6.394240e+05 0.000000e+00 3.391000e+03 7.000000e+00 4.950000e+02\n","  1.000000e+00 0.000000e+00 1.022000e+04 0.000000e+00]\n"," [1.641400e+04 0.000000e+00 3.300000e+02 2.790000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.728000e+03 0.000000e+00]\n"," [4.841030e+05 0.000000e+00 1.300200e+04 1.340000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.241840e+05 0.000000e+00]\n"," [2.241900e+04 0.000000e+00 5.092200e+04 1.092800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.245700e+04 0.000000e+00]]\n","\n","=>Epoches 27, learning rate = 0.0038,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.315: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 27, numImages:   362]\n","Loss: 56.948\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.364: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 27, numImages:    52]\n","Acc:0.7684440562762097, Acc_class:0.26601250619222405, mIoU:0.19822754181861876, fwIoU: 0.6264176966024133\n","Classwise_IoU:\n","[0.8012917  0.         0.28884673 0.38171352 0.03654271 0.00166069\n"," 0.         0.26923599 0.00475652]\n","Loss: 9.471\n","[[9.189061e+06 0.000000e+00 1.731000e+04 4.919200e+04 1.294300e+04\n","  7.170000e+02 0.000000e+00 1.919510e+05 0.000000e+00]\n"," [7.862000e+03 0.000000e+00 4.262000e+03 2.354800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.894000e+03 2.292000e+03]\n"," [6.792110e+05 0.000000e+00 4.971240e+05 1.141630e+05 2.442900e+04\n","  4.400000e+01 0.000000e+00 3.558080e+05 5.717000e+03]\n"," [2.306290e+05 0.000000e+00 6.414000e+03 4.220240e+05 0.000000e+00\n","  1.170000e+02 0.000000e+00 7.290500e+04 0.000000e+00]\n"," [9.321700e+04 0.000000e+00 7.274000e+03 1.842000e+03 7.272000e+03\n","  2.538000e+03 0.000000e+00 1.359000e+04 0.000000e+00]\n"," [5.991260e+05 0.000000e+00 7.203000e+03 1.023000e+03 3.558600e+04\n","  1.091000e+03 0.000000e+00 9.509000e+03 0.000000e+00]\n"," [1.245800e+04 0.000000e+00 0.000000e+00 3.576000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.717000e+03 0.000000e+00]\n"," [3.639750e+05 0.000000e+00 2.106000e+03 5.634700e+04 3.090000e+02\n","  0.000000e+00 0.000000e+00 3.986860e+05 0.000000e+00]\n"," [2.015800e+04 0.000000e+00 0.000000e+00 1.238240e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.008000e+03 7.360000e+02]]\n","\n","=>Epoches 28, learning rate = 0.0037,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.317: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 28, numImages:   362]\n","Loss: 57.346\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.347: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 28, numImages:    52]\n","Acc:0.7776524561432738, Acc_class:0.24158918344478725, mIoU:0.1937334145795516, fwIoU: 0.6303091719843847\n","Classwise_IoU:\n","[0.79127283 0.         0.47018412 0.19550271 0.03842295 0.00496064\n"," 0.         0.24325749 0.        ]\n","Loss: 9.026\n","[[9.194489e+06 0.000000e+00 2.005340e+05 5.129000e+03 1.393000e+03\n","  4.750000e+02 0.000000e+00 5.915400e+04 0.000000e+00]\n"," [1.001100e+04 0.000000e+00 1.726300e+04 1.046700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.117000e+03 0.000000e+00]\n"," [5.475620e+05 0.000000e+00 9.961490e+05 8.952000e+03 2.280000e+02\n","  7.200000e+01 0.000000e+00 1.235330e+05 0.000000e+00]\n"," [4.165930e+05 0.000000e+00 3.934000e+04 1.667120e+05 0.000000e+00\n","  1.650000e+02 0.000000e+00 1.092790e+05 0.000000e+00]\n"," [8.922900e+04 0.000000e+00 2.152600e+04 3.500000e+02 4.902000e+03\n","  3.528000e+03 0.000000e+00 6.198000e+03 0.000000e+00]\n"," [5.704100e+05 0.000000e+00 7.779800e+04 4.400000e+01 1.000000e+00\n","  3.263000e+03 0.000000e+00 2.022000e+03 0.000000e+00]\n"," [1.501300e+04 0.000000e+00 1.895000e+03 2.506000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.337000e+03 0.000000e+00]\n"," [4.686280e+05 0.000000e+00 6.896800e+04 7.108000e+03 2.250000e+02\n","  0.000000e+00 0.000000e+00 2.764940e+05 0.000000e+00]\n"," [4.125200e+04 0.000000e+00 1.481600e+04 8.609000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.568000e+03 0.000000e+00]]\n","\n","=>Epoches 29, learning rate = 0.0037,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.295: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 29, numImages:   362]\n","Loss: 53.366\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.337: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 29, numImages:    52]\n","Acc:0.7703003510174947, Acc_class:0.22506646917175738, mIoU:0.1797497007736125, fwIoU: 0.6186448816741329\n","Classwise_IoU:\n","[0.79286984 0.         0.39743989 0.13251956 0.05781084 0.00483645\n"," 0.         0.23227073 0.        ]\n","Loss: 8.755\n","[[9.328009e+06 0.000000e+00 6.542800e+04 6.546000e+03 2.577000e+03\n","  1.354000e+03 0.000000e+00 5.726000e+04 0.000000e+00]\n"," [9.822000e+03 0.000000e+00 2.620200e+04 3.845000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.989000e+03 0.000000e+00]\n"," [6.821960e+05 0.000000e+00 8.126350e+05 4.270000e+03 3.490000e+02\n","  1.200000e+02 0.000000e+00 1.769260e+05 0.000000e+00]\n"," [3.472170e+05 0.000000e+00 1.362790e+05 1.037330e+05 3.000000e+00\n","  2.050000e+02 0.000000e+00 1.446520e+05 0.000000e+00]\n"," [9.710000e+04 0.000000e+00 1.055300e+04 5.200000e+01 7.522000e+03\n","  3.531000e+03 0.000000e+00 6.975000e+03 0.000000e+00]\n"," [6.149000e+05 0.000000e+00 3.201700e+04 4.400000e+01 0.000000e+00\n","  3.186000e+03 0.000000e+00 3.391000e+03 0.000000e+00]\n"," [1.690400e+04 0.000000e+00 2.600000e+02 2.484000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.103000e+03 0.000000e+00]\n"," [5.050090e+05 0.000000e+00 2.092800e+04 7.722000e+03 1.452000e+03\n","  0.000000e+00 0.000000e+00 2.863120e+05 0.000000e+00]\n"," [3.054600e+04 0.000000e+00 7.651100e+04 2.572300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.394600e+04 0.000000e+00]]\n","\n","=>Epoches 30, learning rate = 0.0036,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.302: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 30, numImages:   362]\n","Loss: 54.589\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.350: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 30, numImages:    52]\n","Acc:0.7743072819250104, Acc_class:0.24084646721690936, mIoU:0.19126354484715716, fwIoU: 0.622261267709172\n","Classwise_IoU:\n","[7.91272939e-01 0.00000000e+00 3.49468130e-01 3.51932285e-01\n"," 3.21947264e-03 2.14216640e-05 0.00000000e+00 2.25457655e-01\n"," 0.00000000e+00]\n","Loss: 9.101\n","[[9.343991e+06 0.000000e+00 3.932600e+04 3.433600e+04 6.400000e+01\n","  0.000000e+00 0.000000e+00 4.345700e+04 0.000000e+00]\n"," [9.423000e+03 0.000000e+00 1.140800e+04 1.955700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.441000e+03 2.900000e+01]\n"," [7.779990e+05 0.000000e+00 6.443420e+05 8.084500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.733100e+05 0.000000e+00]\n"," [2.763500e+05 0.000000e+00 4.278500e+04 3.559510e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.700300e+04 0.000000e+00]\n"," [1.072640e+05 0.000000e+00 1.074600e+04 7.060000e+02 4.050000e+02\n","  6.000000e+00 0.000000e+00 6.606000e+03 0.000000e+00]\n"," [6.189970e+05 0.000000e+00 3.209900e+04 6.810000e+02 0.000000e+00\n","  1.400000e+01 0.000000e+00 1.747000e+03 0.000000e+00]\n"," [1.683100e+04 0.000000e+00 0.000000e+00 3.180000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.740000e+03 0.000000e+00]\n"," [5.175050e+05 0.000000e+00 1.075800e+04 4.163200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.515280e+05 0.000000e+00]\n"," [2.326600e+04 0.000000e+00 2.016100e+04 9.839300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.906000e+03 0.000000e+00]]\n","\n","=>Epoches 31, learning rate = 0.0036,                 previous best = 0.2143\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.304: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 31, numImages:   362]\n","Loss: 54.955\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.342: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 31, numImages:    52]\n","Acc:0.7893512855295968, Acc_class:0.2815689066965875, mIoU:0.21981884110468008, fwIoU: 0.6506706136726528\n","Classwise_IoU:\n","[8.04350692e-01 0.00000000e+00 4.67885079e-01 4.09198222e-01\n"," 4.84133717e-02 1.09865628e-04 0.00000000e+00 2.48412340e-01\n"," 0.00000000e+00]\n","Loss: 8.882\n","[[9.126652e+06 0.000000e+00 1.437080e+05 9.040900e+04 5.572000e+03\n","  1.250000e+02 0.000000e+00 9.470800e+04 0.000000e+00]\n"," [8.891000e+03 0.000000e+00 1.309000e+04 2.020600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.671000e+03 0.000000e+00]\n"," [5.528800e+05 0.000000e+00 9.376810e+05 6.039200e+04 3.870000e+02\n","  0.000000e+00 0.000000e+00 1.251560e+05 0.000000e+00]\n"," [2.021070e+05 0.000000e+00 3.960600e+04 4.613890e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.898700e+04 0.000000e+00]\n"," [9.151900e+04 0.000000e+00 1.678100e+04 3.740000e+03 6.449000e+03\n","  1.683000e+03 0.000000e+00 5.561000e+03 0.000000e+00]\n"," [5.789990e+05 0.000000e+00 6.400700e+04 5.332000e+03 7.140000e+02\n","  7.200000e+01 0.000000e+00 4.414000e+03 0.000000e+00]\n"," [1.501900e+04 0.000000e+00 2.490000e+02 4.298000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.185000e+03 0.000000e+00]\n"," [4.209370e+05 0.000000e+00 3.442700e+04 9.539600e+04 8.010000e+02\n","  0.000000e+00 0.000000e+00 2.698620e+05 0.000000e+00]\n"," [1.508200e+04 0.000000e+00 1.572000e+04 1.156820e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.420000e+02 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 32, learning rate = 0.0035,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.314: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 32, numImages:   362]\n","Loss: 56.923\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.359: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 32, numImages:    52]\n","Acc:0.7608500036683067, Acc_class:0.21064610128033395, mIoU:0.15640264263796752, fwIoU: 0.6127075219711594\n","Classwise_IoU:\n","[8.01282734e-01 0.00000000e+00 3.57638829e-01 9.32723717e-04\n"," 0.00000000e+00 5.31866929e-04 0.00000000e+00 2.47237630e-01\n"," 0.00000000e+00]\n","Loss: 9.332\n","[[9.268197e+06 0.000000e+00 6.744700e+04 8.000000e+00 0.000000e+00\n","  3.900000e+01 0.000000e+00 1.254830e+05 0.000000e+00]\n"," [1.086700e+04 0.000000e+00 2.268500e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.030600e+04 0.000000e+00]\n"," [6.572070e+05 0.000000e+00 7.674940e+05 6.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.517890e+05 0.000000e+00]\n"," [2.726460e+05 0.000000e+00 2.025890e+05 6.830000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.561710e+05 0.000000e+00]\n"," [9.635400e+04 0.000000e+00 1.218400e+04 0.000000e+00 0.000000e+00\n","  7.220000e+02 0.000000e+00 1.647300e+04 0.000000e+00]\n"," [6.107100e+05 0.000000e+00 3.598100e+04 0.000000e+00 0.000000e+00\n","  3.480000e+02 0.000000e+00 6.499000e+03 0.000000e+00]\n"," [1.574800e+04 0.000000e+00 2.190000e+03 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.813000e+03 0.000000e+00]\n"," [4.191840e+05 0.000000e+00 2.689000e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.753490e+05 0.000000e+00]\n"," [2.281000e+04 0.000000e+00 9.954100e+04 1.610000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.421400e+04 0.000000e+00]]\n","\n","=>Epoches 33, learning rate = 0.0035,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.301: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 33, numImages:   362]\n","Loss: 54.540\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.346: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 33, numImages:    52]\n","Acc:0.7778659048280471, Acc_class:0.2564177091020003, mIoU:0.19384327163950532, fwIoU: 0.6301139244991486\n","Classwise_IoU:\n","[0.80007589 0.         0.37967928 0.37996458 0.01773203 0.00536489\n"," 0.         0.16177277 0.        ]\n","Loss: 8.998\n","[[9.257951e+06 0.000000e+00 9.132000e+04 8.597800e+04 7.320000e+02\n","  2.143000e+03 0.000000e+00 2.303800e+04 1.200000e+01]\n"," [7.818000e+03 0.000000e+00 1.804000e+03 3.404400e+04 0.000000e+00\n","  2.500000e+01 0.000000e+00 1.670000e+02 0.000000e+00]\n"," [7.224710e+05 0.000000e+00 7.275160e+05 1.976670e+05 0.000000e+00\n","  7.580000e+02 0.000000e+00 2.105200e+04 7.032000e+03]\n"," [2.096470e+05 0.000000e+00 6.110000e+03 5.123830e+05 0.000000e+00\n","  7.500000e+01 0.000000e+00 3.874000e+03 0.000000e+00]\n"," [9.576000e+04 0.000000e+00 1.615800e+04 1.548000e+03 2.260000e+03\n","  9.109000e+03 0.000000e+00 8.980000e+02 0.000000e+00]\n"," [6.011550e+05 0.000000e+00 4.336800e+04 4.590000e+03 0.000000e+00\n","  3.577000e+03 0.000000e+00 8.480000e+02 0.000000e+00]\n"," [1.432500e+04 0.000000e+00 2.484000e+03 5.357000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.585000e+03 0.000000e+00]\n"," [4.419340e+05 0.000000e+00 7.839300e+04 1.577700e+05 9.880000e+02\n","  1.095000e+03 0.000000e+00 1.412430e+05 0.000000e+00]\n"," [1.705700e+04 0.000000e+00 0.000000e+00 1.294590e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.100000e+02 0.000000e+00]]\n","\n","=>Epoches 34, learning rate = 0.0034,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.303: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 34, numImages:   362]\n","Loss: 54.763\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.339: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 34, numImages:    52]\n","Acc:0.7624252564234097, Acc_class:0.2220565098339257, mIoU:0.16898062722485932, fwIoU: 0.6151189237690367\n","Classwise_IoU:\n","[0.80264381 0.         0.31071071 0.07306133 0.03465892 0.00687021\n"," 0.         0.29288066 0.        ]\n","Loss: 8.803\n","[[9.272586e+06 0.000000e+00 5.989600e+04 1.348900e+04 1.953000e+03\n","  4.180000e+02 0.000000e+00 1.128140e+05 1.800000e+01]\n"," [6.788000e+03 0.000000e+00 3.061800e+04 1.826000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.626000e+03 0.000000e+00]\n"," [6.907860e+05 0.000000e+00 7.028500e+05 8.966000e+03 2.130000e+02\n","  2.850000e+02 0.000000e+00 2.733960e+05 0.000000e+00]\n"," [2.375730e+05 0.000000e+00 3.371090e+05 5.662100e+04 5.000000e+00\n","  5.500000e+01 0.000000e+00 1.007260e+05 0.000000e+00]\n"," [1.022070e+05 0.000000e+00 4.960000e+03 8.200000e+02 4.688000e+03\n","  2.744000e+03 0.000000e+00 1.031400e+04 0.000000e+00]\n"," [6.247230e+05 0.000000e+00 1.155000e+04 5.480000e+02 7.133000e+03\n","  4.514000e+03 0.000000e+00 5.070000e+03 0.000000e+00]\n"," [1.279600e+04 0.000000e+00 1.059000e+03 1.899000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.997000e+03 0.000000e+00]\n"," [3.958150e+05 0.000000e+00 2.675400e+04 6.261000e+03 2.240000e+02\n","  0.000000e+00 0.000000e+00 3.923690e+05 0.000000e+00]\n"," [2.069200e+04 0.000000e+00 1.136300e+05 9.081000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.323000e+03 0.000000e+00]]\n","\n","=>Epoches 35, learning rate = 0.0034,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.294: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 35, numImages:   362]\n","Loss: 53.266\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.328: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 35, numImages:    52]\n","Acc:0.7703279729287732, Acc_class:0.22573909376190737, mIoU:0.1716480595373593, fwIoU: 0.6229043263189254\n","Classwise_IoU:\n","[8.04045046e-01 0.00000000e+00 3.71454466e-01 6.30767348e-02\n"," 4.73899960e-03 5.07673205e-04 0.00000000e+00 3.01009616e-01\n"," 0.00000000e+00]\n","Loss: 8.517\n","[[9.267383e+06 0.000000e+00 6.373100e+04 4.205000e+03 6.510000e+02\n","  9.000000e+00 0.000000e+00 1.251950e+05 0.000000e+00]\n"," [1.199500e+04 0.000000e+00 2.791500e+04 6.500000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.298000e+03 0.000000e+00]\n"," [6.060790e+05 0.000000e+00 8.221710e+05 5.720000e+03 1.320000e+02\n","  0.000000e+00 0.000000e+00 2.423940e+05 0.000000e+00]\n"," [3.016240e+05 0.000000e+00 2.656480e+05 4.742500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.173920e+05 0.000000e+00]\n"," [9.585600e+04 0.000000e+00 1.115500e+04 7.800000e+01 6.000000e+02\n","  4.170000e+02 0.000000e+00 1.762700e+04 0.000000e+00]\n"," [6.206220e+05 0.000000e+00 2.671600e+04 0.000000e+00 9.300000e+01\n","  3.320000e+02 0.000000e+00 5.775000e+03 0.000000e+00]\n"," [1.516500e+04 0.000000e+00 1.933000e+03 5.160000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.137000e+03 0.000000e+00]\n"," [3.888730e+05 0.000000e+00 2.423000e+04 4.456000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.038640e+05 0.000000e+00]\n"," [2.456200e+04 0.000000e+00 1.155590e+05 4.148000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.457000e+03 0.000000e+00]]\n","\n","=>Epoches 36, learning rate = 0.0033,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.296: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 36, numImages:   362]\n","Loss: 53.582\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.319: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 36, numImages:    52]\n","Acc:0.7891053920601474, Acc_class:0.26832967681493725, mIoU:0.21526420179580402, fwIoU: 0.6473491593883308\n","Classwise_IoU:\n","[0.80650511 0.         0.42337313 0.32170053 0.04408578 0.0067689\n"," 0.         0.33191534 0.00302903]\n","Loss: 8.301\n","[[9.260686e+06 0.000000e+00 5.375200e+04 4.126900e+04 2.311000e+03\n","  8.600000e+02 0.000000e+00 1.022960e+05 0.000000e+00]\n"," [6.929000e+03 0.000000e+00 2.156100e+04 1.001700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.201000e+03 1.150000e+03]\n"," [6.499750e+05 0.000000e+00 8.452890e+05 5.339000e+04 3.910000e+02\n","  1.680000e+02 0.000000e+00 1.272570e+05 2.600000e+01]\n"," [2.155690e+05 0.000000e+00 1.474980e+05 3.025230e+05 0.000000e+00\n","  2.030000e+02 0.000000e+00 6.629600e+04 0.000000e+00]\n"," [9.828100e+04 0.000000e+00 6.684000e+03 4.450000e+02 5.900000e+03\n","  4.103000e+03 0.000000e+00 1.032000e+04 0.000000e+00]\n"," [6.244180e+05 0.000000e+00 1.251400e+04 2.922000e+03 5.231000e+03\n","  4.460000e+03 0.000000e+00 3.993000e+03 0.000000e+00]\n"," [1.454500e+04 0.000000e+00 6.500000e+01 3.398000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.743000e+03 0.000000e+00]\n"," [3.939350e+05 0.000000e+00 1.645100e+04 3.141500e+04 1.640000e+02\n","  2.400000e+01 0.000000e+00 3.794340e+05 0.000000e+00]\n"," [1.766300e+04 0.000000e+00 6.153700e+04 6.544200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.636000e+03 4.480000e+02]]\n","\n","=>Epoches 37, learning rate = 0.0033,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.292: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 37, numImages:   362]\n","Loss: 52.873\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.339: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 37, numImages:    52]\n","Acc:0.7780048912705114, Acc_class:0.2540694984922184, mIoU:0.1907346340692879, fwIoU: 0.6434771514943518\n","Classwise_IoU:\n","[0.82183376 0.         0.41836347 0.00170454 0.06651046 0.09508499\n"," 0.         0.3131145  0.        ]\n","Loss: 8.822\n","[[9.08410e+06 0.00000e+00 1.88559e+05 3.10000e+02 2.73000e+03 1.43370e+04\n","  0.00000e+00 1.71138e+05 0.00000e+00]\n"," [4.66400e+03 0.00000e+00 3.02850e+04 0.00000e+00 0.00000e+00 0.00000e+00\n","  0.00000e+00 8.90900e+03 0.00000e+00]\n"," [4.24396e+05 0.00000e+00 1.05610e+06 0.00000e+00 6.37000e+02 1.32130e+04\n","  0.00000e+00 1.82150e+05 0.00000e+00]\n"," [1.60911e+05 0.00000e+00 4.02798e+05 1.24900e+03 0.00000e+00 9.39000e+02\n","  0.00000e+00 1.66192e+05 0.00000e+00]\n"," [8.80190e+04 0.00000e+00 1.61890e+04 2.30000e+01 8.77100e+03 6.75300e+03\n","  0.00000e+00 5.97800e+03 0.00000e+00]\n"," [5.34111e+05 0.00000e+00 4.50140e+04 0.00000e+00 1.78500e+03 6.55360e+04\n","  0.00000e+00 7.09200e+03 0.00000e+00]\n"," [1.27960e+04 0.00000e+00 2.05900e+03 0.00000e+00 0.00000e+00 0.00000e+00\n","  0.00000e+00 8.89600e+03 0.00000e+00]\n"," [3.50494e+05 0.00000e+00 3.84070e+04 1.00000e+00 9.89000e+02 4.56000e+02\n","  0.00000e+00 4.31076e+05 0.00000e+00]\n"," [1.68870e+04 0.00000e+00 1.24553e+05 3.28000e+02 0.00000e+00 0.00000e+00\n","  0.00000e+00 4.95800e+03 0.00000e+00]]\n","\n","=>Epoches 38, learning rate = 0.0033,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.308: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 38, numImages:   362]\n","Loss: 55.696\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.351: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 38, numImages:    52]\n","Acc:0.7585666654097967, Acc_class:0.21110916188475726, mIoU:0.16288544359529905, fwIoU: 0.6068195809790575\n","Classwise_IoU:\n","[0.79438844 0.         0.33563856 0.05306087 0.06473979 0.00308624\n"," 0.         0.21505509 0.        ]\n","Loss: 9.137\n","[[9.35985e+06 0.00000e+00 2.53030e+04 2.61100e+03 2.42400e+03 5.45000e+02\n","  0.00000e+00 7.04410e+04 0.00000e+00]\n"," [9.87500e+03 0.00000e+00 1.31280e+04 9.00000e+00 0.00000e+00 0.00000e+00\n","  0.00000e+00 2.08460e+04 0.00000e+00]\n"," [7.18474e+05 0.00000e+00 6.36462e+05 9.78000e+02 3.36000e+02 1.10000e+02\n","  0.00000e+00 3.20136e+05 0.00000e+00]\n"," [3.31349e+05 0.00000e+00 7.84450e+04 4.01310e+04 0.00000e+00 9.80000e+01\n","  0.00000e+00 2.82066e+05 0.00000e+00]\n"," [1.03333e+05 0.00000e+00 5.62300e+03 1.35000e+02 8.36600e+03 2.81900e+03\n","  0.00000e+00 5.45700e+03 0.00000e+00]\n"," [6.34470e+05 0.00000e+00 1.44630e+04 9.50000e+01 1.30000e+01 2.02800e+03\n","  0.00000e+00 2.46900e+03 0.00000e+00]\n"," [1.60460e+04 0.00000e+00 0.00000e+00 2.20000e+01 0.00000e+00 0.00000e+00\n","  0.00000e+00 7.68300e+03 0.00000e+00]\n"," [4.76722e+05 0.00000e+00 9.87500e+03 1.20000e+02 7.19000e+02 0.00000e+00\n","  0.00000e+00 3.33987e+05 0.00000e+00]\n"," [3.10170e+04 0.00000e+00 7.29390e+04 2.02610e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 2.25090e+04 0.00000e+00]]\n","\n","=>Epoches 39, learning rate = 0.0032,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.295: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 39, numImages:   362]\n","Loss: 53.319\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.333: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 39, numImages:    52]\n","Acc:0.7761536386241423, Acc_class:0.23112974373765663, mIoU:0.18497635909832122, fwIoU: 0.6260784157227334\n","Classwise_IoU:\n","[8.00901456e-01 0.00000000e+00 3.81443423e-01 1.55209672e-01\n"," 4.54630921e-02 9.18079744e-06 0.00000000e+00 2.81760408e-01\n"," 0.00000000e+00]\n","Loss: 8.666\n","[[9.350257e+06 0.000000e+00 5.281700e+04 1.039400e+04 1.541000e+03\n","  0.000000e+00 0.000000e+00 4.616500e+04 0.000000e+00]\n"," [9.656000e+03 0.000000e+00 2.998300e+04 8.150000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.404000e+03 0.000000e+00]\n"," [6.856230e+05 0.000000e+00 8.260760e+05 4.841000e+03 1.170000e+02\n","  0.000000e+00 0.000000e+00 1.598390e+05 0.000000e+00]\n"," [2.750510e+05 0.000000e+00 2.532470e+05 1.219560e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.183500e+04 0.000000e+00]\n"," [1.063500e+05 0.000000e+00 8.804000e+03 1.990000e+02 5.803000e+03\n","  0.000000e+00 0.000000e+00 4.577000e+03 0.000000e+00]\n"," [6.285220e+05 0.000000e+00 2.281900e+04 4.670000e+02 0.000000e+00\n","  6.000000e+00 0.000000e+00 1.724000e+03 0.000000e+00]\n"," [1.531700e+04 0.000000e+00 1.725000e+03 1.102000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.607000e+03 0.000000e+00]\n"," [4.707980e+05 0.000000e+00 2.564100e+04 7.333000e+03 2.510000e+02\n","  0.000000e+00 0.000000e+00 3.174000e+05 0.000000e+00]\n"," [2.217500e+04 0.000000e+00 9.412600e+04 2.851000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.915000e+03 0.000000e+00]]\n","\n","=>Epoches 40, learning rate = 0.0032,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.293: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 40, numImages:   362]\n","Loss: 53.087\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.338: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 40, numImages:    52]\n","Acc:0.7841334480300316, Acc_class:0.2580703321056563, mIoU:0.20487095495808852, fwIoU: 0.6443937782870973\n","Classwise_IoU:\n","[8.11465431e-01 0.00000000e+00 4.21989814e-01 2.81275484e-01\n"," 6.13765172e-02 2.62445565e-04 0.00000000e+00 2.67468903e-01\n"," 0.00000000e+00]\n","Loss: 8.798\n","[[9.221326e+06 0.000000e+00 1.142380e+05 6.416100e+04 5.570000e+03\n","  1.410000e+02 0.000000e+00 5.573800e+04 0.000000e+00]\n"," [6.484000e+03 0.000000e+00 3.207200e+04 3.291000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.011000e+03 0.000000e+00]\n"," [5.918400e+05 0.000000e+00 9.535400e+05 1.162600e+04 1.874000e+03\n","  0.000000e+00 0.000000e+00 1.176160e+05 0.000000e+00]\n"," [1.728700e+05 0.000000e+00 2.536670e+05 2.666230e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.892900e+04 0.000000e+00]\n"," [9.247100e+04 0.000000e+00 1.426300e+04 3.245000e+03 9.335000e+03\n","  1.695000e+03 0.000000e+00 4.724000e+03 0.000000e+00]\n"," [6.033100e+05 0.000000e+00 2.881700e+04 2.547000e+03 1.725900e+04\n","  1.720000e+02 0.000000e+00 1.433000e+03 0.000000e+00]\n"," [1.357800e+04 0.000000e+00 3.393000e+03 3.072000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.708000e+03 0.000000e+00]\n"," [4.080980e+05 0.000000e+00 8.848400e+04 4.347900e+04 1.658000e+03\n","  0.000000e+00 0.000000e+00 2.797040e+05 0.000000e+00]\n"," [1.396900e+04 0.000000e+00 4.819800e+04 8.439700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.620000e+02 0.000000e+00]]\n","\n","=>Epoches 41, learning rate = 0.0031,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.306: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 41, numImages:   362]\n","Loss: 55.316\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.353: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 41, numImages:    52]\n","Acc:0.7577564226789629, Acc_class:0.20196066382120426, mIoU:0.162736338053932, fwIoU: 0.5925334304057632\n","Classwise_IoU:\n","[7.71166780e-01 0.00000000e+00 3.26656531e-01 1.03031836e-01\n"," 3.90742954e-02 1.52716055e-06 0.00000000e+00 2.24696073e-01\n"," 0.00000000e+00]\n","Loss: 9.172\n","[[9.397379e+06 0.000000e+00 2.062800e+04 3.975000e+03 1.208000e+03\n","  9.200000e+01 0.000000e+00 3.789200e+04 0.000000e+00]\n"," [1.453600e+04 0.000000e+00 2.398800e+04 1.547000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.787000e+03 0.000000e+00]\n"," [8.934830e+05 0.000000e+00 6.516690e+05 5.998000e+03 2.090000e+02\n","  0.000000e+00 0.000000e+00 1.251370e+05 0.000000e+00]\n"," [4.448290e+05 0.000000e+00 1.582600e+05 7.945300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.954700e+04 0.000000e+00]\n"," [1.064090e+05 0.000000e+00 5.002000e+03 5.500000e+01 4.969000e+03\n","  1.180000e+03 0.000000e+00 8.118000e+03 0.000000e+00]\n"," [6.425010e+05 0.000000e+00 9.322000e+03 3.900000e+01 0.000000e+00\n","  1.000000e+00 0.000000e+00 1.675000e+03 0.000000e+00]\n"," [1.876700e+04 0.000000e+00 1.066000e+03 1.336000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.582000e+03 0.000000e+00]\n"," [5.646780e+05 0.000000e+00 1.305200e+04 7.410000e+03 1.800000e+01\n","  0.000000e+00 0.000000e+00 2.362650e+05 0.000000e+00]\n"," [3.954600e+04 0.000000e+00 8.715300e+04 1.870100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.326000e+03 0.000000e+00]]\n","\n","=>Epoches 42, learning rate = 0.0031,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.301: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 42, numImages:   362]\n","Loss: 54.415\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.330: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 42, numImages:    52]\n","Acc:0.7789742888234732, Acc_class:0.23499348552501698, mIoU:0.18816176811476765, fwIoU: 0.6323709305114347\n","Classwise_IoU:\n","[0.80622558 0.         0.42569357 0.20905138 0.06636372 0.01146559\n"," 0.         0.17465608 0.        ]\n","Loss: 8.572\n","[[9.301069e+06 0.000000e+00 8.537900e+04 4.487200e+04 2.937000e+03\n","  1.251000e+03 0.000000e+00 2.566600e+04 0.000000e+00]\n"," [7.078000e+03 0.000000e+00 3.262200e+04 3.419000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.190000e+02 2.000000e+01]\n"," [6.065400e+05 0.000000e+00 9.873660e+05 3.873600e+04 3.750000e+02\n","  5.590000e+02 0.000000e+00 4.292000e+04 0.000000e+00]\n"," [2.179320e+05 0.000000e+00 3.127580e+05 1.983030e+05 5.500000e+01\n","  1.510000e+02 0.000000e+00 2.890000e+03 0.000000e+00]\n"," [9.397100e+04 0.000000e+00 1.411300e+04 1.868000e+03 8.704000e+03\n","  4.437000e+03 0.000000e+00 2.640000e+03 0.000000e+00]\n"," [6.144290e+05 0.000000e+00 2.859400e+04 2.225000e+03 3.000000e+00\n","  7.567000e+03 0.000000e+00 7.200000e+02 0.000000e+00]\n"," [1.594200e+04 0.000000e+00 2.108000e+03 3.385000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.316000e+03 0.000000e+00]\n"," [5.005510e+05 0.000000e+00 6.928200e+04 9.240900e+04 2.053000e+03\n","  3.900000e+01 0.000000e+00 1.570890e+05 0.000000e+00]\n"," [1.894200e+04 0.000000e+00 9.807700e+04 2.958200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.250000e+02 0.000000e+00]]\n","\n","=>Epoches 43, learning rate = 0.0030,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.299: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 43, numImages:   362]\n","Loss: 54.036\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.348: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 43, numImages:    52]\n","Acc:0.7668731148776291, Acc_class:0.23770477867688536, mIoU:0.17632462272926394, fwIoU: 0.6262979106826485\n","Classwise_IoU:\n","[8.11986591e-01 0.00000000e+00 3.37674061e-01 1.03658928e-01\n"," 3.95602323e-02 5.70519401e-04 0.00000000e+00 2.93471273e-01\n"," 0.00000000e+00]\n","Loss: 9.047\n","[[9.208528e+06 0.000000e+00 6.880000e+04 7.104000e+03 1.290000e+03\n","  2.210000e+02 0.000000e+00 1.752310e+05 0.000000e+00]\n"," [8.288000e+03 0.000000e+00 2.165200e+04 3.200000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.388600e+04 0.000000e+00]\n"," [5.824820e+05 0.000000e+00 7.171130e+05 1.015000e+03 2.010000e+02\n","  0.000000e+00 0.000000e+00 3.756850e+05 0.000000e+00]\n"," [2.335220e+05 0.000000e+00 1.927480e+05 7.910700e+04 0.000000e+00\n","  1.000000e+01 0.000000e+00 2.267020e+05 0.000000e+00]\n"," [9.192200e+04 0.000000e+00 1.307600e+04 3.270000e+02 5.034000e+03\n","  1.774000e+03 0.000000e+00 1.360000e+04 0.000000e+00]\n"," [5.955910e+05 0.000000e+00 4.976600e+04 3.030000e+02 0.000000e+00\n","  3.740000e+02 0.000000e+00 7.504000e+03 0.000000e+00]\n"," [1.350000e+04 0.000000e+00 5.050000e+02 5.740000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.172000e+03 0.000000e+00]\n"," [3.341730e+05 0.000000e+00 2.132000e+03 7.530000e+02 2.500000e+01\n","  0.000000e+00 0.000000e+00 4.843400e+05 0.000000e+00]\n"," [2.008700e+04 0.000000e+00 9.850900e+04 2.095000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.180000e+03 0.000000e+00]]\n","\n","=>Epoches 44, learning rate = 0.0030,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.297: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 44, numImages:   362]\n","Loss: 53.767\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.339: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 44, numImages:    52]\n","Acc:0.7690845484782081, Acc_class:0.22386320504532323, mIoU:0.1772334239067881, fwIoU: 0.6168416624472374\n","Classwise_IoU:\n","[0.79723843 0.         0.35355807 0.06061167 0.069031   0.00672383\n"," 0.         0.30112458 0.00681324]\n","Loss: 8.823\n","[[9.321448e+06 0.000000e+00 7.346200e+04 6.002000e+03 2.998000e+03\n","  1.026000e+03 0.000000e+00 5.623800e+04 0.000000e+00]\n"," [1.060200e+04 0.000000e+00 3.033400e+04 1.980000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.677000e+03 4.700000e+01]\n"," [7.381500e+05 0.000000e+00 8.215880e+05 2.660000e+03 3.940000e+02\n","  2.910000e+02 0.000000e+00 1.134130e+05 0.000000e+00]\n"," [2.848840e+05 0.000000e+00 3.383370e+05 4.586400e+04 4.400000e+01\n","  2.630000e+02 0.000000e+00 6.269700e+04 0.000000e+00]\n"," [9.489600e+04 0.000000e+00 1.352500e+04 1.190000e+02 9.051000e+03\n","  4.273000e+03 0.000000e+00 3.869000e+03 0.000000e+00]\n"," [6.167470e+05 0.000000e+00 3.092800e+04 1.540000e+02 3.200000e+01\n","  4.434000e+03 0.000000e+00 1.243000e+03 0.000000e+00]\n"," [1.541800e+04 0.000000e+00 3.172000e+03 8.810000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.280000e+03 0.000000e+00]\n"," [4.486250e+05 0.000000e+00 4.506100e+04 4.394000e+03 1.914000e+03\n","  5.500000e+01 0.000000e+00 3.213740e+05 0.000000e+00]\n"," [2.167500e+04 0.000000e+00 1.124560e+05 1.018900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.406000e+03 1.000000e+03]]\n","\n","=>Epoches 45, learning rate = 0.0029,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.296: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 45, numImages:   362]\n","Loss: 53.618\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.389: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 45, numImages:    52]\n","Acc:0.7574548469439205, Acc_class:0.22419709974036983, mIoU:0.16199997505959746, fwIoU: 0.6152853623662845\n","Classwise_IoU:\n","[8.07819200e-01 0.00000000e+00 3.31283215e-01 4.91740132e-05\n"," 5.77353692e-02 2.53564413e-04 0.00000000e+00 2.60859253e-01\n"," 0.00000000e+00]\n","Loss: 10.118\n","[[9.197642e+06 0.000000e+00 5.084700e+04 0.000000e+00 1.971000e+03\n","  4.100000e+01 0.000000e+00 2.106730e+05 0.000000e+00]\n"," [9.413000e+03 0.000000e+00 2.092900e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.351600e+04 0.000000e+00]\n"," [6.289310e+05 0.000000e+00 6.863360e+05 0.000000e+00 2.250000e+02\n","  0.000000e+00 0.000000e+00 3.610040e+05 0.000000e+00]\n"," [2.098770e+05 0.000000e+00 1.705980e+05 3.600000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.515780e+05 0.000000e+00]\n"," [9.524000e+04 0.000000e+00 6.729000e+03 0.000000e+00 7.400000e+03\n","  1.087000e+03 0.000000e+00 1.527700e+04 0.000000e+00]\n"," [6.039840e+05 0.000000e+00 3.855700e+04 0.000000e+00 0.000000e+00\n","  1.660000e+02 0.000000e+00 1.083100e+04 0.000000e+00]\n"," [1.401500e+04 0.000000e+00 6.690000e+02 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.067000e+03 0.000000e+00]\n"," [3.430560e+05 0.000000e+00 4.096000e+03 0.000000e+00 2.420000e+02\n","  0.000000e+00 0.000000e+00 4.740290e+05 0.000000e+00]\n"," [2.007800e+04 0.000000e+00 1.028290e+05 5.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.381400e+04 0.000000e+00]]\n","\n","=>Epoches 46, learning rate = 0.0029,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.301: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 46, numImages:   362]\n","Loss: 54.533\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.342: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 46, numImages:    52]\n","Acc:0.7731483308327466, Acc_class:0.21984853850578145, mIoU:0.17171145793212247, fwIoU: 0.6234338880246563\n","Classwise_IoU:\n","[0.80621317 0.         0.39221746 0.00190643 0.0525302  0.01197006\n"," 0.         0.28056581 0.        ]\n","Loss: 8.902\n","[[9.296157e+06 0.000000e+00 1.192930e+05 1.810000e+02 2.538000e+03\n","  3.444000e+03 0.000000e+00 3.956100e+04 0.000000e+00]\n"," [9.033000e+03 0.000000e+00 3.379000e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.035000e+03 0.000000e+00]\n"," [6.220410e+05 0.000000e+00 9.920160e+05 0.000000e+00 3.910000e+02\n","  1.469000e+03 0.000000e+00 6.057900e+04 0.000000e+00]\n"," [2.449370e+05 0.000000e+00 4.334300e+05 1.397000e+03 0.000000e+00\n","  3.970000e+02 0.000000e+00 5.192800e+04 0.000000e+00]\n"," [9.429000e+04 0.000000e+00 1.474100e+04 1.800000e+01 6.818000e+03\n","  7.566000e+03 0.000000e+00 2.300000e+03 0.000000e+00]\n"," [6.021410e+05 0.000000e+00 4.232900e+04 0.000000e+00 9.900000e+01\n","  8.005000e+03 0.000000e+00 9.640000e+02 0.000000e+00]\n"," [1.502000e+04 0.000000e+00 4.163000e+03 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.568000e+03 0.000000e+00]\n"," [4.607660e+05 0.000000e+00 8.131000e+04 0.000000e+00 1.031000e+03\n","  2.338000e+03 0.000000e+00 2.759780e+05 0.000000e+00]\n"," [2.124200e+04 0.000000e+00 1.236980e+05 4.960000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.290000e+03 0.000000e+00]]\n","\n","=>Epoches 47, learning rate = 0.0028,                 previous best = 0.2198\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.275: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 47, numImages:   362]\n","Loss: 49.722\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.340: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 47, numImages:    52]\n","Acc:0.7976687691471728, Acc_class:0.28362223103418066, mIoU:0.22659829350719696, fwIoU: 0.6584445050663055\n","Classwise_IoU:\n","[0.81172816 0.         0.46882855 0.41806325 0.05885425 0.00145495\n"," 0.         0.28045547 0.        ]\n","Loss: 8.833\n","[[9.254831e+06 0.000000e+00 7.778200e+04 7.168400e+04 2.080000e+03\n","  6.860000e+02 0.000000e+00 5.411100e+04 0.000000e+00]\n"," [7.618000e+03 0.000000e+00 1.571600e+04 1.750000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.024000e+03 0.000000e+00]\n"," [6.235260e+05 0.000000e+00 9.124660e+05 5.122800e+04 3.140000e+02\n","  1.280000e+02 0.000000e+00 8.883400e+04 0.000000e+00]\n"," [1.899170e+05 0.000000e+00 4.874500e+04 4.550560e+05 0.000000e+00\n","  1.780000e+02 0.000000e+00 3.819300e+04 0.000000e+00]\n"," [9.539200e+04 0.000000e+00 1.316500e+04 1.092000e+03 7.550000e+03\n","  3.865000e+03 0.000000e+00 4.669000e+03 0.000000e+00]\n"," [6.020010e+05 0.000000e+00 4.455500e+04 4.829000e+03 7.000000e+00\n","  9.580000e+02 0.000000e+00 1.188000e+03 0.000000e+00]\n"," [1.393200e+04 0.000000e+00 1.276000e+03 3.823000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.720000e+03 0.000000e+00]\n"," [3.910800e+05 0.000000e+00 5.425500e+04 9.082600e+04 1.490000e+02\n","  4.600000e+01 0.000000e+00 2.850670e+05 0.000000e+00]\n"," [1.675200e+04 0.000000e+00 1.427800e+04 1.154150e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.810000e+02 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 48, learning rate = 0.0028,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.293: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 48, numImages:   362]\n","Loss: 52.977\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.353: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 48, numImages:    52]\n","Acc:0.7793854022437177, Acc_class:0.2780367769635761, mIoU:0.22430243442977224, fwIoU: 0.6304275862432929\n","Classwise_IoU:\n","[0.78941795 0.         0.347806   0.35989826 0.09201518 0.04513502\n"," 0.         0.3177706  0.06667891]\n","Loss: 9.186\n","[[9.267012e+06 0.000000e+00 2.227000e+04 2.523500e+04 5.457000e+03\n","  3.578000e+03 0.000000e+00 1.375400e+05 8.200000e+01]\n"," [1.525400e+04 0.000000e+00 1.402600e+04 1.311700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.353000e+03 1.080000e+02]\n"," [8.223390e+05 0.000000e+00 6.187340e+05 4.372700e+04 1.936000e+03\n","  4.778000e+03 0.000000e+00 1.849820e+05 0.000000e+00]\n"," [3.147480e+05 0.000000e+00 2.791200e+04 3.408600e+05 2.090000e+02\n","  5.740000e+02 0.000000e+00 4.771400e+04 7.200000e+01]\n"," [9.261100e+04 0.000000e+00 6.125000e+03 5.920000e+02 1.326500e+04\n","  2.714000e+03 0.000000e+00 1.042600e+04 0.000000e+00]\n"," [5.975360e+05 0.000000e+00 1.153700e+04 5.490000e+02 7.292000e+03\n","  3.002300e+04 0.000000e+00 6.601000e+03 0.000000e+00]\n"," [1.630500e+04 0.000000e+00 7.600000e+01 3.350000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.020000e+03 0.000000e+00]\n"," [3.957850e+05 0.000000e+00 8.075000e+03 2.800000e+04 3.534000e+03\n","  0.000000e+00 0.000000e+00 3.860290e+05 0.000000e+00]\n"," [2.329200e+04 0.000000e+00 1.244600e+04 1.004420e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.450000e+02 9.801000e+03]]\n","\n","=>Epoches 49, learning rate = 0.0027,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.287: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 49, numImages:   362]\n","Loss: 51.911\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.336: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 49, numImages:    52]\n","Acc:0.7795422187029861, Acc_class:0.2549094215971512, mIoU:0.2170711030071653, fwIoU: 0.6232673721326605\n","Classwise_IoU:\n","[0.77824196 0.         0.43062931 0.27895619 0.07456227 0.05838419\n"," 0.         0.21292355 0.11994245]\n","Loss: 8.724\n","[[9.389869e+06 0.000000e+00 2.869400e+04 1.008900e+04 2.814000e+03\n","  6.810000e+03 0.000000e+00 2.289200e+04 6.000000e+00]\n"," [1.592900e+04 0.000000e+00 1.210000e+04 8.247000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.202000e+03 6.380000e+03]\n"," [7.923160e+05 0.000000e+00 7.647800e+05 1.762900e+04 4.310000e+02\n","  1.440700e+04 0.000000e+00 8.126400e+04 5.669000e+03]\n"," [4.456860e+05 0.000000e+00 1.761700e+04 2.398920e+05 0.000000e+00\n","  3.170000e+02 0.000000e+00 2.819000e+04 3.870000e+02]\n"," [1.035240e+05 0.000000e+00 3.853000e+03 1.890000e+02 9.769000e+03\n","  5.936000e+03 0.000000e+00 2.462000e+03 0.000000e+00]\n"," [6.031280e+05 0.000000e+00 9.495000e+03 2.800000e+01 5.640000e+02\n","  3.976600e+04 0.000000e+00 5.570000e+02 0.000000e+00]\n"," [1.945100e+04 0.000000e+00 3.000000e+00 1.608000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.689000e+03 0.000000e+00]\n"," [5.887730e+05 0.000000e+00 1.411600e+04 1.225400e+04 1.476000e+03\n","  1.010000e+02 0.000000e+00 2.047030e+05 0.000000e+00]\n"," [3.550700e+04 0.000000e+00 1.358500e+04 7.783000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.130000e+02 1.909100e+04]]\n","\n","=>Epoches 50, learning rate = 0.0027,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.277: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 50, numImages:   362]\n","Loss: 50.215\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.316: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 50, numImages:    52]\n","Acc:0.7969373730890095, Acc_class:0.2689155344197238, mIoU:0.2178953780847939, fwIoU: 0.6579699618620858\n","Classwise_IoU:\n","[0.81412678 0.         0.48154435 0.32060342 0.03399003 0.\n"," 0.         0.31079382 0.        ]\n","Loss: 8.219\n","[[9.286351e+06 0.000000e+00 7.843600e+04 2.500600e+04 1.133000e+03\n","  9.900000e+01 0.000000e+00 7.014900e+04 0.000000e+00]\n"," [8.110000e+03 0.000000e+00 3.173900e+04 1.077000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.932000e+03 0.000000e+00]\n"," [5.311550e+05 0.000000e+00 9.718480e+05 8.869000e+03 7.400000e+01\n","  0.000000e+00 0.000000e+00 1.645500e+05 0.000000e+00]\n"," [2.379950e+05 0.000000e+00 1.195420e+05 2.788740e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.567800e+04 0.000000e+00]\n"," [9.987800e+04 0.000000e+00 1.091200e+04 9.670000e+02 4.315000e+03\n","  1.285000e+03 0.000000e+00 8.376000e+03 0.000000e+00]\n"," [6.115140e+05 0.000000e+00 3.978000e+04 3.570000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.887000e+03 0.000000e+00]\n"," [1.396700e+04 0.000000e+00 7.550000e+02 2.083000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.946000e+03 0.000000e+00]\n"," [4.211360e+05 0.000000e+00 2.040800e+04 1.533900e+04 9.000000e+00\n","  0.000000e+00 0.000000e+00 3.645310e+05 0.000000e+00]\n"," [2.158800e+04 0.000000e+00 4.012200e+04 8.405400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.620000e+02 0.000000e+00]]\n","\n","=>Epoches 51, learning rate = 0.0026,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.287: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 51, numImages:   362]\n","Loss: 51.970\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.338: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 51, numImages:    52]\n","Acc:0.7692855746102899, Acc_class:0.22358748891430041, mIoU:0.17280730579259088, fwIoU: 0.6214648820231679\n","Classwise_IoU:\n","[8.03627139e-01 0.00000000e+00 3.73788955e-01 5.37151947e-02\n"," 4.43521788e-02 1.02223436e-04 0.00000000e+00 2.79680061e-01\n"," 0.00000000e+00]\n","Loss: 8.791\n","[[9.285603e+06 0.000000e+00 9.255700e+04 7.861000e+03 1.042500e+04\n","  1.450000e+02 0.000000e+00 6.458300e+04 0.000000e+00]\n"," [1.168600e+04 0.000000e+00 2.573800e+04 4.400000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.390000e+03 0.000000e+00]\n"," [6.489030e+05 0.000000e+00 8.590500e+05 1.882000e+03 6.492000e+03\n","  0.000000e+00 0.000000e+00 1.601690e+05 0.000000e+00]\n"," [2.592580e+05 0.000000e+00 3.136660e+05 4.126600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.178990e+05 0.000000e+00]\n"," [9.686100e+04 0.000000e+00 1.240200e+04 1.100000e+02 6.858000e+03\n","  1.744000e+03 0.000000e+00 7.758000e+03 0.000000e+00]\n"," [5.811960e+05 0.000000e+00 4.835500e+04 4.320000e+02 1.195200e+04\n","  6.700000e+01 0.000000e+00 1.153600e+04 0.000000e+00]\n"," [1.606300e+04 0.000000e+00 2.373000e+03 6.420000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.673000e+03 0.000000e+00]\n"," [4.586450e+05 0.000000e+00 2.310200e+04 4.986000e+03 2.400000e+01\n","  0.000000e+00 0.000000e+00 3.346660e+05 0.000000e+00]\n"," [2.083000e+04 0.000000e+00 1.035330e+05 2.019100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.172000e+03 0.000000e+00]]\n","\n","=>Epoches 52, learning rate = 0.0026,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.284: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 52, numImages:   362]\n","Loss: 51.492\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.355: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 52, numImages:    52]\n","Acc:0.764935196657778, Acc_class:0.2083854905693097, mIoU:0.1609259731384152, fwIoU: 0.6121731576601221\n","Classwise_IoU:\n","[7.98657656e-01 0.00000000e+00 3.73466661e-01 0.00000000e+00\n"," 4.32952718e-02 1.04974258e-04 0.00000000e+00 2.30376088e-01\n"," 2.43310661e-03]\n","Loss: 9.241\n","[[9.259438e+06 0.000000e+00 1.738030e+05 0.000000e+00 5.054000e+03\n","  3.050000e+02 0.000000e+00 2.257400e+04 0.000000e+00]\n"," [1.255800e+04 0.000000e+00 3.088500e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.150000e+02 0.000000e+00]\n"," [6.422560e+05 0.000000e+00 9.918550e+05 0.000000e+00 3.740000e+03\n","  2.400000e+01 0.000000e+00 3.862100e+04 0.000000e+00]\n"," [2.653830e+05 0.000000e+00 4.415680e+05 0.000000e+00 0.000000e+00\n","  1.400000e+01 0.000000e+00 2.512400e+04 0.000000e+00]\n"," [9.383900e+04 0.000000e+00 1.984500e+04 0.000000e+00 5.843000e+03\n","  3.242000e+03 0.000000e+00 2.964000e+03 0.000000e+00]\n"," [5.784630e+05 0.000000e+00 7.444400e+04 0.000000e+00 3.480000e+02\n","  6.900000e+01 0.000000e+00 2.140000e+02 0.000000e+00]\n"," [1.686300e+04 0.000000e+00 5.579000e+03 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.309000e+03 0.000000e+00]\n"," [5.035140e+05 0.000000e+00 1.072240e+05 8.000000e+00 8.200000e+01\n","  1.810000e+02 0.000000e+00 2.104140e+05 0.000000e+00]\n"," [1.970100e+04 0.000000e+00 1.259620e+05 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.060000e+02 3.570000e+02]]\n","\n","=>Epoches 53, learning rate = 0.0025,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.275: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 53, numImages:   362]\n","Loss: 49.813\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.332: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 53, numImages:    52]\n","Acc:0.7875880868596576, Acc_class:0.2835074430337713, mIoU:0.21525687491888862, fwIoU: 0.6472984545162419\n","Classwise_IoU:\n","[0.81020955 0.         0.40963366 0.40165783 0.06790313 0.00217192\n"," 0.         0.24573578 0.        ]\n","Loss: 8.639\n","[[9.220623e+06 0.000000e+00 6.749300e+04 1.248470e+05 2.887000e+03\n","  5.690000e+02 0.000000e+00 4.475500e+04 0.000000e+00]\n"," [7.249000e+03 0.000000e+00 1.711000e+03 3.143700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.461000e+03 0.000000e+00]\n"," [6.264380e+05 0.000000e+00 7.433110e+05 1.934060e+05 8.700000e+02\n","  2.270000e+02 0.000000e+00 1.122440e+05 0.000000e+00]\n"," [1.560010e+05 0.000000e+00 1.311000e+03 5.552060e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.957100e+04 0.000000e+00]\n"," [9.095100e+04 0.000000e+00 1.410000e+04 3.540000e+03 8.860000e+03\n","  3.609000e+03 0.000000e+00 4.673000e+03 0.000000e+00]\n"," [5.953900e+05 0.000000e+00 4.827400e+04 7.034000e+03 1.740000e+02\n","  1.429000e+03 0.000000e+00 1.237000e+03 0.000000e+00]\n"," [1.499700e+04 0.000000e+00 0.000000e+00 4.678000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.076000e+03 0.000000e+00]\n"," [4.146960e+05 0.000000e+00 5.018000e+03 1.523460e+05 8.160000e+02\n","  0.000000e+00 0.000000e+00 2.485470e+05 0.000000e+00]\n"," [1.364500e+04 0.000000e+00 1.720000e+02 1.329090e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00]]\n","\n","=>Epoches 54, learning rate = 0.0025,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.275: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 54, numImages:   362]\n","Loss: 49.831\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.336: 100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 54, numImages:    52]\n","Acc:0.7702846401420321, Acc_class:0.2158222892700172, mIoU:0.1718938479993214, fwIoU: 0.6150554054968334\n","Classwise_IoU:\n","[0.7947708  0.         0.39123444 0.03035882 0.07488691 0.00131567\n"," 0.         0.25447799 0.        ]\n","Loss: 8.724\n","[[9.348695e+06 0.000000e+00 7.385600e+04 3.731000e+03 2.983000e+03\n","  4.450000e+02 0.000000e+00 3.146400e+04 0.000000e+00]\n"," [8.407000e+03 0.000000e+00 3.251500e+04 3.950000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.541000e+03 0.000000e+00]\n"," [6.951920e+05 0.000000e+00 9.136400e+05 1.884000e+03 3.410000e+02\n","  6.000000e+00 0.000000e+00 6.543300e+04 0.000000e+00]\n"," [2.909330e+05 0.000000e+00 3.860280e+05 2.324900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.187900e+04 0.000000e+00]\n"," [1.066140e+05 0.000000e+00 4.836000e+03 4.600000e+01 9.817000e+03\n","  2.712000e+03 0.000000e+00 1.708000e+03 0.000000e+00]\n"," [6.400540e+05 0.000000e+00 1.145400e+04 1.200000e+01 3.500000e+01\n","  8.640000e+02 0.000000e+00 1.119000e+03 0.000000e+00]\n"," [1.475700e+04 0.000000e+00 1.614000e+03 1.390000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.990000e+03 0.000000e+00]\n"," [5.194370e+05 0.000000e+00 4.849100e+04 6.579000e+03 1.999000e+03\n","  0.000000e+00 0.000000e+00 2.449170e+05 0.000000e+00]\n"," [2.618800e+04 0.000000e+00 9.998500e+04 1.968100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.720000e+02 0.000000e+00]]\n","\n","=>Epoches 55, learning rate = 0.0024,                 previous best = 0.2266\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.287: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 55, numImages:   362]\n","Loss: 51.925\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.312: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 55, numImages:    52]\n","Acc:0.8039138056066342, Acc_class:0.3082031636470628, mIoU:0.24460093573256123, fwIoU: 0.67179615286245\n","Classwise_IoU:\n","[0.81941968 0.         0.47288559 0.43226264 0.0749938  0.04792025\n"," 0.         0.35392646 0.        ]\n","Loss: 8.111\n","[[9.197981e+06 0.000000e+00 7.216900e+04 6.333200e+04 4.763000e+03\n","  3.983000e+03 0.000000e+00 1.189460e+05 0.000000e+00]\n"," [7.176000e+03 0.000000e+00 1.686300e+04 1.621000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.606000e+03 3.000000e+00]\n"," [5.299650e+05 0.000000e+00 8.775910e+05 8.044700e+04 1.135000e+03\n","  3.798000e+03 0.000000e+00 1.835600e+05 0.000000e+00]\n"," [1.880750e+05 0.000000e+00 2.970000e+04 4.559100e+05 1.300000e+01\n","  2.840000e+02 0.000000e+00 5.810700e+04 0.000000e+00]\n"," [8.710100e+04 0.000000e+00 1.358600e+04 1.886000e+03 1.089300e+04\n","  4.775000e+03 0.000000e+00 7.492000e+03 0.000000e+00]\n"," [5.707460e+05 0.000000e+00 2.944500e+04 2.881000e+03 1.287200e+04\n","  3.193300e+04 0.000000e+00 5.661000e+03 0.000000e+00]\n"," [1.328300e+04 0.000000e+00 4.000000e+00 3.739000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.725000e+03 0.000000e+00]\n"," [3.501160e+05 0.000000e+00 7.634000e+03 3.585500e+04 7.360000e+02\n","  0.000000e+00 0.000000e+00 4.270820e+05 0.000000e+00]\n"," [1.735800e+04 0.000000e+00 9.924000e+03 1.182670e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.177000e+03 0.000000e+00]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 56, learning rate = 0.0024,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.267: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 56, numImages:   362]\n","Loss: 48.393\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.334: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 56, numImages:    52]\n","Acc:0.7906672723026473, Acc_class:0.2683093401260374, mIoU:0.21907531244018902, fwIoU: 0.6467573642162019\n","Classwise_IoU:\n","[0.80368907 0.         0.42473105 0.37505411 0.05881268 0.00758336\n"," 0.         0.30180754 0.        ]\n","Loss: 8.677\n","[[9.290542e+06 0.000000e+00 5.055100e+04 5.010700e+04 2.199000e+03\n","  4.110000e+02 0.000000e+00 6.736400e+04 0.000000e+00]\n"," [8.583000e+03 0.000000e+00 2.852000e+04 2.258000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.497000e+03 0.000000e+00]\n"," [6.804310e+05 0.000000e+00 8.571370e+05 1.652700e+04 4.380000e+02\n","  4.620000e+02 0.000000e+00 1.215010e+05 0.000000e+00]\n"," [2.118570e+05 0.000000e+00 1.410740e+05 3.353160e+05 0.000000e+00\n","  1.220000e+02 0.000000e+00 4.372000e+04 0.000000e+00]\n"," [9.791900e+04 0.000000e+00 7.055000e+03 1.612000e+03 7.654000e+03\n","  3.355000e+03 0.000000e+00 8.138000e+03 0.000000e+00]\n"," [6.232910e+05 0.000000e+00 1.965600e+04 1.416000e+03 1.136000e+03\n","  4.989000e+03 0.000000e+00 3.050000e+03 0.000000e+00]\n"," [1.541400e+04 0.000000e+00 1.890000e+02 3.384000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.764000e+03 0.000000e+00]\n"," [4.428740e+05 0.000000e+00 2.522900e+04 2.820800e+04 6.360000e+02\n","  0.000000e+00 0.000000e+00 3.244760e+05 0.000000e+00]\n"," [1.832800e+04 0.000000e+00 6.930000e+04 5.844600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.520000e+02 0.000000e+00]]\n","\n","=>Epoches 57, learning rate = 0.0023,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.279: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 57, numImages:   362]\n","Loss: 50.433\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.346: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 57, numImages:    52]\n","Acc:0.7891937383319347, Acc_class:0.2584310660645263, mIoU:0.21356612903674393, fwIoU: 0.6410103319855411\n","Classwise_IoU:\n","[7.94767325e-01 0.00000000e+00 4.51948227e-01 3.43526546e-01\n"," 4.14816794e-02 1.03302002e-03 0.00000000e+00 2.89215686e-01\n"," 1.22677644e-04]\n","Loss: 8.995\n","[[9.327499e+06 0.000000e+00 5.669900e+04 1.693400e+04 1.330000e+03\n","  1.390000e+02 0.000000e+00 5.857300e+04 0.000000e+00]\n"," [1.229600e+04 0.000000e+00 2.536900e+04 3.702000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.491000e+03 0.000000e+00]\n"," [6.697640e+05 0.000000e+00 8.587640e+05 2.416100e+04 1.730000e+02\n","  0.000000e+00 0.000000e+00 1.236340e+05 0.000000e+00]\n"," [3.499540e+05 0.000000e+00 4.201900e+04 3.015610e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.855500e+04 0.000000e+00]\n"," [1.000360e+05 0.000000e+00 1.176900e+04 4.290000e+02 5.279000e+03\n","  1.683000e+03 0.000000e+00 6.537000e+03 0.000000e+00]\n"," [6.122860e+05 0.000000e+00 3.872500e+04 3.430000e+02 1.000000e+01\n","  6.770000e+02 0.000000e+00 1.497000e+03 0.000000e+00]\n"," [1.767600e+04 0.000000e+00 5.200000e+02 1.884000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.671000e+03 0.000000e+00]\n"," [4.824200e+05 0.000000e+00 1.762500e+04 1.521200e+04 1.500000e+01\n","  0.000000e+00 0.000000e+00 3.061510e+05 0.000000e+00]\n"," [3.053200e+04 0.000000e+00 3.091600e+04 8.308500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.175000e+03 1.800000e+01]]\n","\n","=>Epoches 58, learning rate = 0.0023,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.289: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 58, numImages:   362]\n","Loss: 52.319\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.344: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 58, numImages:    52]\n","Acc:0.7740713264977142, Acc_class:0.23240633078798462, mIoU:0.18656292210458808, fwIoU: 0.6211195557641964\n","Classwise_IoU:\n","[7.91672015e-01 0.00000000e+00 3.72652897e-01 1.61907055e-01\n"," 3.21659187e-02 3.82736971e-03 0.00000000e+00 3.16329887e-01\n"," 5.11156850e-04]\n","Loss: 8.944\n","[[9.33167e+06 0.00000e+00 3.80470e+04 8.68100e+03 6.87000e+02 1.00000e+03\n","  0.00000e+00 8.10890e+04 0.00000e+00]\n"," [9.97000e+03 0.00000e+00 2.99310e+04 7.62000e+02 0.00000e+00 0.00000e+00\n","  0.00000e+00 3.19500e+03 0.00000e+00]\n"," [7.44181e+05 0.00000e+00 7.71788e+05 1.08410e+04 8.36000e+02 1.21000e+02\n","  0.00000e+00 1.48729e+05 0.00000e+00]\n"," [3.57575e+05 0.00000e+00 1.96896e+05 1.27790e+05 0.00000e+00 1.05000e+02\n","  0.00000e+00 4.97230e+04 0.00000e+00]\n"," [1.02890e+05 0.00000e+00 5.72200e+03 3.21000e+02 4.27900e+03 4.83600e+03\n","  0.00000e+00 7.68500e+03 0.00000e+00]\n"," [6.31865e+05 0.00000e+00 1.03330e+04 2.30000e+02 5.77300e+03 2.52500e+03\n","  0.00000e+00 2.81200e+03 0.00000e+00]\n"," [1.62830e+04 0.00000e+00 4.80000e+02 1.74500e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 5.24300e+03 0.00000e+00]\n"," [4.32909e+05 0.00000e+00 2.36800e+04 9.83700e+03 0.00000e+00 1.22000e+02\n","  0.00000e+00 3.54875e+05 0.00000e+00]\n"," [3.04460e+04 0.00000e+00 8.94790e+04 2.47740e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.95200e+03 7.50000e+01]]\n","\n","=>Epoches 59, learning rate = 0.0022,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.284: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 59, numImages:   362]\n","Loss: 51.452\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.328: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 59, numImages:    52]\n","Acc:0.7804449729144507, Acc_class:0.24519061561773833, mIoU:0.19876473142008605, fwIoU: 0.6344471512396862\n","Classwise_IoU:\n","[0.80423358 0.         0.39835082 0.11142769 0.06819726 0.1117018\n"," 0.         0.29497143 0.        ]\n","Loss: 8.541\n","[[9.295109e+06 0.000000e+00 7.508000e+04 1.000600e+04 2.646000e+03\n","  2.419500e+04 0.000000e+00 5.413800e+04 0.000000e+00]\n"," [9.409000e+03 0.000000e+00 3.161500e+04 4.510000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.383000e+03 0.000000e+00]\n"," [6.264490e+05 0.000000e+00 9.063740e+05 5.597000e+03 4.550000e+02\n","  1.611900e+04 0.000000e+00 1.215020e+05 0.000000e+00]\n"," [3.061690e+05 0.000000e+00 3.152590e+05 8.502100e+04 0.000000e+00\n","  1.641000e+03 0.000000e+00 2.399900e+04 0.000000e+00]\n"," [9.293700e+04 0.000000e+00 1.071000e+04 2.890000e+02 9.437000e+03\n","  7.299000e+03 0.000000e+00 5.061000e+03 0.000000e+00]\n"," [5.465340e+05 0.000000e+00 1.793700e+04 1.160000e+02 8.391000e+03\n","  7.871000e+04 0.000000e+00 1.850000e+03 0.000000e+00]\n"," [1.698400e+04 0.000000e+00 1.425000e+03 8.660000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.476000e+03 0.000000e+00]\n"," [4.723140e+05 0.000000e+00 3.375600e+04 6.775000e+03 1.153000e+03\n","  1.852000e+03 0.000000e+00 3.055730e+05 0.000000e+00]\n"," [2.575300e+04 0.000000e+00 1.130380e+05 6.826000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.109000e+03 0.000000e+00]]\n","\n","=>Epoches 60, learning rate = 0.0022,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.281: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 60, numImages:   362]\n","Loss: 50.924\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.312: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 60, numImages:    52]\n","Acc:0.8013195381616435, Acc_class:0.29796307804288447, mIoU:0.23687389923415914, fwIoU: 0.6674284765850212\n","Classwise_IoU:\n","[0.81678904 0.         0.48322253 0.41350688 0.07151502 0.00534733\n"," 0.         0.34148429 0.        ]\n","Loss: 8.107\n","[[9.217412e+06 0.000000e+00 6.274900e+04 3.821000e+04 4.050000e+03\n","  6.010000e+02 0.000000e+00 1.381520e+05 0.000000e+00]\n"," [6.945000e+03 0.000000e+00 1.536300e+04 1.438400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.166000e+03 0.000000e+00]\n"," [5.203970e+05 0.000000e+00 8.830800e+05 6.541100e+04 1.230000e+03\n","  2.900000e+02 0.000000e+00 2.060880e+05 0.000000e+00]\n"," [2.245260e+05 0.000000e+00 6.770000e+03 4.145270e+05 0.000000e+00\n","  2.200000e+01 0.000000e+00 8.624400e+04 0.000000e+00]\n"," [9.103600e+04 0.000000e+00 1.290600e+04 9.350000e+02 9.572000e+03\n","  4.195000e+03 0.000000e+00 7.089000e+03 0.000000e+00]\n"," [5.994000e+05 0.000000e+00 3.980000e+04 2.214000e+03 2.292000e+03\n","  3.522000e+03 0.000000e+00 6.310000e+03 0.000000e+00]\n"," [1.285600e+04 0.000000e+00 0.000000e+00 3.383000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.512000e+03 0.000000e+00]\n"," [3.486670e+05 0.000000e+00 6.983000e+03 2.745700e+04 5.410000e+02\n","  0.000000e+00 0.000000e+00 4.377750e+05 0.000000e+00]\n"," [1.993500e+04 0.000000e+00 6.414000e+03 1.183840e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.993000e+03 0.000000e+00]]\n","\n","=>Epoches 61, learning rate = 0.0021,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.278: 100%|██████████| 181/181 [03:27<00:00,  1.15s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 61, numImages:   362]\n","Loss: 50.285\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.341: 100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 61, numImages:    52]\n","Acc:0.7860088881172291, Acc_class:0.3008149947846999, mIoU:0.23910964425802542, fwIoU: 0.6416383347539616\n","Classwise_IoU:\n","[8.00359151e-01 0.00000000e+00 3.62615686e-01 4.24527927e-01\n"," 8.32864250e-02 3.34789694e-04 0.00000000e+00 3.08858183e-01\n"," 1.72004636e-01]\n","Loss: 8.865\n","[[9.247272e+06 0.000000e+00 3.178700e+04 5.554700e+04 3.402000e+03\n","  6.000000e+00 0.000000e+00 1.227810e+05 3.790000e+02]\n"," [1.243100e+04 0.000000e+00 1.836000e+03 2.256200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.699000e+03 4.330000e+03]\n"," [7.263960e+05 0.000000e+00 6.382580e+05 1.064030e+05 8.260000e+02\n","  0.000000e+00 0.000000e+00 2.046130e+05 0.000000e+00]\n"," [2.281920e+05 0.000000e+00 3.059000e+03 4.591970e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.036500e+04 1.276000e+03]\n"," [9.209200e+04 0.000000e+00 9.760000e+03 1.969000e+03 1.094900e+04\n","  5.980000e+02 0.000000e+00 1.036500e+04 0.000000e+00]\n"," [6.112230e+05 0.000000e+00 3.415700e+04 3.044000e+03 3.740000e+02\n","  2.190000e+02 0.000000e+00 4.521000e+03 0.000000e+00]\n"," [1.554700e+04 0.000000e+00 0.000000e+00 3.760000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.444000e+03 0.000000e+00]\n"," [3.895060e+05 0.000000e+00 3.055000e+03 5.353200e+04 1.127000e+03\n","  0.000000e+00 0.000000e+00 3.742030e+05 0.000000e+00]\n"," [1.734200e+04 0.000000e+00 0.000000e+00 1.027590e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.580000e+02 2.626700e+04]]\n","\n","=>Epoches 62, learning rate = 0.0021,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.283: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 62, numImages:   362]\n","Loss: 51.168\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.325: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 62, numImages:    52]\n","Acc:0.7878604330589557, Acc_class:0.2649271784202819, mIoU:0.21119333464622125, fwIoU: 0.6477556572953226\n","Classwise_IoU:\n","[0.80930889 0.         0.4354059  0.30526515 0.04410378 0.00194876\n"," 0.         0.30001871 0.00468881]\n","Loss: 8.462\n","[[9.276241e+06 0.000000e+00 6.152800e+04 1.774500e+04 1.344000e+03\n","  7.220000e+02 0.000000e+00 1.035940e+05 0.000000e+00]\n"," [7.905000e+03 0.000000e+00 1.535100e+04 8.905000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.105100e+04 6.460000e+02]\n"," [5.854870e+05 0.000000e+00 8.228980e+05 7.420000e+03 1.680000e+02\n","  1.250000e+02 0.000000e+00 2.603980e+05 0.000000e+00]\n"," [2.787600e+05 0.000000e+00 4.924200e+04 2.693620e+05 0.000000e+00\n","  9.600000e+01 0.000000e+00 1.346290e+05 0.000000e+00]\n"," [9.693000e+04 0.000000e+00 1.155200e+04 6.690000e+02 5.613000e+03\n","  4.735000e+03 0.000000e+00 6.234000e+03 0.000000e+00]\n"," [6.132170e+05 0.000000e+00 3.502200e+04 2.000000e+01 0.000000e+00\n","  1.285000e+03 0.000000e+00 3.994000e+03 0.000000e+00]\n"," [1.276900e+04 0.000000e+00 5.400000e+02 2.923000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.519000e+03 0.000000e+00]\n"," [3.803720e+05 0.000000e+00 2.187300e+04 1.336500e+04 2.300000e+01\n","  1.770000e+02 0.000000e+00 4.056130e+05 0.000000e+00]\n"," [2.531500e+04 0.000000e+00 1.835200e+04 9.925100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.117000e+03 6.910000e+02]]\n","\n","=>Epoches 63, learning rate = 0.0020,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.281: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 63, numImages:   362]\n","Loss: 50.804\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.320: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 63, numImages:    52]\n","Acc:0.794891451734583, Acc_class:0.298732039286195, mIoU:0.23964459198782784, fwIoU: 0.6565313587245782\n","Classwise_IoU:\n","[0.8097416  0.         0.47130836 0.38957905 0.07555138 0.00541519\n"," 0.         0.2601769  0.14502884]\n","Loss: 8.315\n","[[9.282217e+06 0.000000e+00 7.542300e+04 4.077300e+04 1.714900e+04\n","  7.380000e+02 0.000000e+00 4.487400e+04 0.000000e+00]\n"," [9.978000e+03 0.000000e+00 8.250000e+02 2.104800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.684000e+03 9.323000e+03]\n"," [5.243970e+05 0.000000e+00 8.487420e+05 1.537240e+05 1.065900e+04\n","  5.280000e+02 0.000000e+00 1.338380e+05 4.608000e+03]\n"," [2.776860e+05 0.000000e+00 0.000000e+00 4.378440e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.598600e+04 5.730000e+02]\n"," [9.387400e+04 0.000000e+00 8.173000e+03 9.100000e+02 1.407900e+04\n","  3.345000e+03 0.000000e+00 5.352000e+03 0.000000e+00]\n"," [5.777120e+05 0.000000e+00 3.710200e+04 1.371000e+03 3.266600e+04\n","  3.564000e+03 0.000000e+00 1.123000e+03 0.000000e+00]\n"," [1.553100e+04 0.000000e+00 0.000000e+00 3.324000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.896000e+03 0.000000e+00]\n"," [4.795980e+05 0.000000e+00 2.802000e+03 7.078800e+04 1.430000e+02\n","  0.000000e+00 0.000000e+00 2.680920e+05 0.000000e+00]\n"," [2.323400e+04 0.000000e+00 0.000000e+00 9.986300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.460000e+02 2.338300e+04]]\n","\n","=>Epoches 64, learning rate = 0.0020,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.280: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 64, numImages:   362]\n","Loss: 50.714\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.326: 100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 64, numImages:    52]\n","Acc:0.7966583040964902, Acc_class:0.29792714306620377, mIoU:0.23845373980991802, fwIoU: 0.6586369082672412\n","Classwise_IoU:\n","[0.80991048 0.         0.48972147 0.39011745 0.03430615 0.01589128\n"," 0.         0.25151422 0.1546226 ]\n","Loss: 8.466\n","[[9.237059e+06 0.000000e+00 1.143260e+05 5.869000e+04 6.146000e+03\n","  8.200000e+02 0.000000e+00 4.413300e+04 0.000000e+00]\n"," [9.138000e+03 0.000000e+00 1.079000e+03 2.333100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.420000e+02 9.668000e+03]\n"," [5.342100e+05 0.000000e+00 9.154050e+05 1.570770e+05 6.110000e+02\n","  1.494000e+03 0.000000e+00 6.379600e+04 3.903000e+03]\n"," [2.515070e+05 0.000000e+00 1.210000e+03 4.699940e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.181000e+03 1.970000e+02]\n"," [9.346200e+04 0.000000e+00 1.283100e+04 1.109000e+03 5.104000e+03\n","  4.573000e+03 0.000000e+00 8.654000e+03 0.000000e+00]\n"," [5.897230e+05 0.000000e+00 3.258500e+04 3.958000e+03 1.628500e+04\n","  1.049500e+04 0.000000e+00 4.920000e+02 0.000000e+00]\n"," [1.529800e+04 0.000000e+00 1.728000e+03 3.904000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.821000e+03 0.000000e+00]\n"," [4.288780e+05 0.000000e+00 2.898100e+04 1.243340e+05 3.000000e+00\n","  0.000000e+00 0.000000e+00 2.392270e+05 0.000000e+00]\n"," [2.164700e+04 0.000000e+00 0.000000e+00 1.002580e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.000000e+00 2.481600e+04]]\n","\n","=>Epoches 65, learning rate = 0.0019,                 previous best = 0.2446\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.269: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 65, numImages:   362]\n","Loss: 48.736\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.328: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 65, numImages:    52]\n","Acc:0.7919757324702436, Acc_class:0.3258838099910526, mIoU:0.25576133854679767, fwIoU: 0.6505476814883424\n","Classwise_IoU:\n","[0.80375301 0.         0.43610873 0.35919008 0.06925475 0.04479555\n"," 0.         0.26633918 0.32241074]\n","Loss: 8.520\n","[[9.30175e+06 0.00000e+00 4.39660e+04 5.74230e+04 4.28900e+03 3.85400e+03\n","  0.00000e+00 4.81830e+04 1.70900e+03]\n"," [7.31300e+03 0.00000e+00 7.67200e+03 9.31100e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 3.74600e+03 1.58160e+04]\n"," [6.54183e+05 0.00000e+00 7.87591e+05 7.39450e+04 2.14000e+03 4.83900e+03\n","  0.00000e+00 1.46000e+05 7.79800e+03]\n"," [2.45887e+05 0.00000e+00 3.93480e+04 3.49451e+05 0.00000e+00 8.25000e+02\n","  0.00000e+00 2.51040e+04 7.14740e+04]\n"," [1.00344e+05 0.00000e+00 6.26000e+03 7.58000e+02 1.00400e+04 6.05800e+03\n","  0.00000e+00 2.21500e+03 5.80000e+01]\n"," [5.95970e+05 0.00000e+00 1.19450e+04 2.15800e+03 1.22220e+04 3.00110e+04\n","  0.00000e+00 1.23200e+03 0.00000e+00]\n"," [1.44560e+04 0.00000e+00 4.91000e+02 3.04600e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 5.75800e+03 0.00000e+00]\n"," [4.66359e+05 0.00000e+00 1.75070e+04 5.54760e+04 5.88000e+02 8.41000e+02\n","  0.00000e+00 2.80640e+05 1.20000e+01]\n"," [2.72100e+04 0.00000e+00 2.26600e+03 3.86800e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 3.30000e+01 7.85370e+04]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 66, learning rate = 0.0019,                 previous best = 0.2558\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.266: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 66, numImages:   362]\n","Loss: 48.094\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.359: 100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 66, numImages:    52]\n","Acc:0.7713463299541067, Acc_class:0.2268394035900612, mIoU:0.17267905789972177, fwIoU: 0.6235813196983802\n","Classwise_IoU:\n","[0.8062617  0.         0.38727902 0.00152879 0.0549039  0.01027075\n"," 0.         0.29386737 0.        ]\n","Loss: 9.324\n","[[9.29488e+06 0.00000e+00 6.42290e+04 3.58000e+02 2.70700e+03 9.55000e+02\n","  0.00000e+00 9.80450e+04 0.00000e+00]\n"," [6.81200e+03 0.00000e+00 2.70140e+04 0.00000e+00 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.00320e+04 0.00000e+00]\n"," [6.19989e+05 0.00000e+00 8.54420e+05 0.00000e+00 2.07000e+03 1.06300e+03\n","  0.00000e+00 1.98954e+05 0.00000e+00]\n"," [2.79898e+05 0.00000e+00 2.81887e+05 1.12100e+03 0.00000e+00 2.96000e+02\n","  0.00000e+00 1.68887e+05 0.00000e+00]\n"," [9.60820e+04 0.00000e+00 9.37400e+03 0.00000e+00 7.78400e+03 4.47000e+03\n","  0.00000e+00 8.02300e+03 0.00000e+00]\n"," [6.15429e+05 0.00000e+00 1.55550e+04 0.00000e+00 1.12360e+04 6.78200e+03\n","  0.00000e+00 4.53600e+03 0.00000e+00]\n"," [1.46110e+04 0.00000e+00 1.77100e+03 0.00000e+00 0.00000e+00 0.00000e+00\n","  0.00000e+00 7.36900e+03 0.00000e+00]\n"," [4.08482e+05 0.00000e+00 2.21880e+04 0.00000e+00 2.90000e+01 0.00000e+00\n","  0.00000e+00 3.90724e+05 0.00000e+00]\n"," [2.58890e+04 0.00000e+00 1.07699e+05 8.14000e+02 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.23240e+04 0.00000e+00]]\n","\n","=>Epoches 67, learning rate = 0.0018,                 previous best = 0.2558\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.278: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 67, numImages:   362]\n","Loss: 50.393\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.325: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 67, numImages:    52]\n","Acc:0.7942294027499732, Acc_class:0.2827167479930195, mIoU:0.2264978558263573, fwIoU: 0.6562790867404128\n","Classwise_IoU:\n","[0.81187071 0.         0.45459482 0.36597938 0.09098605 0.00294721\n"," 0.         0.31210254 0.        ]\n","Loss: 8.452\n","[[9.263228e+06 0.000000e+00 6.665600e+04 3.418600e+04 9.727000e+03\n","  6.220000e+02 0.000000e+00 8.675500e+04 0.000000e+00]\n"," [6.778000e+03 0.000000e+00 2.423300e+04 6.843000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.004000e+03 0.000000e+00]\n"," [5.797220e+05 0.000000e+00 8.714360e+05 3.026900e+04 8.174000e+03\n","  2.300000e+02 0.000000e+00 1.866650e+05 0.000000e+00]\n"," [2.063140e+05 0.000000e+00 9.544100e+04 3.401050e+05 0.000000e+00\n","  6.300000e+01 0.000000e+00 9.016600e+04 0.000000e+00]\n"," [9.949800e+04 0.000000e+00 3.725000e+03 1.312000e+03 1.494000e+04\n","  3.119000e+03 0.000000e+00 3.139000e+03 0.000000e+00]\n"," [6.179470e+05 0.000000e+00 1.216700e+04 1.772000e+03 1.733000e+04\n","  1.938000e+03 0.000000e+00 2.384000e+03 0.000000e+00]\n"," [1.209400e+04 0.000000e+00 5.300000e+01 3.600000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.004000e+03 0.000000e+00]\n"," [4.061490e+05 0.000000e+00 1.527200e+04 1.955100e+04 3.237000e+03\n","  0.000000e+00 0.000000e+00 3.772140e+05 0.000000e+00]\n"," [2.005700e+04 0.000000e+00 2.290800e+04 9.967900e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.082000e+03 0.000000e+00]]\n","\n","=>Epoches 68, learning rate = 0.0018,                 previous best = 0.2558\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.273: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 68, numImages:   362]\n","Loss: 49.470\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.314: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 68, numImages:    52]\n","Acc:0.7957610304229777, Acc_class:0.29410824037023536, mIoU:0.23138584763304929, fwIoU: 0.6585468196390056\n","Classwise_IoU:\n","[0.81297437 0.         0.43461734 0.42312752 0.07589849 0.0010249\n"," 0.         0.32998424 0.00484577]\n","Loss: 8.155\n","[[9.251289e+06 0.000000e+00 4.135500e+04 4.326200e+04 7.498000e+03\n","  1.300000e+02 0.000000e+00 1.176400e+05 0.000000e+00]\n"," [7.704000e+03 0.000000e+00 3.963000e+03 2.509500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.096000e+03 0.000000e+00]\n"," [5.800230e+05 0.000000e+00 7.634510e+05 7.754400e+04 1.861000e+03\n","  0.000000e+00 0.000000e+00 2.536170e+05 0.000000e+00]\n"," [2.311560e+05 0.000000e+00 2.819000e+03 4.393460e+05 8.000000e+00\n","  1.450000e+02 0.000000e+00 5.861500e+04 0.000000e+00]\n"," [9.443700e+04 0.000000e+00 7.568000e+03 8.330000e+02 1.172700e+04\n","  1.862000e+03 0.000000e+00 9.306000e+03 0.000000e+00]\n"," [6.070780e+05 0.000000e+00 2.120900e+04 1.932000e+03 1.817300e+04\n","  6.720000e+02 0.000000e+00 4.474000e+03 0.000000e+00]\n"," [1.297200e+04 0.000000e+00 0.000000e+00 3.558000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.221000e+03 0.000000e+00]\n"," [3.624760e+05 0.000000e+00 2.519000e+03 3.256700e+04 1.236000e+03\n","  0.000000e+00 0.000000e+00 4.226250e+05 0.000000e+00]\n"," [2.253800e+04 0.000000e+00 6.760000e+02 1.214500e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.351000e+03 7.110000e+02]]\n","\n","=>Epoches 69, learning rate = 0.0017,                 previous best = 0.2558\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.268: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 69, numImages:   362]\n","Loss: 48.452\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.348: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 69, numImages:    52]\n","Acc:0.7725395526770309, Acc_class:0.24874219628264493, mIoU:0.19530841621022021, fwIoU: 0.6249631828973221\n","Classwise_IoU:\n","[0.79756198 0.         0.34130946 0.27879015 0.06767576 0.00159776\n"," 0.         0.26829849 0.00254215]\n","Loss: 9.053\n","[[9.327422e+06 0.000000e+00 1.722600e+04 1.417800e+04 2.623000e+03\n","  3.800000e+01 0.000000e+00 9.968700e+04 0.000000e+00]\n"," [8.715000e+03 0.000000e+00 5.391000e+03 1.683000e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.292200e+04 0.000000e+00]\n"," [7.359340e+05 0.000000e+00 5.864560e+05 1.798800e+04 4.130000e+02\n","  7.000000e+01 0.000000e+00 3.356350e+05 0.000000e+00]\n"," [2.964090e+05 0.000000e+00 5.637000e+03 2.517160e+05 0.000000e+00\n","  7.500000e+01 0.000000e+00 1.782520e+05 0.000000e+00]\n"," [1.013620e+05 0.000000e+00 4.600000e+03 4.570000e+02 9.197000e+03\n","  2.197000e+03 0.000000e+00 7.920000e+03 0.000000e+00]\n"," [6.343390e+05 0.000000e+00 6.886000e+03 3.200000e+01 6.811000e+03\n","  1.048000e+03 0.000000e+00 4.422000e+03 0.000000e+00]\n"," [1.532600e+04 0.000000e+00 0.000000e+00 2.321000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.104000e+03 0.000000e+00]\n"," [4.123480e+05 0.000000e+00 1.671000e+03 1.125800e+04 3.180000e+02\n","  0.000000e+00 0.000000e+00 3.958280e+05 0.000000e+00]\n"," [2.931100e+04 0.000000e+00 3.460000e+02 1.077340e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.962000e+03 3.730000e+02]]\n","\n","=>Epoches 70, learning rate = 0.0017,                 previous best = 0.2558\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.271: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 70, numImages:   362]\n","Loss: 49.090\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.306: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 70, numImages:    52]\n","Acc:0.8041569953440273, Acc_class:0.3288093696204091, mIoU:0.26982486173884207, fwIoU: 0.6695178363285659\n","Classwise_IoU:\n","[0.81237345 0.         0.50205172 0.41753645 0.07695888 0.03723938\n"," 0.         0.31035358 0.27191029]\n","Loss: 7.948\n","[[9.228218e+06 0.000000e+00 1.152310e+05 3.622700e+04 1.475800e+04\n","  4.091000e+03 0.000000e+00 6.182000e+04 8.290000e+02]\n"," [1.023700e+04 0.000000e+00 5.306000e+03 1.861000e+04 2.200000e+01\n","  0.000000e+00 0.000000e+00 2.612000e+03 7.071000e+03]\n"," [5.283900e+05 0.000000e+00 9.539530e+05 8.986000e+04 4.098000e+03\n","  1.777000e+03 0.000000e+00 9.841800e+04 0.000000e+00]\n"," [2.712710e+05 0.000000e+00 2.078000e+03 4.236830e+05 6.230000e+02\n","  1.650000e+02 0.000000e+00 2.367100e+04 1.059800e+04]\n"," [8.682800e+04 0.000000e+00 1.691300e+04 9.710000e+02 1.355700e+04\n","  4.645000e+03 0.000000e+00 2.801000e+03 1.800000e+01]\n"," [5.346690e+05 0.000000e+00 6.968600e+04 8.850000e+02 2.265500e+04\n","  2.474300e+04 0.000000e+00 9.000000e+02 0.000000e+00]\n"," [1.501300e+04 0.000000e+00 1.500000e+01 3.645000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.078000e+03 0.000000e+00]\n"," [4.291550e+05 0.000000e+00 1.427200e+04 5.387800e+04 8.270000e+03\n","  2.150000e+02 0.000000e+00 3.156330e+05 0.000000e+00]\n"," [2.283900e+04 0.000000e+00 1.120000e+02 7.855600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.880000e+02 4.493100e+04]]\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","=>Epoches 71, learning rate = 0.0016,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.270: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 71, numImages:   362]\n","Loss: 48.873\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.310: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 71, numImages:    52]\n","Acc:0.7921540326382842, Acc_class:0.26884642394026176, mIoU:0.21986655886177003, fwIoU: 0.6488795018560654\n","Classwise_IoU:\n","[0.80780703 0.         0.48814164 0.16907029 0.06373682 0.005735\n"," 0.         0.32293029 0.12137796]\n","Loss: 8.071\n","[[9.259829e+06 0.000000e+00 1.196910e+05 8.451000e+03 1.700800e+04\n","  1.211000e+03 0.000000e+00 5.493000e+04 5.400000e+01]\n"," [8.691000e+03 0.000000e+00 3.095300e+04 8.750000e+02 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.339000e+03 0.000000e+00]\n"," [4.868800e+05 0.000000e+00 1.083898e+06 1.957000e+03 4.871000e+03\n","  5.100000e+01 0.000000e+00 9.883900e+04 0.000000e+00]\n"," [3.392530e+05 0.000000e+00 2.189910e+05 1.317110e+05 0.000000e+00\n","  1.930000e+02 0.000000e+00 4.180800e+04 1.330000e+02]\n"," [9.219300e+04 0.000000e+00 1.519600e+04 3.600000e+02 1.025500e+04\n","  4.641000e+03 0.000000e+00 3.088000e+03 0.000000e+00]\n"," [5.791250e+05 0.000000e+00 5.738400e+04 2.200000e+01 1.236200e+04\n","  3.783000e+03 0.000000e+00 8.620000e+02 0.000000e+00]\n"," [1.633800e+04 0.000000e+00 8.510000e+02 1.271000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.291000e+03 0.000000e+00]\n"," [4.485210e+05 0.000000e+00 2.952400e+04 9.304000e+03 9.220000e+02\n","  0.000000e+00 0.000000e+00 3.331520e+05 0.000000e+00]\n"," [3.074700e+04 0.000000e+00 7.137200e+04 2.470200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.073000e+03 1.783200e+04]]\n","\n","=>Epoches 72, learning rate = 0.0016,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.269: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 72, numImages:   362]\n","Loss: 48.669\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.318: 100%|██████████| 26/26 [00:07<00:00,  3.36it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 72, numImages:    52]\n","Acc:0.7921759547900925, Acc_class:0.26626902220647214, mIoU:0.22382472949901544, fwIoU: 0.6443028429373687\n","Classwise_IoU:\n","[0.79829833 0.         0.45671306 0.31036473 0.0785387  0.00824952\n"," 0.         0.3008717  0.06138653]\n","Loss: 8.280\n","[[9.355868e+06 0.000000e+00 4.268500e+04 1.604400e+04 3.180000e+03\n","  5.900000e+02 0.000000e+00 4.280700e+04 0.000000e+00]\n"," [9.744000e+03 0.000000e+00 3.064100e+04 1.248000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.225000e+03 0.000000e+00]\n"," [6.735250e+05 0.000000e+00 9.003390e+05 9.394000e+03 4.060000e+02\n","  4.990000e+02 0.000000e+00 9.233300e+04 0.000000e+00]\n"," [3.282460e+05 0.000000e+00 1.062000e+05 2.554370e+05 0.000000e+00\n","  1.460000e+02 0.000000e+00 4.206000e+04 0.000000e+00]\n"," [9.853400e+04 0.000000e+00 8.522000e+03 5.690000e+02 1.021600e+04\n","  3.568000e+03 0.000000e+00 4.324000e+03 0.000000e+00]\n"," [6.221450e+05 0.000000e+00 2.471000e+04 1.310000e+02 7.500000e+01\n","  5.431000e+03 0.000000e+00 1.046000e+03 0.000000e+00]\n"," [1.697700e+04 0.000000e+00 1.450000e+02 2.331000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.298000e+03 0.000000e+00]\n"," [4.826590e+05 0.000000e+00 1.913500e+04 1.448500e+04 6.820000e+02\n","  0.000000e+00 0.000000e+00 3.044620e+05 0.000000e+00]\n"," [2.676000e+04 0.000000e+00 6.281100e+04 4.673100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.417000e+03 9.007000e+03]]\n","\n","=>Epoches 73, learning rate = 0.0015,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.281: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 73, numImages:   362]\n","Loss: 50.908\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.338: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 73, numImages:    52]\n","Acc:0.7754683521586159, Acc_class:0.23963630790416537, mIoU:0.19360210718676846, fwIoU: 0.6249254248962592\n","Classwise_IoU:\n","[7.93593179e-01 0.00000000e+00 3.85211867e-01 2.21164146e-01\n"," 6.09173107e-02 1.75927217e-02 0.00000000e+00 2.63892032e-01\n"," 4.77079727e-05]\n","Loss: 8.778\n","[[9.351952e+06 0.000000e+00 4.258000e+04 6.083000e+03 1.593000e+03\n","  1.411000e+03 0.000000e+00 5.755500e+04 0.000000e+00]\n"," [1.260000e+04 0.000000e+00 2.126400e+04 2.080000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.914000e+03 0.000000e+00]\n"," [7.012070e+05 0.000000e+00 7.247430e+05 2.418000e+03 3.150000e+02\n","  1.028000e+03 0.000000e+00 2.467850e+05 0.000000e+00]\n"," [3.740250e+05 0.000000e+00 5.964600e+04 1.800400e+05 3.000000e+00\n","  2.110000e+02 0.000000e+00 1.181640e+05 0.000000e+00]\n"," [9.968300e+04 0.000000e+00 6.094000e+03 2.780000e+02 7.977000e+03\n","  3.744000e+03 0.000000e+00 7.957000e+03 0.000000e+00]\n"," [6.076520e+05 0.000000e+00 2.948800e+04 0.000000e+00 3.280000e+03\n","  1.161000e+04 0.000000e+00 1.508000e+03 0.000000e+00]\n"," [1.798600e+04 0.000000e+00 0.000000e+00 1.643000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.122000e+03 0.000000e+00]\n"," [4.760250e+05 0.000000e+00 4.889000e+03 4.694000e+03 2.400000e+01\n","  0.000000e+00 0.000000e+00 3.357910e+05 0.000000e+00]\n"," [3.396300e+04 0.000000e+00 4.095700e+04 6.477100e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.028000e+03 7.000000e+00]]\n","\n","=>Epoches 74, learning rate = 0.0015,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.267: 100%|██████████| 181/181 [03:25<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 74, numImages:   362]\n","Loss: 48.243\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.341: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 74, numImages:    52]\n","Acc:0.7760568157869892, Acc_class:0.23417903643131804, mIoU:0.18269650982229244, fwIoU: 0.6339598323238013\n","Classwise_IoU:\n","[0.81577089 0.         0.38697714 0.05062329 0.06298848 0.03360857\n"," 0.         0.29430022 0.        ]\n","Loss: 8.872\n","[[9.234015e+06 0.000000e+00 1.510910e+05 1.095700e+04 2.376000e+03\n","  2.714000e+03 0.000000e+00 6.002100e+04 0.000000e+00]\n"," [5.921000e+03 0.000000e+00 3.376500e+04 0.000000e+00 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.172000e+03 0.000000e+00]\n"," [5.533860e+05 0.000000e+00 1.008594e+06 6.820000e+02 8.490000e+02\n","  1.972000e+03 0.000000e+00 1.110130e+05 0.000000e+00]\n"," [1.816750e+05 0.000000e+00 4.721230e+05 3.863200e+04 1.450000e+02\n","  1.290000e+02 0.000000e+00 3.938500e+04 0.000000e+00]\n"," [9.330700e+04 0.000000e+00 1.431000e+04 1.800000e+01 8.559000e+03\n","  5.187000e+03 0.000000e+00 4.352000e+03 0.000000e+00]\n"," [5.747130e+05 0.000000e+00 4.756700e+04 1.960000e+02 6.691000e+03\n","  2.230100e+04 0.000000e+00 2.070000e+03 0.000000e+00]\n"," [1.384300e+04 0.000000e+00 5.809000e+03 3.400000e+01 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.065000e+03 0.000000e+00]\n"," [4.168490e+05 0.000000e+00 8.182700e+04 1.457600e+04 8.800000e+01\n","  1.100000e+01 0.000000e+00 3.080720e+05 0.000000e+00]\n"," [1.850500e+04 0.000000e+00 1.233520e+05 4.575000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.940000e+02 0.000000e+00]]\n","\n","=>Epoches 75, learning rate = 0.0014,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.277: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 75, numImages:   362]\n","Loss: 50.196\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.330: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 75, numImages:    52]\n","Acc:0.7908737058988419, Acc_class:0.3045549264968456, mIoU:0.23564403276618184, fwIoU: 0.6555375598451121\n","Classwise_IoU:\n","[0.81604316 0.         0.41111858 0.3993572  0.05756307 0.007504\n"," 0.         0.28671318 0.14249711]\n","Loss: 8.586\n","[[9.199279e+06 0.000000e+00 5.854400e+04 8.830600e+04 3.479000e+03\n","  5.170000e+02 0.000000e+00 1.110490e+05 0.000000e+00]\n"," [6.848000e+03 0.000000e+00 2.679000e+03 2.847300e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.910000e+02 4.867000e+03]\n"," [5.738250e+05 0.000000e+00 7.395460e+05 1.733430e+05 1.598000e+03\n","  4.200000e+02 0.000000e+00 1.864760e+05 1.288000e+03]\n"," [1.758270e+05 0.000000e+00 1.920000e+02 5.099420e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.584800e+04 2.800000e+02]\n"," [9.112700e+04 0.000000e+00 1.047900e+04 2.656000e+03 7.683000e+03\n","  4.240000e+03 0.000000e+00 9.548000e+03 0.000000e+00]\n"," [5.884980e+05 0.000000e+00 4.731100e+04 6.474000e+03 2.653000e+03\n","  4.943000e+03 0.000000e+00 3.659000e+03 0.000000e+00]\n"," [1.321000e+04 0.000000e+00 1.300000e+01 4.807000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.721000e+03 0.000000e+00]\n"," [3.451340e+05 0.000000e+00 3.149000e+03 1.334110e+05 8.000000e+00\n","  0.000000e+00 0.000000e+00 3.397210e+05 0.000000e+00]\n"," [1.738700e+04 0.000000e+00 0.000000e+00 1.073480e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.660000e+02 2.182500e+04]]\n","\n","=>Epoches 76, learning rate = 0.0014,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.263: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 76, numImages:   362]\n","Loss: 47.626\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.317: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 76, numImages:    52]\n","Acc:0.7987309704761228, Acc_class:0.28468444115751057, mIoU:0.2313953504897056, fwIoU: 0.6611396149394948\n","Classwise_IoU:\n","[0.81232192 0.         0.4859401  0.39177657 0.05935013 0.00126122\n"," 0.         0.30170335 0.03020485]\n","Loss: 8.239\n","[[9.296996e+06 0.000000e+00 5.554200e+04 3.120000e+04 4.072000e+03\n","  4.070000e+02 0.000000e+00 7.295100e+04 6.000000e+00]\n"," [7.326000e+03 0.000000e+00 1.403300e+04 1.055600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.666000e+03 3.277000e+03]\n"," [5.420650e+05 0.000000e+00 8.798830e+05 3.802000e+04 4.220000e+02\n","  3.200000e+01 0.000000e+00 2.160740e+05 0.000000e+00]\n"," [2.571080e+05 0.000000e+00 2.022000e+04 3.724420e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.231900e+04 0.000000e+00]\n"," [1.002560e+05 0.000000e+00 9.065000e+03 8.900000e+02 8.360000e+03\n","  2.530000e+03 0.000000e+00 4.632000e+03 0.000000e+00]\n"," [6.123930e+05 0.000000e+00 2.702900e+04 5.650000e+02 1.063200e+04\n","  8.280000e+02 0.000000e+00 2.091000e+03 0.000000e+00]\n"," [1.314600e+04 0.000000e+00 0.000000e+00 2.953000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.652000e+03 0.000000e+00]\n"," [4.269830e+05 0.000000e+00 6.331000e+03 2.068500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.674240e+05 0.000000e+00]\n"," [2.451400e+04 0.000000e+00 1.966000e+03 1.136910e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.024000e+03 4.531000e+03]]\n","\n","=>Epoches 77, learning rate = 0.0013,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.263: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 77, numImages:   362]\n","Loss: 47.670\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.345: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 77, numImages:    52]\n","Acc:0.7858368722993736, Acc_class:0.29440979036519277, mIoU:0.22399197180766592, fwIoU: 0.6552856480838293\n","Classwise_IoU:\n","[0.81757973 0.         0.39227505 0.40771736 0.06652745 0.02911407\n"," 0.         0.30271409 0.        ]\n","Loss: 8.960\n","[[9.10956e+06 0.00000e+00 6.28590e+04 4.65450e+04 2.71800e+03 2.81800e+03\n","  0.00000e+00 2.36674e+05 0.00000e+00]\n"," [6.97300e+03 0.00000e+00 8.70500e+03 1.46740e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.35060e+04 0.00000e+00]\n"," [5.01554e+05 0.00000e+00 7.14214e+05 4.20590e+04 3.79000e+02 1.86900e+03\n","  0.00000e+00 4.16421e+05 0.00000e+00]\n"," [2.00726e+05 0.00000e+00 8.13800e+03 4.03060e+05 3.20000e+01 2.01000e+02\n","  0.00000e+00 1.19932e+05 0.00000e+00]\n"," [8.48490e+04 0.00000e+00 1.08410e+04 1.17900e+03 9.27100e+03 4.99900e+03\n","  0.00000e+00 1.45940e+04 0.00000e+00]\n"," [5.58129e+05 0.00000e+00 5.18370e+04 1.29500e+03 1.03360e+04 1.93150e+04\n","  0.00000e+00 1.26260e+04 0.00000e+00]\n"," [1.13710e+04 0.00000e+00 0.00000e+00 3.39800e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 8.98200e+03 0.00000e+00]\n"," [2.97004e+05 0.00000e+00 1.38900e+03 2.42810e+04 1.58000e+02 0.00000e+00\n","  0.00000e+00 4.98591e+05 0.00000e+00]\n"," [2.03260e+04 0.00000e+00 4.32000e+02 1.23057e+05 0.00000e+00 0.00000e+00\n","  0.00000e+00 2.91100e+03 0.00000e+00]]\n","\n","=>Epoches 78, learning rate = 0.0013,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.261: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 78, numImages:   362]\n","Loss: 47.302\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.327: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 78, numImages:    52]\n","Acc:0.7891659702729775, Acc_class:0.27618078813379, mIoU:0.2219908535705562, fwIoU: 0.6428409322560534\n","Classwise_IoU:\n","[0.79941838 0.         0.39335343 0.43047771 0.06758033 0.00979258\n"," 0.         0.29729526 0.        ]\n","Loss: 8.505\n","[[9.322148e+06 0.000000e+00 2.372900e+04 4.841700e+04 1.844000e+03\n","  1.249000e+03 0.000000e+00 6.378700e+04 0.000000e+00]\n"," [7.251000e+03 0.000000e+00 1.229100e+04 1.403400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.028200e+04 0.000000e+00]\n"," [7.450500e+05 0.000000e+00 6.814860e+05 6.077300e+04 1.930000e+02\n","  5.340000e+02 0.000000e+00 1.884600e+05 0.000000e+00]\n"," [2.221940e+05 0.000000e+00 6.374000e+03 4.342530e+05 0.000000e+00\n","  9.300000e+01 0.000000e+00 6.917500e+04 0.000000e+00]\n"," [1.072670e+05 0.000000e+00 2.655000e+03 1.316000e+03 8.659000e+03\n","  3.959000e+03 0.000000e+00 1.877000e+03 0.000000e+00]\n"," [6.380860e+05 0.000000e+00 6.234000e+03 1.769000e+03 0.000000e+00\n","  6.457000e+03 0.000000e+00 9.920000e+02 0.000000e+00]\n"," [1.264400e+04 0.000000e+00 0.000000e+00 3.187000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.920000e+03 0.000000e+00]\n"," [4.456330e+05 0.000000e+00 3.292000e+03 2.556900e+04 3.590000e+02\n","  4.000000e+00 0.000000e+00 3.465660e+05 0.000000e+00]\n"," [2.186400e+04 0.000000e+00 1.432000e+03 1.216160e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.814000e+03 0.000000e+00]]\n","\n","=>Epoches 79, learning rate = 0.0012,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.266: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 79, numImages:   362]\n","Loss: 48.152\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.333: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 79, numImages:    52]\n","Acc:0.7890363372819513, Acc_class:0.2580894878084514, mIoU:0.20768307859600238, fwIoU: 0.6456311784162285\n","Classwise_IoU:\n","[0.80765715 0.         0.44779766 0.22378182 0.0572599  0.00634356\n"," 0.         0.32630762 0.        ]\n","Loss: 8.657\n","[[9.29793e+06 0.00000e+00 6.82700e+04 1.02880e+04 1.55700e+03 3.52000e+02\n","  0.00000e+00 8.27770e+04 0.00000e+00]\n"," [8.64200e+03 0.00000e+00 2.73150e+04 8.91000e+02 0.00000e+00 0.00000e+00\n","  0.00000e+00 7.01000e+03 0.00000e+00]\n"," [6.08383e+05 0.00000e+00 9.07719e+05 1.77000e+03 3.17000e+02 2.95000e+02\n","  0.00000e+00 1.58012e+05 0.00000e+00]\n"," [2.83055e+05 0.00000e+00 1.34990e+05 1.79917e+05 0.00000e+00 8.40000e+01\n","  0.00000e+00 1.34043e+05 0.00000e+00]\n"," [9.66530e+04 0.00000e+00 9.93200e+03 5.35000e+02 7.38000e+03 3.09100e+03\n","  0.00000e+00 8.14200e+03 0.00000e+00]\n"," [6.12265e+05 0.00000e+00 3.36020e+04 0.00000e+00 1.24300e+03 4.17000e+03\n","  0.00000e+00 2.25800e+03 0.00000e+00]\n"," [1.37670e+04 0.00000e+00 4.37000e+02 1.96200e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 7.58500e+03 0.00000e+00]\n"," [4.02573e+05 0.00000e+00 1.37310e+04 4.40400e+03 3.60000e+01 0.00000e+00\n","  0.00000e+00 4.00679e+05 0.00000e+00]\n"," [2.57120e+04 0.00000e+00 6.23010e+04 5.20450e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 6.66800e+03 0.00000e+00]]\n","\n","=>Epoches 80, learning rate = 0.0012,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.270: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 80, numImages:   362]\n","Loss: 48.922\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.313: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 80, numImages:    52]\n","Acc:0.8013061656490403, Acc_class:0.2953257598598165, mIoU:0.23907475653662338, fwIoU: 0.665700494668558\n","Classwise_IoU:\n","[0.81118886 0.         0.49869196 0.40074559 0.05850237 0.02135752\n"," 0.         0.34300664 0.01817986]\n","Loss: 8.149\n","[[9.226669e+06 0.000000e+00 9.339300e+04 3.237000e+04 2.376800e+04\n","  2.195000e+03 0.000000e+00 8.277900e+04 0.000000e+00]\n"," [7.992000e+03 0.000000e+00 1.763200e+04 1.061700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.552000e+03 2.065000e+03]\n"," [5.420790e+05 0.000000e+00 9.323500e+05 5.615100e+04 3.011000e+03\n","  1.816000e+03 0.000000e+00 1.410890e+05 0.000000e+00]\n"," [2.554570e+05 0.000000e+00 1.389200e+04 3.888170e+05 0.000000e+00\n","  2.230000e+02 0.000000e+00 7.370000e+04 0.000000e+00]\n"," [9.356900e+04 0.000000e+00 1.109500e+04 1.311000e+03 9.976000e+03\n","  5.084000e+03 0.000000e+00 4.698000e+03 0.000000e+00]\n"," [5.771290e+05 0.000000e+00 4.255000e+04 3.620000e+02 1.794200e+04\n","  1.415700e+04 0.000000e+00 1.398000e+03 0.000000e+00]\n"," [1.305400e+04 0.000000e+00 4.200000e+01 3.088000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.567000e+03 0.000000e+00]\n"," [3.993980e+05 0.000000e+00 8.228000e+03 2.269500e+04 6.900000e+01\n","  2.000000e+00 0.000000e+00 3.910310e+05 0.000000e+00]\n"," [2.440300e+04 0.000000e+00 6.263000e+03 1.115510e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.804000e+03 2.705000e+03]]\n","\n","=>Epoches 81, learning rate = 0.0011,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.256: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 81, numImages:   362]\n","Loss: 46.405\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.327: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 81, numImages:    52]\n","Acc:0.7967845026170665, Acc_class:0.29179875150300955, mIoU:0.2374872489867468, fwIoU: 0.6563255025258105\n","Classwise_IoU:\n","[0.80793474 0.         0.4404741  0.40853378 0.06698028 0.02169276\n"," 0.         0.32614129 0.06562829]\n","Loss: 8.507\n","[[9.298462e+06 0.000000e+00 4.017400e+04 3.917600e+04 6.042000e+03\n","  9.100000e+02 0.000000e+00 7.638200e+04 2.800000e+01]\n"," [9.592000e+03 0.000000e+00 2.101500e+04 8.560000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.201000e+03 1.490000e+03]\n"," [6.580120e+05 0.000000e+00 8.008220e+05 5.419800e+04 4.750000e+02\n","  1.540000e+03 0.000000e+00 1.614490e+05 0.000000e+00]\n"," [2.466990e+05 0.000000e+00 3.107500e+04 4.019380e+05 5.400000e+01\n","  1.670000e+02 0.000000e+00 5.215600e+04 0.000000e+00]\n"," [9.425600e+04 0.000000e+00 9.973000e+03 1.274000e+03 1.003800e+04\n","  3.005000e+03 0.000000e+00 7.187000e+03 0.000000e+00]\n"," [5.966580e+05 0.000000e+00 2.247100e+04 8.880000e+02 1.728900e+04\n","  1.429900e+04 0.000000e+00 1.933000e+03 0.000000e+00]\n"," [1.398300e+04 0.000000e+00 1.130000e+02 3.678000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.977000e+03 0.000000e+00]\n"," [4.065250e+05 0.000000e+00 6.421000e+03 3.966600e+04 2.720000e+02\n","  0.000000e+00 0.000000e+00 3.685390e+05 0.000000e+00]\n"," [2.202800e+04 0.000000e+00 1.035300e+04 1.043260e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.900000e+02 9.729000e+03]]\n","\n","=>Epoches 82, learning rate = 0.0011,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.255: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 82, numImages:   362]\n","Loss: 46.240\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.326: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 82, numImages:    52]\n","Acc:0.793488507092693, Acc_class:0.2946770456987607, mIoU:0.23202786095339023, fwIoU: 0.6560080019074996\n","Classwise_IoU:\n","[0.80851652 0.         0.42477359 0.41686107 0.06143303 0.03944581\n"," 0.         0.33722074 0.        ]\n","Loss: 8.475\n","[[9.239561e+06 0.000000e+00 4.005200e+04 4.559000e+04 4.875400e+04\n","  3.896000e+03 0.000000e+00 8.332100e+04 0.000000e+00]\n"," [8.617000e+03 0.000000e+00 7.700000e+03 2.262500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.916000e+03 0.000000e+00]\n"," [6.281170e+05 0.000000e+00 7.465570e+05 8.909300e+04 2.247400e+04\n","  3.565000e+03 0.000000e+00 1.866900e+05 0.000000e+00]\n"," [2.381580e+05 0.000000e+00 6.772000e+03 4.424380e+05 7.000000e+00\n","  2.480000e+02 0.000000e+00 4.446600e+04 0.000000e+00]\n"," [9.237200e+04 0.000000e+00 6.552000e+03 1.200000e+03 1.394800e+04\n","  5.210000e+03 0.000000e+00 6.451000e+03 0.000000e+00]\n"," [5.774180e+05 0.000000e+00 1.652200e+04 1.409000e+03 2.977500e+04\n","  2.629000e+04 0.000000e+00 2.124000e+03 0.000000e+00]\n"," [1.359700e+04 0.000000e+00 0.000000e+00 3.704000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.450000e+03 0.000000e+00]\n"," [3.839170e+05 0.000000e+00 3.375000e+03 4.387500e+04 3.010000e+02\n","  2.700000e+01 0.000000e+00 3.899280e+05 0.000000e+00]\n"," [2.442500e+04 0.000000e+00 7.200000e+01 1.217710e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.580000e+02 0.000000e+00]]\n","\n","=>Epoches 83, learning rate = 0.0010,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.262: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 83, numImages:   362]\n","Loss: 47.345\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.335: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 83, numImages:    52]\n","Acc:0.7851283483529303, Acc_class:0.27878884013337735, mIoU:0.2180472425569341, fwIoU: 0.6392970440796325\n","Classwise_IoU:\n","[0.80187105 0.         0.33946902 0.41136636 0.05960743 0.01999222\n"," 0.         0.3301191  0.        ]\n","Loss: 8.698\n","[[9.298783e+06 0.000000e+00 2.129400e+04 4.343000e+04 5.015000e+03\n","  1.149000e+03 0.000000e+00 9.150300e+04 0.000000e+00]\n"," [9.498000e+03 0.000000e+00 1.612000e+03 2.537400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.821000e+03 1.553000e+03]\n"," [7.589530e+05 0.000000e+00 5.825750e+05 9.767000e+04 2.792000e+03\n","  2.106000e+03 0.000000e+00 2.324000e+05 0.000000e+00]\n"," [2.342900e+05 0.000000e+00 0.000000e+00 4.342190e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.358000e+04 0.000000e+00]\n"," [9.815700e+04 0.000000e+00 6.307000e+03 1.346000e+03 8.843000e+03\n","  4.264000e+03 0.000000e+00 6.816000e+03 0.000000e+00]\n"," [6.120700e+05 0.000000e+00 9.294000e+03 1.443000e+03 1.480600e+04\n","  1.321600e+04 0.000000e+00 2.709000e+03 0.000000e+00]\n"," [1.423600e+04 0.000000e+00 0.000000e+00 3.553000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.962000e+03 0.000000e+00]\n"," [3.859680e+05 0.000000e+00 1.133000e+03 2.763500e+04 8.000000e+00\n","  0.000000e+00 0.000000e+00 4.066790e+05 0.000000e+00]\n"," [2.201100e+04 0.000000e+00 0.000000e+00 1.230130e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.702000e+03 0.000000e+00]]\n","\n","=>Epoches 84, learning rate = 0.0010,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.255: 100%|██████████| 181/181 [03:25<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 84, numImages:   362]\n","Loss: 46.234\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.319: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 84, numImages:    52]\n","Acc:0.7983083113892594, Acc_class:0.28937911620879436, mIoU:0.23322383003005903, fwIoU: 0.660821273839758\n","Classwise_IoU:\n","[0.81302449 0.         0.4512426  0.37331117 0.07502473 0.03342116\n"," 0.         0.35299032 0.        ]\n","Loss: 8.303\n","[[9.256444e+06 0.000000e+00 5.402500e+04 4.055400e+04 4.349000e+03\n","  1.836000e+03 0.000000e+00 1.039660e+05 0.000000e+00]\n"," [7.746000e+03 0.000000e+00 2.577300e+04 9.016000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.323000e+03 0.000000e+00]\n"," [6.028280e+05 0.000000e+00 8.662450e+05 5.466500e+04 9.670000e+02\n","  2.058000e+03 0.000000e+00 1.497330e+05 0.000000e+00]\n"," [2.316760e+05 0.000000e+00 8.930100e+04 3.674360e+05 0.000000e+00\n","  3.070000e+02 0.000000e+00 4.336900e+04 0.000000e+00]\n"," [8.967000e+04 0.000000e+00 1.119600e+04 1.523000e+03 1.061600e+04\n","  3.813000e+03 0.000000e+00 8.915000e+03 0.000000e+00]\n"," [5.872170e+05 0.000000e+00 2.883000e+04 2.315000e+03 9.977000e+03\n","  2.211000e+04 0.000000e+00 3.089000e+03 0.000000e+00]\n"," [1.432800e+04 0.000000e+00 1.070000e+02 3.718000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.598000e+03 0.000000e+00]\n"," [3.701840e+05 0.000000e+00 1.930300e+04 2.962800e+04 4.740000e+02\n","  5.000000e+00 0.000000e+00 4.018290e+05 0.000000e+00]\n"," [2.037400e+04 0.000000e+00 1.465700e+04 1.107540e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 9.410000e+02 0.000000e+00]]\n","\n","=>Epoches 85, learning rate = 0.0009,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.250: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 85, numImages:   362]\n","Loss: 45.254\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.327: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 85, numImages:    52]\n","Acc:0.7945095678500829, Acc_class:0.30123076510458197, mIoU:0.23377591228339215, fwIoU: 0.6614427896625724\n","Classwise_IoU:\n","[0.81439655 0.         0.44402047 0.38464602 0.07666058 0.02808579\n"," 0.         0.35617381 0.        ]\n","Loss: 8.506\n","[[9.145038e+06 0.000000e+00 5.598400e+04 3.947600e+04 1.255100e+04\n","  2.090000e+03 0.000000e+00 2.060350e+05 0.000000e+00]\n"," [7.590000e+03 0.000000e+00 1.661400e+04 1.454800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.106000e+03 0.000000e+00]\n"," [5.439830e+05 0.000000e+00 8.075640e+05 6.470600e+04 1.270000e+03\n","  1.586000e+03 0.000000e+00 2.573870e+05 0.000000e+00]\n"," [2.336860e+05 0.000000e+00 1.576600e+04 3.844310e+05 0.000000e+00\n","  2.670000e+02 0.000000e+00 9.793900e+04 0.000000e+00]\n"," [8.535900e+04 0.000000e+00 1.168700e+04 9.010000e+02 1.183900e+04\n","  4.740000e+03 0.000000e+00 1.120700e+04 0.000000e+00]\n"," [5.748020e+05 0.000000e+00 3.537700e+04 1.795000e+03 1.453300e+04\n","  1.859900e+04 0.000000e+00 8.432000e+03 0.000000e+00]\n"," [1.144300e+04 0.000000e+00 0.000000e+00 3.548000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 8.760000e+03 0.000000e+00]\n"," [2.861500e+05 0.000000e+00 4.028000e+03 2.567400e+04 3.470000e+02\n","  0.000000e+00 0.000000e+00 5.052240e+05 0.000000e+00]\n"," [2.503300e+04 0.000000e+00 2.802000e+03 1.167040e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.187000e+03 0.000000e+00]]\n","\n","=>Epoches 86, learning rate = 0.0009,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.256: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 86, numImages:   362]\n","Loss: 46.421\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.322: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 86, numImages:    52]\n","Acc:0.7981551486219589, Acc_class:0.2982104125084903, mIoU:0.23387407194881357, fwIoU: 0.6670498886266716\n","Classwise_IoU:\n","[0.82103052 0.         0.46306118 0.40122664 0.07180573 0.02503046\n"," 0.         0.32271211 0.        ]\n","Loss: 8.383\n","[[9.211781e+06 0.000000e+00 5.898400e+04 4.489000e+04 1.061200e+04\n","  2.067000e+03 0.000000e+00 1.328400e+05 0.000000e+00]\n"," [6.414000e+03 0.000000e+00 9.344000e+03 2.116200e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.938000e+03 0.000000e+00]\n"," [4.990380e+05 0.000000e+00 8.314120e+05 5.493400e+04 8.025000e+03\n","  1.744000e+03 0.000000e+00 2.813430e+05 0.000000e+00]\n"," [1.966560e+05 0.000000e+00 1.372400e+04 4.037660e+05 4.000000e+00\n","  1.930000e+02 0.000000e+00 1.177460e+05 0.000000e+00]\n"," [9.156900e+04 0.000000e+00 7.563000e+03 1.686000e+03 1.166800e+04\n","  4.731000e+03 0.000000e+00 8.516000e+03 0.000000e+00]\n"," [5.851690e+05 0.000000e+00 2.601400e+04 7.580000e+02 1.806500e+04\n","  1.657700e+04 0.000000e+00 6.955000e+03 0.000000e+00]\n"," [1.287500e+04 0.000000e+00 0.000000e+00 3.434000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.442000e+03 0.000000e+00]\n"," [3.469950e+05 0.000000e+00 3.313000e+03 2.368000e+04 5.500000e+01\n","  0.000000e+00 0.000000e+00 4.473800e+05 0.000000e+00]\n"," [1.988900e+04 0.000000e+00 3.100000e+01 1.236960e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.110000e+03 0.000000e+00]]\n","\n","=>Epoches 87, learning rate = 0.0008,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.253: 100%|██████████| 181/181 [03:25<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 87, numImages:   362]\n","Loss: 45.867\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.317: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 87, numImages:    52]\n","Acc:0.7929945279386132, Acc_class:0.2936886909011582, mIoU:0.23411894110699574, fwIoU: 0.653437111656892\n","Classwise_IoU:\n","[0.80895875 0.         0.42254313 0.39626046 0.07277261 0.0064053\n"," 0.         0.32297978 0.07715043]\n","Loss: 8.235\n","[[9.267442e+06 0.000000e+00 3.557700e+04 3.945500e+04 5.929000e+03\n","  5.060000e+02 0.000000e+00 1.122400e+05 2.500000e+01]\n"," [7.745000e+03 0.000000e+00 3.935000e+03 2.133600e+04 6.000000e+00\n","  0.000000e+00 0.000000e+00 6.687000e+03 4.149000e+03]\n"," [5.923930e+05 0.000000e+00 7.407460e+05 1.046370e+05 3.140000e+02\n","  4.770000e+02 0.000000e+00 2.379290e+05 0.000000e+00]\n"," [2.583480e+05 0.000000e+00 6.327000e+03 4.139420e+05 0.000000e+00\n","  5.600000e+01 0.000000e+00 5.341600e+04 0.000000e+00]\n"," [9.297000e+04 0.000000e+00 9.333000e+03 9.390000e+02 9.893000e+03\n","  3.784000e+03 0.000000e+00 8.814000e+03 0.000000e+00]\n"," [6.213020e+05 0.000000e+00 1.969900e+04 1.574000e+03 3.806000e+03\n","  4.217000e+03 0.000000e+00 2.940000e+03 0.000000e+00]\n"," [1.319800e+04 0.000000e+00 0.000000e+00 3.342000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.211000e+03 0.000000e+00]\n"," [3.839510e+05 0.000000e+00 1.694000e+03 3.154200e+04 1.560000e+02\n","  0.000000e+00 0.000000e+00 4.040800e+05 0.000000e+00]\n"," [2.493200e+04 0.000000e+00 5.000000e+00 1.097070e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.400000e+02 1.164200e+04]]\n","\n","=>Epoches 88, learning rate = 0.0007,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.243: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 88, numImages:   362]\n","Loss: 44.043\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.328: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 88, numImages:    52]\n","Acc:0.7880122074233082, Acc_class:0.2834271121131038, mIoU:0.2212327338524499, fwIoU: 0.6466022570301283\n","Classwise_IoU:\n","[0.80508391 0.         0.40490257 0.39690608 0.0660966  0.02525431\n"," 0.         0.28813487 0.00471627]\n","Loss: 8.532\n","[[9.278431e+06 0.000000e+00 3.581800e+04 5.367600e+04 4.070300e+04\n","  1.512000e+03 0.000000e+00 5.103400e+04 0.000000e+00]\n"," [8.408000e+03 0.000000e+00 4.197000e+03 2.727800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.975000e+03 0.000000e+00]\n"," [6.532450e+05 0.000000e+00 7.057970e+05 1.492360e+05 2.076400e+04\n","  1.867000e+03 0.000000e+00 1.455870e+05 0.000000e+00]\n"," [2.460910e+05 0.000000e+00 3.054000e+03 4.645480e+05 0.000000e+00\n","  4.680000e+02 0.000000e+00 1.792800e+04 0.000000e+00]\n"," [9.328200e+04 0.000000e+00 6.334000e+03 1.216000e+03 1.450100e+04\n","  4.361000e+03 0.000000e+00 6.039000e+03 0.000000e+00]\n"," [5.858250e+05 0.000000e+00 1.599600e+04 2.225000e+03 3.154100e+04\n","  1.671300e+04 0.000000e+00 1.238000e+03 0.000000e+00]\n"," [1.515200e+04 0.000000e+00 0.000000e+00 4.076000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.523000e+03 0.000000e+00]\n"," [4.393300e+05 0.000000e+00 1.233000e+03 7.707000e+04 6.500000e+02\n","  4.200000e+01 0.000000e+00 3.030980e+05 0.000000e+00]\n"," [2.229300e+04 0.000000e+00 0.000000e+00 1.235570e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.840000e+02 6.920000e+02]]\n","\n","=>Epoches 89, learning rate = 0.0007,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.244: 100%|██████████| 181/181 [03:27<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 89, numImages:   362]\n","Loss: 44.217\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.314: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 89, numImages:    52]\n","Acc:0.7964016687726547, Acc_class:0.29124835527103715, mIoU:0.23408591856165867, fwIoU: 0.6553907672512097\n","Classwise_IoU:\n","[0.80720739 0.         0.43770202 0.40173884 0.07703563 0.00321024\n"," 0.         0.35025767 0.02962147]\n","Loss: 8.173\n","[[9.29326e+06 0.00000e+00 3.94720e+04 3.58040e+04 1.00640e+04 1.44000e+02\n","  0.00000e+00 8.24280e+04 2.00000e+00]\n"," [8.56100e+03 0.00000e+00 4.37000e+03 2.28010e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 4.08500e+03 4.04100e+03]\n"," [6.53142e+05 0.00000e+00 7.66316e+05 9.51030e+04 1.08600e+03 2.70000e+01\n","  0.00000e+00 1.60822e+05 0.00000e+00]\n"," [2.47734e+05 0.00000e+00 2.69000e+02 4.18133e+05 1.07000e+02 3.00000e+00\n","  0.00000e+00 6.58430e+04 0.00000e+00]\n"," [9.42920e+04 0.00000e+00 8.86600e+03 9.77000e+02 1.07930e+04 2.31300e+03\n","  0.00000e+00 8.49200e+03 0.00000e+00]\n"," [6.26920e+05 0.00000e+00 1.81100e+04 1.45300e+03 2.93600e+03 2.10600e+03\n","  0.00000e+00 2.01300e+03 0.00000e+00]\n"," [1.53150e+04 0.00000e+00 0.00000e+00 3.44000e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 4.99600e+03 0.00000e+00]\n"," [3.83560e+05 0.00000e+00 3.17600e+03 3.09950e+04 1.78000e+02 0.00000e+00\n","  0.00000e+00 4.03514e+05 0.00000e+00]\n"," [2.21550e+04 0.00000e+00 1.20000e+01 1.18146e+05 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.94700e+03 4.46600e+03]]\n","\n","=>Epoches 90, learning rate = 0.0006,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.258: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 90, numImages:   362]\n","Loss: 46.616\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.309: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 90, numImages:    52]\n","Acc:0.8010713794031739, Acc_class:0.2930115271507304, mIoU:0.23906451117733107, fwIoU: 0.6617857931837507\n","Classwise_IoU:\n","[0.80844076 0.         0.48185713 0.40549781 0.07760617 0.00535244\n"," 0.         0.34822822 0.02459807]\n","Loss: 8.038\n","[[9.295789e+06 0.000000e+00 4.518200e+04 3.572400e+04 1.444900e+04\n","  3.670000e+02 0.000000e+00 6.965400e+04 9.000000e+00]\n"," [8.343000e+03 0.000000e+00 1.563000e+04 1.374600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.651000e+03 1.488000e+03]\n"," [6.179610e+05 0.000000e+00 8.617080e+05 5.988800e+04 1.765000e+03\n","  4.060000e+02 0.000000e+00 1.347680e+05 0.000000e+00]\n"," [2.545860e+05 0.000000e+00 1.587300e+04 4.012490e+05 0.000000e+00\n","  3.180000e+02 0.000000e+00 6.006300e+04 0.000000e+00]\n"," [9.480300e+04 0.000000e+00 9.734000e+03 1.017000e+03 1.179800e+04\n","  3.389000e+03 0.000000e+00 4.992000e+03 0.000000e+00]\n"," [6.232430e+05 0.000000e+00 1.639400e+04 1.188000e+03 7.623000e+03\n","  3.522000e+03 0.000000e+00 1.568000e+03 0.000000e+00]\n"," [1.408500e+04 0.000000e+00 0.000000e+00 3.228000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.438000e+03 0.000000e+00]\n"," [4.014100e+05 0.000000e+00 6.213000e+03 2.656600e+04 2.454000e+03\n","  0.000000e+00 0.000000e+00 3.847800e+05 0.000000e+00]\n"," [2.281200e+04 0.000000e+00 2.784000e+03 1.160760e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.408000e+03 3.646000e+03]]\n","\n","=>Epoches 91, learning rate = 0.0006,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.245: 100%|██████████| 181/181 [03:25<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 91, numImages:   362]\n","Loss: 44.296\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.308: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 91, numImages:    52]\n","Acc:0.8009248663552552, Acc_class:0.3002827358041913, mIoU:0.24340643258051997, fwIoU: 0.6621010289945153\n","Classwise_IoU:\n","[0.80808806 0.         0.4730706  0.42891406 0.07413936 0.0150657\n"," 0.         0.34319535 0.04818477]\n","Loss: 8.009\n","[[9.275844e+06 0.000000e+00 4.211700e+04 5.079900e+04 2.165100e+04\n","  1.253000e+03 0.000000e+00 6.949300e+04 1.700000e+01]\n"," [7.537000e+03 0.000000e+00 1.061700e+04 1.841800e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.874000e+03 2.412000e+03]\n"," [6.309360e+05 0.000000e+00 8.354810e+05 8.068100e+04 2.003000e+03\n","  1.501000e+03 0.000000e+00 1.258940e+05 0.000000e+00]\n"," [2.313980e+05 0.000000e+00 9.266000e+03 4.513780e+05 3.200000e+01\n","  2.930000e+02 0.000000e+00 3.972200e+04 0.000000e+00]\n"," [9.545800e+04 0.000000e+00 7.395000e+03 1.321000e+03 1.181900e+04\n","  4.453000e+03 0.000000e+00 5.287000e+03 0.000000e+00]\n"," [6.179790e+05 0.000000e+00 1.316100e+04 2.289000e+03 8.358000e+03\n","  9.959000e+03 0.000000e+00 1.792000e+03 0.000000e+00]\n"," [1.440300e+04 0.000000e+00 0.000000e+00 3.731000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.617000e+03 0.000000e+00]\n"," [3.988830e+05 0.000000e+00 6.457000e+03 4.562500e+04 1.639000e+03\n","  0.000000e+00 0.000000e+00 3.688190e+05 0.000000e+00]\n"," [2.098600e+04 0.000000e+00 5.720000e+02 1.174210e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.600000e+02 7.187000e+03]]\n","\n","=>Epoches 92, learning rate = 0.0005,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.248: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 92, numImages:   362]\n","Loss: 44.915\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.318: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 92, numImages:    52]\n","Acc:0.7951705938009416, Acc_class:0.2825325740676481, mIoU:0.2294382295233868, fwIoU: 0.6540393868385854\n","Classwise_IoU:\n","[0.80682812 0.         0.43773356 0.38651389 0.06932046 0.03942314\n"," 0.         0.3228758  0.00224909]\n","Loss: 8.270\n","[[9.313551e+06 0.000000e+00 3.928000e+04 2.937100e+04 7.316000e+03\n","  3.354000e+03 0.000000e+00 6.830200e+04 0.000000e+00]\n"," [9.493000e+03 0.000000e+00 1.489300e+04 1.455700e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.915000e+03 0.000000e+00]\n"," [6.395010e+05 0.000000e+00 7.785910e+05 4.990900e+04 4.410000e+02\n","  4.504000e+03 0.000000e+00 2.035500e+05 0.000000e+00]\n"," [2.850760e+05 0.000000e+00 1.389800e+04 3.749320e+05 0.000000e+00\n","  4.170000e+02 0.000000e+00 5.776600e+04 0.000000e+00]\n"," [9.420400e+04 0.000000e+00 9.740000e+03 8.810000e+02 9.940000e+03\n","  5.105000e+03 0.000000e+00 5.863000e+03 0.000000e+00]\n"," [5.983040e+05 0.000000e+00 1.780600e+04 2.610000e+02 9.316000e+03\n","  2.629200e+04 0.000000e+00 1.559000e+03 0.000000e+00]\n"," [1.390300e+04 0.000000e+00 0.000000e+00 3.221000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.627000e+03 0.000000e+00]\n"," [4.160980e+05 0.000000e+00 4.345000e+03 2.228900e+04 5.860000e+02\n","  0.000000e+00 0.000000e+00 3.781050e+05 0.000000e+00]\n"," [2.566100e+04 0.000000e+00 2.229000e+03 1.174570e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.049000e+03 3.300000e+02]]\n","\n","=>Epoches 93, learning rate = 0.0005,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.243: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 93, numImages:   362]\n","Loss: 43.929\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.314: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 93, numImages:    52]\n","Acc:0.7953097263910848, Acc_class:0.28801758031932123, mIoU:0.23229640433032525, fwIoU: 0.6534876447088187\n","Classwise_IoU:\n","[0.80680395 0.         0.41773612 0.4176876  0.07334053 0.03510765\n"," 0.         0.32808622 0.01190557]\n","Loss: 8.163\n","[[9.312708e+06 0.000000e+00 3.113200e+04 3.859000e+04 8.018000e+03\n","  3.009000e+03 0.000000e+00 6.771700e+04 0.000000e+00]\n"," [8.230000e+03 0.000000e+00 1.346700e+04 1.596400e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.185000e+03 1.200000e+01]\n"," [6.793370e+05 0.000000e+00 7.332000e+05 7.981800e+04 4.140000e+02\n","  4.004000e+03 0.000000e+00 1.797230e+05 0.000000e+00]\n"," [2.480780e+05 0.000000e+00 4.114000e+03 4.275350e+05 0.000000e+00\n","  4.860000e+02 0.000000e+00 5.187600e+04 0.000000e+00]\n"," [9.490500e+04 0.000000e+00 7.994000e+03 1.144000e+03 1.039800e+04\n","  5.342000e+03 0.000000e+00 5.950000e+03 0.000000e+00]\n"," [6.036420e+05 0.000000e+00 1.700900e+04 1.027000e+03 7.005000e+03\n","  2.339500e+04 0.000000e+00 1.460000e+03 0.000000e+00]\n"," [1.377400e+04 0.000000e+00 0.000000e+00 3.526000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.451000e+03 0.000000e+00]\n"," [4.102160e+05 0.000000e+00 3.207000e+03 3.273100e+04 6.070000e+02\n","  0.000000e+00 0.000000e+00 3.746620e+05 0.000000e+00]\n"," [2.335900e+04 0.000000e+00 1.756000e+03 1.186870e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.177000e+03 1.747000e+03]]\n","\n","=>Epoches 94, learning rate = 0.0004,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.241: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 94, numImages:   362]\n","Loss: 43.694\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.317: 100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 94, numImages:    52]\n","Acc:0.79461508647412, Acc_class:0.28094529860219275, mIoU:0.22735351042203789, fwIoU: 0.6541933785208364\n","Classwise_IoU:\n","[0.80869315 0.         0.43856623 0.36859652 0.07428063 0.01799796\n"," 0.         0.33423728 0.00380982]\n","Loss: 8.249\n","[[9.298049e+06 0.000000e+00 4.200700e+04 2.157500e+04 3.754000e+03\n","  7.800000e+02 0.000000e+00 9.500900e+04 0.000000e+00]\n"," [8.210000e+03 0.000000e+00 2.447100e+04 4.904000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.273000e+03 0.000000e+00]\n"," [6.341380e+05 0.000000e+00 8.010250e+05 1.533000e+04 3.150000e+02\n","  1.183000e+03 0.000000e+00 2.245050e+05 0.000000e+00]\n"," [2.696360e+05 0.000000e+00 3.422000e+04 3.298080e+05 0.000000e+00\n","  5.220000e+02 0.000000e+00 9.790300e+04 0.000000e+00]\n"," [9.357200e+04 0.000000e+00 1.001300e+04 6.690000e+02 1.017600e+04\n","  4.774000e+03 0.000000e+00 6.529000e+03 0.000000e+00]\n"," [6.154080e+05 0.000000e+00 1.647300e+04 6.200000e+01 6.927000e+03\n","  1.189300e+04 0.000000e+00 2.775000e+03 0.000000e+00]\n"," [1.370100e+04 0.000000e+00 6.000000e+00 3.042000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.002000e+03 0.000000e+00]\n"," [3.770340e+05 0.000000e+00 6.434000e+03 1.506100e+04 2.650000e+02\n","  0.000000e+00 0.000000e+00 4.226290e+05 0.000000e+00]\n"," [2.475000e+04 0.000000e+00 1.634300e+04 1.020350e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.039000e+03 5.590000e+02]]\n","\n","=>Epoches 95, learning rate = 0.0003,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.243: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 95, numImages:   362]\n","Loss: 43.992\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.304: 100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 95, numImages:    52]\n","Acc:0.8058650963390883, Acc_class:0.30775521150150903, mIoU:0.24582926781303552, fwIoU: 0.6747478032597088\n","Classwise_IoU:\n","[0.82023035 0.         0.50206041 0.40718581 0.07494362 0.02608129\n"," 0.         0.37220907 0.00975287]\n","Loss: 7.905\n","[[9.187501e+06 0.000000e+00 8.066300e+04 4.643800e+04 2.025900e+04\n","  1.850000e+03 0.000000e+00 1.244630e+05 0.000000e+00]\n"," [6.478000e+03 0.000000e+00 2.449400e+04 8.523000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 4.363000e+03 0.000000e+00]\n"," [4.922590e+05 0.000000e+00 9.594490e+05 4.946700e+04 1.421000e+03\n","  1.523000e+03 0.000000e+00 1.723770e+05 0.000000e+00]\n"," [1.994190e+05 0.000000e+00 6.764700e+04 4.005670e+05 0.000000e+00\n","  5.460000e+02 0.000000e+00 6.391000e+04 0.000000e+00]\n"," [8.602700e+04 0.000000e+00 1.262700e+04 1.046000e+03 1.199600e+04\n","  5.087000e+03 0.000000e+00 8.950000e+03 0.000000e+00]\n"," [5.931570e+05 0.000000e+00 2.599800e+04 1.200000e+03 1.167200e+04\n","  1.728000e+04 0.000000e+00 4.231000e+03 0.000000e+00]\n"," [1.217500e+04 0.000000e+00 5.040000e+02 3.205000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.867000e+03 0.000000e+00]\n"," [3.294290e+05 0.000000e+00 1.360700e+04 2.753600e+04 9.820000e+02\n","  0.000000e+00 0.000000e+00 4.498690e+05 0.000000e+00]\n"," [2.100500e+04 0.000000e+00 8.987000e+03 1.142410e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.062000e+03 1.431000e+03]]\n","\n","=>Epoches 96, learning rate = 0.0003,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.239: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 96, numImages:   362]\n","Loss: 43.344\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.320: 100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 96, numImages:    52]\n","Acc:0.7944888879535438, Acc_class:0.28824614508559687, mIoU:0.2308967442835493, fwIoU: 0.652109953236486\n","Classwise_IoU:\n","[0.80663496 0.         0.41436364 0.42423483 0.07535538 0.0071171\n"," 0.         0.32826964 0.02209516]\n","Loss: 8.330\n","[[9.31136e+06 0.00000e+00 2.97760e+04 4.15620e+04 9.59100e+03 2.67000e+02\n","  0.00000e+00 6.86150e+04 3.00000e+00]\n"," [8.51000e+03 0.00000e+00 1.04500e+04 2.03930e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 4.50500e+03 0.00000e+00]\n"," [6.62956e+05 0.00000e+00 7.21606e+05 8.54260e+04 7.19000e+02 5.17000e+02\n","  0.00000e+00 2.05272e+05 0.00000e+00]\n"," [2.43355e+05 0.00000e+00 3.04800e+03 4.40038e+05 0.00000e+00 1.90000e+01\n","  0.00000e+00 4.56290e+04 0.00000e+00]\n"," [9.85310e+04 0.00000e+00 5.26600e+03 1.04000e+03 1.07930e+04 3.37100e+03\n","  0.00000e+00 6.73200e+03 0.00000e+00]\n"," [6.25350e+05 0.00000e+00 1.37120e+04 1.32400e+03 6.87900e+03 4.68100e+03\n","  0.00000e+00 1.59200e+03 0.00000e+00]\n"," [1.50870e+04 0.00000e+00 0.00000e+00 3.38300e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 5.28100e+03 0.00000e+00]\n"," [4.05022e+05 0.00000e+00 2.60700e+03 3.27960e+04 3.06000e+02 0.00000e+00\n","  0.00000e+00 3.80692e+05 0.00000e+00]\n"," [2.34770e+04 0.00000e+00 1.25000e+02 1.19238e+05 0.00000e+00 0.00000e+00\n","  0.00000e+00 6.44000e+02 3.24200e+03]]\n","\n","=>Epoches 97, learning rate = 0.0002,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.237: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 97, numImages:   362]\n","Loss: 42.851\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.307: 100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 97, numImages:    52]\n","Acc:0.8041246967070297, Acc_class:0.30007738176111076, mIoU:0.24104365318405874, fwIoU: 0.670188008068343\n","Classwise_IoU:\n","[0.8166813  0.         0.49643417 0.40824149 0.07164847 0.01070855\n"," 0.         0.36137154 0.00430735]\n","Loss: 7.991\n","[[9.217596e+06 0.000000e+00 8.721700e+04 4.541100e+04 1.664500e+04\n","  1.038000e+03 0.000000e+00 9.326700e+04 0.000000e+00]\n"," [6.979000e+03 0.000000e+00 2.280300e+04 1.123600e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 2.840000e+03 0.000000e+00]\n"," [5.043160e+05 0.000000e+00 9.478780e+05 5.046500e+04 1.033000e+03\n","  7.980000e+02 0.000000e+00 1.720060e+05 0.000000e+00]\n"," [2.212310e+05 0.000000e+00 6.125900e+04 4.038480e+05 0.000000e+00\n","  3.340000e+02 0.000000e+00 4.541700e+04 0.000000e+00]\n"," [9.163500e+04 0.000000e+00 1.093000e+04 1.158000e+03 1.100800e+04\n","  4.512000e+03 0.000000e+00 6.490000e+03 0.000000e+00]\n"," [6.051090e+05 0.000000e+00 2.838300e+04 9.170000e+02 9.828000e+03\n","  7.070000e+03 0.000000e+00 2.231000e+03 0.000000e+00]\n"," [1.306100e+04 0.000000e+00 1.470000e+02 3.388000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 7.155000e+03 0.000000e+00]\n"," [3.612930e+05 0.000000e+00 1.497800e+04 2.850800e+04 4.000000e+02\n","  0.000000e+00 0.000000e+00 4.162440e+05 0.000000e+00]\n"," [2.185200e+04 0.000000e+00 7.160000e+03 1.160660e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 1.016000e+03 6.320000e+02]]\n","\n","=>Epoches 98, learning rate = 0.0001,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.238: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 98, numImages:   362]\n","Loss: 43.100\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.301: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 98, numImages:    52]\n","Acc:0.8023465909738609, Acc_class:0.29363407003569814, mIoU:0.2385920960470155, fwIoU: 0.6644601254855922\n","Classwise_IoU:\n","[0.81072804 0.         0.48365165 0.41941057 0.06751587 0.02264356\n"," 0.         0.34237732 0.00100187]\n","Loss: 7.828\n","[[9.285055e+06 0.000000e+00 4.909100e+04 3.841900e+04 1.790400e+04\n","  1.644000e+03 0.000000e+00 6.906100e+04 0.000000e+00]\n"," [8.271000e+03 0.000000e+00 1.925500e+04 1.315500e+04 0.000000e+00\n","  0.000000e+00 0.000000e+00 3.177000e+03 0.000000e+00]\n"," [5.893530e+05 0.000000e+00 8.698470e+05 6.753600e+04 1.111000e+03\n","  2.369000e+03 0.000000e+00 1.462800e+05 0.000000e+00]\n"," [2.472000e+05 0.000000e+00 1.592800e+04 4.233870e+05 0.000000e+00\n","  3.480000e+02 0.000000e+00 4.522600e+04 0.000000e+00]\n"," [9.493700e+04 0.000000e+00 9.278000e+03 8.400000e+02 1.034100e+04\n","  4.850000e+03 0.000000e+00 5.487000e+03 0.000000e+00]\n"," [6.103790e+05 0.000000e+00 1.734100e+04 1.260000e+03 8.149000e+03\n","  1.500700e+04 0.000000e+00 1.402000e+03 0.000000e+00]\n"," [1.442400e+04 0.000000e+00 0.000000e+00 3.360000e+03 0.000000e+00\n","  0.000000e+00 0.000000e+00 5.967000e+03 0.000000e+00]\n"," [4.038000e+05 0.000000e+00 8.175000e+03 3.302200e+04 2.670000e+02\n","  0.000000e+00 0.000000e+00 3.761590e+05 0.000000e+00]\n"," [2.319900e+04 0.000000e+00 2.935000e+03 1.198000e+05 0.000000e+00\n","  0.000000e+00 0.000000e+00 6.450000e+02 1.470000e+02]]\n","\n","=>Epoches 99, learning rate = 0.0001,                 previous best = 0.2698\n"],"name":"stdout"},{"output_type":"stream","text":["Train loss: 0.238: 100%|██████████| 181/181 [03:26<00:00,  1.14s/it]\n",":   0%|          | 0/26 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch: 99, numImages:   362]\n","Loss: 43.157\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.310: 100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",":   0%|          | 0/56 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 99, numImages:    52]\n","Acc:0.8033162077483407, Acc_class:0.3023268763849111, mIoU:0.24129149267459743, fwIoU: 0.6698953063052733\n","Classwise_IoU:\n","[0.81880124 0.         0.47440178 0.41074791 0.0788518  0.02468283\n"," 0.         0.36319052 0.00094734]\n","Loss: 8.058\n","[[9.23099e+06 0.00000e+00 5.58310e+04 4.41220e+04 1.35220e+04 1.54400e+03\n","  0.00000e+00 1.15165e+05 0.00000e+00]\n"," [7.21100e+03 0.00000e+00 2.07140e+04 1.09680e+04 0.00000e+00 0.00000e+00\n","  0.00000e+00 4.96500e+03 0.00000e+00]\n"," [5.30692e+05 0.00000e+00 8.78872e+05 5.39000e+04 8.08000e+02 2.13600e+03\n","  0.00000e+00 2.10088e+05 0.00000e+00]\n"," [2.14858e+05 0.00000e+00 4.92000e+04 4.07220e+05 0.00000e+00 3.23000e+02\n","  0.00000e+00 6.04880e+04 0.00000e+00]\n"," [9.00530e+04 0.00000e+00 9.90100e+03 1.06600e+03 1.17680e+04 4.25500e+03\n","  0.00000e+00 8.69000e+03 0.00000e+00]\n"," [5.98345e+05 0.00000e+00 2.54200e+04 1.04300e+03 8.71800e+03 1.63350e+04\n","  0.00000e+00 3.67700e+03 0.00000e+00]\n"," [1.27130e+04 0.00000e+00 3.72000e+02 3.26800e+03 0.00000e+00 0.00000e+00\n","  0.00000e+00 7.39800e+03 0.00000e+00]\n"," [3.37765e+05 0.00000e+00 7.47800e+03 2.78310e+04 4.61000e+02 0.00000e+00\n","  0.00000e+00 4.47888e+05 0.00000e+00]\n"," [2.09750e+04 0.00000e+00 7.17800e+03 1.17124e+05 0.00000e+00 0.00000e+00\n","  0.00000e+00 1.31000e+03 1.39000e+02]]\n","TEST RESULTS ARE BELOW::::::::::::::::::::::::::::\n"],"name":"stdout"},{"output_type":"stream","text":["Test loss: 0.307: 100%|██████████| 56/56 [00:15<00:00,  3.57it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation:\n","[Epoch: 0, numImages:   111]\n","Acc:0.8104841615323473, Acc_class:0.3176707533434975, mIoU:0.23799330645771746, fwIoU: 0.6885255189983248\n","Classwise_IoU:\n","[8.31859612e-01 0.00000000e+00 4.47256266e-01 4.12472358e-01\n"," 1.26540280e-01 1.32262478e-02 0.00000000e+00 3.10578571e-01\n"," 6.42385907e-06]\n","Loss: 17.203\n","[[2.0463244e+07 0.0000000e+00 5.0892200e+05 1.5315900e+05 2.6949000e+04\n","  2.4937000e+04 0.0000000e+00 2.0122600e+05 0.0000000e+00]\n"," [6.5300000e+03 0.0000000e+00 1.4778000e+04 4.6180000e+03 0.0000000e+00\n","  0.0000000e+00 0.0000000e+00 9.9750000e+03 0.0000000e+00]\n"," [9.0643000e+05 0.0000000e+00 1.9072340e+06 1.3142600e+05 5.2440000e+03\n","  7.3910000e+03 0.0000000e+00 4.1569600e+05 0.0000000e+00]\n"," [2.2552500e+05 0.0000000e+00 8.8651000e+04 6.9499200e+05 2.6000000e+01\n","  0.0000000e+00 0.0000000e+00 9.2265000e+04 0.0000000e+00]\n"," [2.0233800e+05 0.0000000e+00 1.7682000e+04 1.7400000e+02 3.8787000e+04\n","  1.9500000e+03 0.0000000e+00 8.5670000e+03 0.0000000e+00]\n"," [1.3345830e+06 0.0000000e+00 8.6116000e+04 6.0660000e+03 3.4560000e+03\n","  1.9854000e+04 0.0000000e+00 1.6753000e+04 0.0000000e+00]\n"," [8.1486000e+04 0.0000000e+00 2.3710000e+03 5.0880000e+03 0.0000000e+00\n","  0.0000000e+00 0.0000000e+00 2.3842000e+04 0.0000000e+00]\n"," [4.2805600e+05 0.0000000e+00 1.4443000e+04 1.1020000e+04 1.3460000e+03\n","  0.0000000e+00 0.0000000e+00 5.5155400e+05 0.0000000e+00]\n"," [3.6011000e+04 0.0000000e+00 1.5791400e+05 2.7193200e+05 0.0000000e+00\n","  0.0000000e+00 0.0000000e+00 1.1490000e+03 3.0000000e+00]]\n","model.modularity.module0.module0.conv1\n","model.modularity.module0.module0.conv2\n","model.modularity.module0.module0.conv3\n","model.modularity.module0.module1.conv1\n","model.modularity.module0.module1.conv2\n","model.modularity.module0.module1.conv3\n","model.modularity.module0.interconnection0.conv1\n","model.modularity.module0.interconnection0.conv2\n","model.modularity.module0.module2.conv1\n","model.modularity.module0.module2.conv2\n","model.modularity.module0.module2.conv3\n","model.modularity.module0.module3.conv1\n","model.modularity.module0.module3.conv2\n","model.modularity.module0.module3.conv3\n","model.modularity.module1.module0.conv1\n","model.modularity.module1.module0.conv2\n","model.modularity.module1.module0.conv3\n","model.modularity.module1.module1.conv1\n","model.modularity.module1.module1.conv2\n","model.modularity.module1.module1.conv3\n","model.modularity.module1.interconnection0.conv1\n","model.modularity.module1.interconnection0.conv2\n","model.modularity.module1.module2.conv1\n","model.modularity.module1.module2.conv2\n","model.modularity.module1.module2.conv3\n","model.modularity.module1.module3.conv1\n","model.modularity.module1.module3.conv2\n","model.modularity.module1.module3.conv3\n","model.modularity.interconnection0.conv1\n","model.modularity.interconnection0.conv2\n","model.modularity.module2.module0.conv1\n","model.modularity.module2.module0.conv2\n","model.modularity.module2.module0.conv3\n","model.modularity.module2.module1.conv1\n","model.modularity.module2.module1.conv2\n","model.modularity.module2.module1.conv3\n","model.modularity.module2.interconnection0.conv1\n","model.modularity.module2.interconnection0.conv2\n","model.modularity.module2.module2.conv1\n","model.modularity.module2.module2.conv2\n","model.modularity.module2.module2.conv3\n","model.modularity.module2.module3.conv1\n","model.modularity.module2.module3.conv2\n","model.modularity.module2.module3.conv3\n","model.modularity.module3.module0.conv1\n","model.modularity.module3.module0.conv2\n","model.modularity.module3.module0.conv3\n","model.modularity.module3.module1.conv1\n","model.modularity.module3.module1.conv2\n","model.modularity.module3.module1.conv3\n","model.modularity.module3.interconnection0.conv1\n","model.modularity.module3.interconnection0.conv2\n","model.modularity.module3.module2.conv1\n","model.modularity.module3.module2.conv2\n","model.modularity.module3.module2.conv3\n","model.modularity.module3.module3.conv1\n","model.modularity.module3.module3.conv2\n","model.modularity.module3.module3.conv3\n","model.modularity.interconnection1.conv1\n","model.modularity.interconnection1.conv2\n","model.modularity.module4.module0.conv1\n","model.modularity.module4.module0.conv2\n","model.modularity.module4.module0.conv3\n","model.modularity.module4.module1.conv1\n","model.modularity.module4.module1.conv2\n","model.modularity.module4.module1.conv3\n","model.modularity.module4.interconnection0.conv1\n","model.modularity.module4.interconnection0.conv2\n","model.modularity.module4.module2.conv1\n","model.modularity.module4.module2.conv2\n","model.modularity.module4.module2.conv3\n","model.modularity.module4.module3.conv1\n","model.modularity.module4.module3.conv2\n","model.modularity.module4.module3.conv3\n","model.modularity.module5.module0.conv1\n","model.modularity.module5.module0.conv2\n","model.modularity.module5.module0.conv3\n","model.modularity.module5.module1.conv1\n","model.modularity.module5.module1.conv2\n","model.modularity.module5.module1.conv3\n","model.modularity.module5.interconnection0.conv1\n","model.modularity.module5.interconnection0.conv2\n","model.modularity.module5.module2.conv1\n","model.modularity.module5.module2.conv2\n","model.modularity.module5.module2.conv3\n","model.modularity.module5.module3.conv1\n","model.modularity.module5.module3.conv2\n","model.modularity.module5.module3.conv3\n","model.modularity.interconnection2.conv1\n","model.modularity.interconnection2.conv2\n","model.modularity.module6.module0.conv1\n","model.modularity.module6.module0.conv2\n","model.modularity.module6.module0.conv3\n","model.modularity.module6.module1.conv1\n","model.modularity.module6.module1.conv2\n","model.modularity.module6.module1.conv3\n","model.modularity.module6.interconnection0.conv1\n","model.modularity.module6.interconnection0.conv2\n","model.modularity.module6.module2.conv1\n","model.modularity.module6.module2.conv2\n","model.modularity.module6.module2.conv3\n","model.modularity.module6.module3.conv1\n","model.modularity.module6.module3.conv2\n","model.modularity.module6.module3.conv3\n","model.modularity.module7.module0.conv1\n","model.modularity.module7.module0.conv2\n","model.modularity.module7.module0.conv3\n","model.modularity.module7.module1.conv1\n","model.modularity.module7.module1.conv2\n","model.modularity.module7.module1.conv3\n","model.modularity.module7.interconnection0.conv1\n","model.modularity.module7.interconnection0.conv2\n","model.modularity.module7.module2.conv1\n","model.modularity.module7.module2.conv2\n","model.modularity.module7.module2.conv3\n","model.modularity.module7.module3.conv1\n","model.modularity.module7.module3.conv2\n","model.modularity.module7.module3.conv3\n","model.modularity.interconnection3.conv1\n","model.modularity.interconnection3.conv2\n","model.modularity.module8.module0.conv1\n","model.modularity.module8.module0.conv2\n","model.modularity.module8.module0.conv3\n","model.modularity.module8.module1.conv1\n","model.modularity.module8.module1.conv2\n","model.modularity.module8.module1.conv3\n","model.modularity.module8.interconnection0.conv1\n","model.modularity.module8.interconnection0.conv2\n","model.modularity.module8.module2.conv1\n","model.modularity.module8.module2.conv2\n","model.modularity.module8.module2.conv3\n","model.modularity.module8.module3.conv1\n","model.modularity.module8.module3.conv2\n","model.modularity.module8.module3.conv3\n","model.modularity.module9.module0.conv1\n","model.modularity.module9.module0.conv2\n","model.modularity.module9.module0.conv3\n","model.modularity.module9.module1.conv1\n","model.modularity.module9.module1.conv2\n","model.modularity.module9.module1.conv3\n","model.modularity.module9.interconnection0.conv1\n","model.modularity.module9.interconnection0.conv2\n","model.modularity.module9.module2.conv1\n","model.modularity.module9.module2.conv2\n","model.modularity.module9.module2.conv3\n","model.modularity.module9.module3.conv1\n","model.modularity.module9.module3.conv2\n","model.modularity.module9.module3.conv3\n","model.modularity.interconnection4.conv1\n","model.modularity.interconnection4.conv2\n","model.modularity.module10.module0.conv1\n","model.modularity.module10.module0.conv2\n","model.modularity.module10.module0.conv3\n","model.modularity.module10.module1.conv1\n","model.modularity.module10.module1.conv2\n","model.modularity.module10.module1.conv3\n","model.modularity.module10.interconnection0.conv1\n","model.modularity.module10.interconnection0.conv2\n","model.modularity.module10.module2.conv1\n","model.modularity.module10.module2.conv2\n","model.modularity.module10.module2.conv3\n","model.modularity.module10.module3.conv1\n","model.modularity.module10.module3.conv2\n","model.modularity.module10.module3.conv3\n","model.modularity.module11.module0.conv1\n","model.modularity.module11.module0.conv2\n","model.modularity.module11.module0.conv3\n","model.modularity.module11.module1.conv1\n","model.modularity.module11.module1.conv2\n","model.modularity.module11.module1.conv3\n","model.modularity.module11.interconnection0.conv1\n","model.modularity.module11.interconnection0.conv2\n","model.modularity.module11.module2.conv1\n","model.modularity.module11.module2.conv2\n","model.modularity.module11.module2.conv3\n","model.modularity.module11.module3.conv1\n","model.modularity.module11.module3.conv2\n","model.modularity.module11.module3.conv3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u_DG36nzOlmU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594573788940,"user_tz":240,"elapsed":21569917,"user":{"displayName":"Jayant Parashar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjnbgSkOK4ntEuf3hVvbye4aBfehqWeRx41-5Ti=s64","userId":"12884008915719439798"}}},"source":["# TO Do : Do pruning whatever I have right now. \n","#better create testing set here too. "],"execution_count":13,"outputs":[]}]}